{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test the tools developped in Utilities/Optobot_utils.py. We then use these tools to analyse Irene's optobot experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "sys.path.insert(0, \"../Utilities\")\n",
    "\n",
    "# sys.path.append(\"/home/durrieu/Tracking_Analysis/Utilities\")\n",
    "# sys.path.append(\"/Users/ulric/git/Tracking_Analysis/Utilities\")\n",
    "import Utils\n",
    "import Optobot_utils\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the experiments\n",
    "\n",
    "We first developp a function to find the experiments in the main directory. We then use a custom class to load the experiments, including metadata and DLC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps = Optobot_utils.find_experiments(\n",
    "    Utils.get_labserver() / \"Experimental_data\" / \"Irene_Optobot\"\n",
    ")\n",
    "\n",
    "#Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the npy file called experiment_dict.npy\n",
    "\n",
    "# Load the experiment_dict.npy file\n",
    "exp_dict = np.load(TestFly / \"experiment_dict.npy\", allow_pickle=True).item()\n",
    "\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict[\"fly0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genotype_dict.npy file\n",
    "gen_dict = np.load(TestFly.parent.parent / \"genotype_dict.npy\", allow_pickle=True).item()\n",
    "\n",
    "gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a .pkl file in the folder\n",
    "pkl_files = list(TestFly.glob(\"*.pkl\"))\n",
    "\n",
    "# Get the first .pkl file\n",
    "pkl_file = pkl_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .pkl file\n",
    "import pickle\n",
    "with open(pkl_file, \"rb\") as input:\n",
    "    data = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the .pkl file\n",
    "data = pd.read_pickle(pkl_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve multiindex\n",
    "\n",
    "data.columns = data.columns.droplevel(0)\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the top level of the multi-index for 'pos_x' and 'pos_y'\n",
    "data.columns = (\n",
    "    data.columns.droplevel(0)\n",
    "    if \"pos_x\" in data.columns or \"pos_y\" in data.columns\n",
    "    else data.columns\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Optobot_utils.Fly(TestFly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = TestFly.compute_velocity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the velocity\n",
    "\n",
    "\n",
    "hv.Curve(vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like small movements below 0.1 mm/s could just be tracking noise. Let's use that to classify the frames as moving or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dataframe loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Optobot_utils.Fly(Exps[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps[0].parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i, exp in enumerate(Exps):\n",
    "    try:\n",
    "        # Load the data and add it to a list to be concatenated later\n",
    "        data = Optobot_utils.Fly(exp).data\n",
    "        # Add a unique identifier to each DataFrame\n",
    "        data[\"id\"] = i\n",
    "        data_list.append(data)\n",
    "    except:\n",
    "        print(f\"Failed to load {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = any(df.duplicated().any() for df in data_list)\n",
    "if duplicates:\n",
    "    print(\"Duplicate datasets found.\")\n",
    "else:\n",
    "    print(\"No duplicate datasets found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate the DataFrames\n",
    "dataset = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = pd.DataFrame()\n",
    "    for i, df in enumerate(data_list):\n",
    "        dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while concatenating DataFrame {i}.\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the problematic DataFrame\n",
    "problematic_df = data_list[16]\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(problematic_df.head())\n",
    "\n",
    "# Print the index of the DataFrame\n",
    "print(problematic_df.index)\n",
    "\n",
    "# Check if the DataFrame has any duplicate indices\n",
    "if problematic_df.index.duplicated().any():\n",
    "    print(\"The DataFrame has duplicate indices.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have duplicate indices.\")\n",
    "\n",
    "# Check if the DataFrame has any duplicate columns\n",
    "if problematic_df.columns.duplicated().any():\n",
    "    print(\"The DataFrame has duplicate columns.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have duplicate columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing nbstripout on semihg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All flies + velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i, exp in enumerate(Exps):\n",
    "    try:\n",
    "        # Load the data and add it to a list to be concatenated later\n",
    "        data = Optobot_utils.Fly(exp).data\n",
    "        # Add a unique identifier to each DataFrame\n",
    "        data[\"id\"] = i\n",
    "        data_list.append(data)\n",
    "    except:\n",
    "        print(f\"Failed to load {exp}\")\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "dataset = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackingAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
