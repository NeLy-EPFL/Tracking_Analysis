{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test the tools developped in Utilities/Optobot_utils.py. We then use these tools to analyse Irene's optobot experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "sys.path.insert(0, \"../Utilities\")\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# sys.path.append(\"/home/durrieu/Tracking_Analysis/Utilities\")\n",
    "# sys.path.append(\"/Users/ulric/git/Tracking_Analysis/Utilities\")\n",
    "import Utils\n",
    "import Optobot_utils\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Import holoviews template\n",
    "import HoloviewsTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Optobot_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the experiments\n",
    "\n",
    "We first developp a function to find the experiments in the main directory. We then use a custom class to load the experiments, including metadata and DLC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps = Optobot_utils.find_experiments(\n",
    "    Utils.get_labserver() / \"Experimental_data\" / \"Irene_Optobot\"\n",
    ")\n",
    "\n",
    "#Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the npy file called experiment_dict.npy\n",
    "\n",
    "# Load the experiment_dict.npy file\n",
    "exp_dict = np.load(TestFly / \"experiment_dict.npy\", allow_pickle=True).item()\n",
    "\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict['fps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict[\"fly0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genotype_dict.npy file\n",
    "gen_dict = np.load(TestFly.parent.parent / \"genotype_dict.npy\", allow_pickle=True).item()\n",
    "\n",
    "gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a .pkl file in the folder\n",
    "pkl_files = list(TestFly.glob(\"*.pkl\"))\n",
    "\n",
    "# Get the first .pkl file\n",
    "pkl_file = pkl_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .pkl file\n",
    "with open(pkl_file, \"rb\") as input:\n",
    "    data = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .pkl file\n",
    "data = pd.read_pickle(pkl_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve multiindex\n",
    "\n",
    "data.columns = data.columns.droplevel(0)\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the top level of the multi-index for 'pos_x' and 'pos_y'\n",
    "data.columns = (\n",
    "    data.columns.droplevel(0)\n",
    "    if \"pos_x\" in data.columns or \"pos_y\" in data.columns\n",
    "    else data.columns\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Optobot_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Optobot_utils.Fly(TestFly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = TestFly.compute_velocity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the velocity\n",
    "\n",
    "\n",
    "hv.Curve(vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like small movements below 0.1 mm/s could just be tracking noise. Let's use that to classify the frames as moving or not. Also, looking at the video, anything below 0.5 is actually small real movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1400/80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dataframe loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Optobot_utils.Fly(Exps[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps[0].parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for i, exp in enumerate(Exps):\n",
    "    try:\n",
    "        # Load the data and add it to a list to be concatenated later\n",
    "        data = Optobot_utils.Fly(exp).data\n",
    "        # Add a unique identifier to each DataFrame\n",
    "        data[\"id\"] = i\n",
    "        data_list.append(data)\n",
    "    except:\n",
    "        print(f\"Failed to load {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = any(df.duplicated().any() for df in data_list)\n",
    "if duplicates:\n",
    "    print(\"Duplicate datasets found.\")\n",
    "else:\n",
    "    print(\"No duplicate datasets found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate the DataFrames\n",
    "dataset = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = pd.DataFrame()\n",
    "    for i, df in enumerate(data_list):\n",
    "        dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while concatenating DataFrame {i}.\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the problematic DataFrame\n",
    "problematic_df = data_list[16]\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(problematic_df.head())\n",
    "\n",
    "# Print the index of the DataFrame\n",
    "print(problematic_df.index)\n",
    "\n",
    "# Check if the DataFrame has any duplicate indices\n",
    "if problematic_df.index.duplicated().any():\n",
    "    print(\"The DataFrame has duplicate indices.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have duplicate indices.\")\n",
    "\n",
    "# Check if the DataFrame has any duplicate columns\n",
    "if problematic_df.columns.duplicated().any():\n",
    "    print(\"The DataFrame has duplicate columns.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have duplicate columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing nbstripout on semihg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All flies + velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for i, exp in enumerate(Exps):\n",
    "    try:\n",
    "        # Load the data and add it to a list to be concatenated later\n",
    "        data = Optobot_utils.Fly(exp).data\n",
    "        # Add a unique identifier to each DataFrame\n",
    "        data[\"id\"] = i\n",
    "        data_list.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {exp}\")\n",
    "        #Also print the error\n",
    "        print(str(e))\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "dataset = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optobot_utils.Fly(\n",
    "    Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/Irene_Optobot/9 days/SynjRQ/SynjRQ-THGal4_m1_9d/221209/193753_s0a0_p6-0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting resting\n",
    "\n",
    "The resting would be basically the frames where the velocity is below 0.1 mm/s. Let's try to detect that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called \"resting\" that is True if the velocity is less than 0.1 and False otherwise\n",
    "\n",
    "dataset[\"resting\"] = dataset[\"velocity\"] < 0.1\n",
    "\n",
    "dataset[\"moving\"] = dataset[\"velocity\"] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the video there's 10 seconds of light off, 30 seconds of light on, 10 off, 30 on, 10 off, 30 on. Let's add this info to the dataframe. (Done directly in Optobot_Utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at average velocities when moving = True grouped by genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique values of genotype\n",
    "\n",
    "genotypes = dataset[\"genotype\"].unique()\n",
    "\n",
    "genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the genotypes that are the same but spelled differently\n",
    "# IF_Atg18 and IF-Atg18 are the same genotype\n",
    "dataset[\"genotype\"] = dataset[\"genotype\"].replace(\"IF_Atg18\", \"IF-Atg18\")\n",
    "# IF-THGal4 and IF_THGal4 are the same genotype\n",
    "dataset[\"genotype\"] = dataset[\"genotype\"].replace(\"IF_THGal4\", \"IF-THGal4\")\n",
    "# SYnjRQ and SynjRQ are the same genotype\n",
    "dataset[\"genotype\"] = dataset[\"genotype\"].replace(\"SYnjRQ\", \"SynjRQ\")\n",
    "# SynjRQ and SynjRQ-THGal4 are the same genotype\n",
    "dataset[\"genotype\"] = dataset[\"genotype\"].replace(\"SynjRQ-THGal4\", \"SynjRQ\")\n",
    "\n",
    "# Get all unique values of genotype\n",
    "genotypes = dataset[\"genotype\"].unique()\n",
    "\n",
    "genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the genotypes that are not of interest, in this case w1118\n",
    "dataset = dataset[dataset != \"w1118\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to only get moving = True\n",
    "\n",
    "moving = dataset[dataset[\"moving\"]]\n",
    "\n",
    "# Get average velocity grouped by genotype and id\n",
    "Avg_vel = moving.groupby([\"genotype\", \"id\"])[\"velocity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a holoviews boxplot of the average velocity grouped by genotype\n",
    "boxplot = hv.BoxWhisker(Avg_vel, \"genotype\", \"velocity\").opts(**HoloviewsTemplates.hv_main[\"boxwhisker\"])\n",
    "\n",
    "scatter = hv.Scatter(Avg_vel, \"genotype\", \"velocity\").opts(**HoloviewsTemplates.hv_main[\"scatter\"])\n",
    "scatter.opts(color=\"genotype\")\n",
    "\n",
    "jitterplot = (boxplot * scatter).opts(**HoloviewsTemplates.hv_main[\"plot\"])\n",
    "jitterplot.opts(ylabel=\"Average velocity (mm/s)\")\n",
    "jitterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not super conclusive. Let's look at the max velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max velocity grouped by genotype and id\n",
    "Max_vel = moving.groupby([\"genotype\", \"id\"])[\"velocity\"].max()\n",
    "\n",
    "# Remake the jitterplot with the max velocity\n",
    "\n",
    "# Make a holoviews boxplot of the average velocity grouped by genotype\n",
    "boxplot = hv.BoxWhisker(Max_vel, \"genotype\", \"velocity\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"boxwhisker\"]\n",
    ")\n",
    "\n",
    "scatter = hv.Scatter(Max_vel, \"genotype\", \"velocity\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"scatter\"]\n",
    ")\n",
    "scatter.opts(color=\"genotype\")\n",
    "\n",
    "jitterplot = (boxplot * scatter).opts(**HoloviewsTemplates.hv_main[\"plot\"])\n",
    "jitterplot.opts(ylabel=\"Maximum velocity (mm/s)\")\n",
    "\n",
    "\n",
    "jitterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not super conclusive either. Let's look at the proportion of time spent moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows in the dataset where moving = True, grouped by genotype and id\n",
    "# Make it a DataFrame\n",
    "num_moving = moving.groupby([\"genotype\", \"id\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "# Rename the counts column to \"time moving\" and divide by 80 to get the time in seconds\n",
    "num_moving.rename(columns={\"counts\": \"time moving\"}, inplace=True)\n",
    "num_moving[\"time moving\"] = num_moving[\"time moving\"] / 80\n",
    "\n",
    "num_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "boxplot = hv.BoxWhisker(num_moving, \"genotype\", \"time moving\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"boxwhisker\"]\n",
    ")\n",
    "\n",
    "scatter = hv.Scatter(num_moving, \"genotype\", \"time moving\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"scatter\"]\n",
    ")\n",
    "scatter.opts(color=\"genotype\")\n",
    "\n",
    "jitterplot = (boxplot * scatter).opts(**HoloviewsTemplates.hv_main[\"plot\"])\n",
    "\n",
    "jitterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Another method here where we just compute the proportion of time moving instead\n",
    "# Get the number of rows in the dataset where moving = True, grouped by genotype and id, and divide by the total number of rows grouped by genotype and id\n",
    "\n",
    "prop_moving = moving.groupby([\"genotype\", \"id\"]).size().div(dataset.groupby([\"genotype\", \"id\"]).size()).reset_index(name=\"proportion time moving\")\n",
    "prop_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "boxplot = hv.BoxWhisker(prop_moving, \"genotype\", \"proportion time moving\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"boxwhisker\"]\n",
    ")\n",
    "\n",
    "scatter = hv.Scatter(prop_moving, \"genotype\", \"proportion time moving\").opts(\n",
    "    **HoloviewsTemplates.hv_main[\"scatter\"]\n",
    ")\n",
    "scatter.opts(color=\"genotype\")\n",
    "\n",
    "jitterplot = (boxplot * scatter).opts(**HoloviewsTemplates.hv_main[\"plot\"])\n",
    "\n",
    "jitterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackingAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
