{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "\n",
    "import holoviews as hv\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import show\n",
    "from bokeh.models import TapTool\n",
    "from bokeh.models import CustomJS\n",
    "from bokeh.io import show, curdoc\n",
    "from bokeh.plotting import figure\n",
    "import webbrowser\n",
    "\n",
    "from holoviews import streams\n",
    "\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import traceback\n",
    "import json\n",
    "import datetime\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import cv2\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.fx import all as vfx\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a video\n",
    "\n",
    "Video = Path(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor5/corridor5.mp4\")\n",
    "\n",
    "Tracking = Path(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor5/corridor5_tracked_fly_full.000_corridor5.analysis.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(Tracking.as_posix(), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = f[\"node_names\"]\n",
    "\n",
    "keypoints[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(h5_file):\n",
    "    \"\"\"\n",
    "    Extracts the x and y coordinates from a h5 file. Only works for single object tracking. For skeleton tracking,\n",
    "    use extract_skeleton.\n",
    "\n",
    "    Args:\n",
    "        h5_file (str): The path to the h5 file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two np.ndarrays representing the x and y coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    with h5py.File(h5_file, \"r\") as f:\n",
    "        locs = f[\"tracks\"][:].T\n",
    "        y = locs[:, :, 1, :].squeeze()\n",
    "        x = locs[:, :, 0, :].squeeze()\n",
    "        keypoints = f[\"keypoints\"][:].T\n",
    "        \n",
    "    return x, y, keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tracking data\n",
    "\n",
    "tracks = extract_coordinates(Tracking)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the shape s like this: x, y . Below is : frame. Below is : keypoint.\n",
    "\n",
    "so tracks [0] [0] is x for frame 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clip(video, tracks, start_frame, end_frame, outpath=\"output.avi\"):\n",
    "    cap = cv2.VideoCapture(str(video))\n",
    "\n",
    "    # Get the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Get the width and height of frame\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    out = cv2.VideoWriter(outpath, fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        for i in range(start_frame, end_frame):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Get the current tracking data\n",
    "            x = tracks[0][i]\n",
    "            y = tracks[1][i]\n",
    "\n",
    "            # Draw the tracking data on the frame\n",
    "            for j in range(len(x)):\n",
    "                if not np.isnan(x[j]) and not np.isnan(y[j]):\n",
    "                    cv2.circle(frame, (int(x[j]), int(y[j])), 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Write the frame to the output video\n",
    "            out.write(frame)\n",
    "    finally:\n",
    "        # Release the video capture and writer objects\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_clip(Video, tracks, 1000, int(1020*29), \"output.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
