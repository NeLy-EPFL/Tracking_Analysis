{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "import more_itertools as mit\n",
    "from pathlib import Path\n",
    "import os\n",
    "from scipy import signal\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "\n",
    "hv.extension(\n",
    "    \"bokeh\",\n",
    "    #'matplotlib',\n",
    ")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the process on one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the frame using opencv\n",
    "\n",
    "frame = cv2.imread(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Feeding_state/230704_FeedingState_1_AM/image0.jpg\"\n",
    ")\n",
    "\n",
    "# make it grayscale\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# display the frame\n",
    "plt.figure()\n",
    "plt.imshow(frame, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate the image 90 degrees\n",
    "# frame = np.rot90(frame)\n",
    "\n",
    "# display the frame\n",
    "plt.figure()\n",
    "plt.imshow(frame, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def generate_subsets(image_path, regions):\n",
    "    \"\"\"\n",
    "    :param image_path: str, path to the image\n",
    "    :param regions: list of tuples, each tuple contains 4 integers representing the coordinates of the region of interest in the form (left, upper, right, lower)\n",
    "    :return: list of Image objects, each representing a subset of the main image\n",
    "    \"\"\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # rotate the image 90 degrees\n",
    "    image = image.rotate(90, expand=True)\n",
    "\n",
    "    subsets = []\n",
    "    for region in regions:\n",
    "        subset = image.crop(region)\n",
    "        subsets.append(subset)\n",
    "    return subsets\n",
    "\n",
    "\n",
    "# Example usage\n",
    "regions_of_interest = [\n",
    "    (0, 0, 850, 1000),\n",
    "    (850, 0, 1900, 1000),\n",
    "    (1900, 0, 2800, 1000),\n",
    "    (0, 1000, 850, 2350),\n",
    "    (850, 1000, 1900, 2350),\n",
    "    (1900, 850, 2800, 2350),\n",
    "    (0, 2350, 850, 3400),\n",
    "    (850, 2350, 1900, 3400),\n",
    "    (1900, 2350, 2800, 3400),\n",
    "]\n",
    "subsets = generate_subsets(\n",
    "    \"/home/matthias/Videos/Test2/image0.jpg\", regions_of_interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the subsets in a grid\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(subsets[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a copy of the first subset as numpy array\n",
    "subset = np.array(subsets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = subset.sum(axis=0)\n",
    "\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=40,\n",
    "    # height=(50_000, 150_000),\n",
    "    # width=(10, 100),\n",
    "    prominence=(20_000, 150_000),\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(cols)))\n",
    "PeaksPos = (x[peaks[0]], cols[peaks[0]])\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"]) * hv.Points(PeaksPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but with another subset\n",
    "subset = np.array(subsets[5])\n",
    "\n",
    "cols = subset.sum(axis=0)\n",
    "\n",
    "\n",
    "peaks = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=40,\n",
    "    height=(50_000, 300_000),\n",
    "    # width=(10, 100),\n",
    "    prominence=(20_000, 400_000),\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(cols)))\n",
    "PeaksPos = (x[peaks[0]], cols[peaks[0]])\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"]) * hv.Points(PeaksPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subset, find the peaks and store their positions in a list\n",
    "Arenapos = []\n",
    "for subset in subsets:\n",
    "    subset = np.array(subset)\n",
    "\n",
    "    cols = subset.sum(axis=0)\n",
    "\n",
    "    peaks = signal.find_peaks(\n",
    "        cols,\n",
    "        distance=40,\n",
    "        height=(50_000, 300_000),\n",
    "        prominence=(20_000, 400_000),\n",
    "    )\n",
    "    x = np.array(range(0, len(cols)))\n",
    "    Arenapos.append(x[peaks[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arenapos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arenapos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cropping on a subset\n",
    "ArenaList = []\n",
    "\n",
    "sub = Arenapos[2]\n",
    "for i in range(0, len(sub)):\n",
    "    # if (i % 2) == 0:\n",
    "    ArenaList.append(list(range(sub[i] - 45, sub[i] + 45)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Visual test if crop was successful\n",
    "\n",
    "# convert subsets[0] to numpy array\n",
    "testarray = np.array(subsets[2])\n",
    "plt.imshow(testarray[:, ArenaList[2]], cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect vertical bounds\n",
    "subset = np.array(subsets[4])\n",
    "\n",
    "rows = subset.sum(axis=1)\n",
    "\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the subset with only the rows where rows < 150_000\n",
    "plt.imshow(subset[rows < 150_000], cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(subset, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That won't work because of the array heterogeneity. I need to crop the arenas properly right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprocess the first frame\n",
    "cols = frame.sum(axis=0)\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = frame.sum(axis=1)\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=1000,\n",
    "    height=(200_000, 600_000),\n",
    "    # width=(10, 100),\n",
    "    # prominence=(20_000, 150_000),\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(cols)))\n",
    "PeaksPos = (x[peaks[0]], cols[peaks[0]])\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"]) * hv.Points(PeaksPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"/home/matthias/Videos/Test2/image0.jpg\")\n",
    "\n",
    "# make it grayscale\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# equalize the histogram to make thresholding easier\n",
    "frame = cv2.equalizeHist(frame)\n",
    "\n",
    "# rotate the image 90 degrees\n",
    "frame = np.rot90(frame)\n",
    "\n",
    "# display the frame\n",
    "plt.figure()\n",
    "plt.imshow(frame, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thresh = frame.copy()\n",
    "# Apply a threshold to the frame to keep only the pixels with a value < 20\n",
    "Thresh[Thresh > 60] = 0\n",
    "# For the pixels with a value < 20, set their value to 255\n",
    "Thresh[Thresh > 0] = 255\n",
    "# display the frame\n",
    "plt.imshow(Thresh, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = Thresh.sum(axis=0)\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = Thresh.sum(axis=1)\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colbounds = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=200,\n",
    "    height=(300_000, 700_000),\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(cols)))\n",
    "ColBoundsPos = (x[colbounds[0]], cols[colbounds[0]])\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"]) * hv.Points(ColBoundsPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowbounds = signal.find_peaks(\n",
    "    rows,\n",
    "    distance=200,\n",
    "    height=(300_000, 700_000),\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(rows)))\n",
    "RowBoundsPos = (x[rowbounds[0]], rows[rowbounds[0]])\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"]) * hv.Points(RowBoundsPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsets(image, regions):\n",
    "    \"\"\"\n",
    "    :param image_path: str, path to the image\n",
    "    :param regions: list of tuples, each tuple contains 4 integers representing the coordinates of the region of interest in the form (left, upper, right, lower)\n",
    "    :return: list of numpy arrays, each representing a subset of the main image\n",
    "    \"\"\"\n",
    "    subsets = []\n",
    "    for region in regions:\n",
    "        subset = image[region[1] : region[3], region[0] : region[2]]\n",
    "        subsets.append(subset)\n",
    "    return regions\n",
    "\n",
    "\n",
    "# Example usage\n",
    "xcoords = colbounds[0]\n",
    "ycoords = rowbounds[0]\n",
    "\n",
    "regions_of_interest = [\n",
    "    (xcoords[0], ycoords[0], xcoords[1], ycoords[1]),\n",
    "    (xcoords[2], ycoords[0], xcoords[3], ycoords[1]),\n",
    "    (xcoords[4], ycoords[0], xcoords[5], ycoords[1]),\n",
    "    (xcoords[0], ycoords[2], xcoords[1], ycoords[3]),\n",
    "    (xcoords[2], ycoords[2], xcoords[3], ycoords[3]),\n",
    "    (xcoords[4], ycoords[2], xcoords[5], ycoords[3]),\n",
    "    (xcoords[0], ycoords[4], xcoords[1], ycoords[5]),\n",
    "    (xcoords[2], ycoords[4], xcoords[3], ycoords[5]),\n",
    "    (xcoords[4], ycoords[4], xcoords[5], ycoords[5]),\n",
    "]\n",
    "subsets = generate_subsets(frame, regions_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt just keeping regions\n",
    "\n",
    "regions_of_interest = [\n",
    "    (xcoords[0], ycoords[0], xcoords[1], ycoords[1]),\n",
    "    (xcoords[2], ycoords[0], xcoords[3], ycoords[1]),\n",
    "    (xcoords[4], ycoords[0], xcoords[5], ycoords[1]),\n",
    "    (xcoords[0], ycoords[2], xcoords[1], ycoords[3]),\n",
    "    (xcoords[2], ycoords[2], xcoords[3], ycoords[3]),\n",
    "    (xcoords[4], ycoords[2], xcoords[5], ycoords[3]),\n",
    "    (xcoords[0], ycoords[4], xcoords[1], ycoords[5]),\n",
    "    (xcoords[2], ycoords[4], xcoords[3], ycoords[5]),\n",
    "    (xcoords[4], ycoords[4], xcoords[5], ycoords[5]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the subsets in a grid\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(subsets[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt using the regions\n",
    "\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(\n",
    "        frame[\n",
    "            regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "            regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "        ],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is perfect ! I can now crop the arenas properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subset, find the peaks and store their positions in a list\n",
    "Arenapos = []\n",
    "for subset in subsets:\n",
    "    subset = np.array(subset)\n",
    "\n",
    "    cols = subset.sum(axis=0)\n",
    "\n",
    "    peaks = signal.find_peaks(\n",
    "        cols,\n",
    "        distance=40,\n",
    "        height=(50_000, 300_000),\n",
    "        prominence=(20_000, 400_000),\n",
    "    )\n",
    "    x = np.array(range(0, len(cols)))\n",
    "    Arenapos.append(x[peaks[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArenaList = []\n",
    "\n",
    "sub = Arenapos[2]\n",
    "for i in range(0, len(sub)):\n",
    "    # if (i % 2) == 0:\n",
    "    ArenaList.append(list(range(sub[i] - 40, sub[i] + 40)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "testarray = np.array(subsets[0])\n",
    "# Reset plt and display only the next plot\n",
    "plt.clf()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testarray[:, ArenaList[1]], cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not ideal, what if I just apply the same method as done for the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Test with one subset\n",
    "testarray = np.array(subsets[3])\n",
    "\n",
    "Thresh = testarray.copy()\n",
    "# Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "Thresh = cv2.adaptiveThreshold(\n",
    "    Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    ")\n",
    "\n",
    "# display the frame\n",
    "\n",
    "plt.imshow(Thresh, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with the regions of interest\n",
    "\n",
    "testarray = np.array(\n",
    "    frame[\n",
    "        regions_of_interest[3][1] : regions_of_interest[3][3],\n",
    "        regions_of_interest[3][0] : regions_of_interest[3][2],\n",
    "    ]\n",
    ")\n",
    "\n",
    "Thresh = testarray.copy()\n",
    "# Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "Thresh = cv2.adaptiveThreshold(\n",
    "    Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    ")\n",
    "\n",
    "# display the frame\n",
    "\n",
    "plt.imshow(Thresh, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cols = Thresh.sum(axis=0)\n",
    "plt.plot(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cols[100:620])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect peaks in the histogram of the subset\n",
    "peaks = signal.find_peaks(\n",
    "    cols[100:620],\n",
    "    distance=20,\n",
    "    height=(60_000, 120_000),\n",
    "    # width=(2, 30),\n",
    "    # prominence=(20_000, 400_000),\n",
    "    # limit the x axis to the middle of the subset\n",
    ")\n",
    "\n",
    "# Add 100 to the x coordinates of the peaks to account for the offset\n",
    "peaks = (peaks[0] + 100, peaks[1])\n",
    "\n",
    "\n",
    "# plot cols with peaks points\n",
    "x = np.array(range(0, len(cols)))\n",
    "plt.plot(x, cols)\n",
    "plt.plot(x[peaks[0]], cols[peaks[0]], \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = testarray.sum(axis=1)\n",
    "plt.plot(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect peaks in the histogram of the subset\n",
    "peaks = signal.find_peaks(\n",
    "    row,\n",
    "    distance=300,\n",
    "    # height=(60_000, 100_000),\n",
    "    # prominence=(20_000, 400_000),\n",
    ")\n",
    "\n",
    "# plot cols with peaks points\n",
    "x = np.array(range(0, len(row)))\n",
    "plt.plot(x, row)\n",
    "plt.plot(x[peaks[0]], row[peaks[0]], \"x\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example worked fine. Now I'll apply it to all the subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each subset, find the cols and rows peaks and store the even peaks in a list\n",
    "Corridors = []\n",
    "for i in range(len(regions_of_interest)):\n",
    "    subset = np.array(\n",
    "        frame[\n",
    "            regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "            regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "        ]\n",
    "    )\n",
    "    Thresh = subset.copy()\n",
    "    # Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "    Thresh = cv2.adaptiveThreshold(\n",
    "        Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    "    )\n",
    "\n",
    "    cols = Thresh.sum(axis=0)\n",
    "    rows = subset.sum(axis=1)\n",
    "\n",
    "    colpeaks = signal.find_peaks(\n",
    "        cols[100:620],\n",
    "        distance=20,\n",
    "        height=(60_000, 120_000),\n",
    "        # width=(5, 30),\n",
    "    )\n",
    "    colpeaks = (colpeaks[0] + 100, colpeaks[1])\n",
    "\n",
    "    rowpeaks = signal.find_peaks(\n",
    "        rows,\n",
    "        distance=300,\n",
    "    )\n",
    "    #######################################################\n",
    "    Colpos = []\n",
    "    Rowpos = []\n",
    "\n",
    "    for peak_index in colpeaks[0]:\n",
    "        peak_x = regions_of_interest[i][0] + peak_index\n",
    "        peak_y = np.argmax(subset[peak_index])\n",
    "        peak_y += regions_of_interest[i][1]\n",
    "        Colpos.append((peak_x, peak_y))\n",
    "\n",
    "    for peak_index in rowpeaks[0]:\n",
    "        peak_x = np.argmax(subset[peak_index])\n",
    "        peak_x += regions_of_interest[i][0]\n",
    "        peak_y = regions_of_interest[i][1] + peak_index\n",
    "        Rowpos.append((peak_x, peak_y))\n",
    "\n",
    "    bound_x = 30\n",
    "    bound_y = 50\n",
    "\n",
    "    subcors = [\n",
    "        (\n",
    "            Colpos[0][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[1][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[2][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[3][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[4][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[5][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[6][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[7][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[8][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[9][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[10][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[11][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # subcors = generate_subsets(subset, regions_of_interest)\n",
    "\n",
    "    Corridors.append(subcors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_detection(image, regions):\n",
    "    peaks = []\n",
    "    for region in regions:\n",
    "        x1, y1, x2, y2 = region\n",
    "        sub_image = image[y1:y2, x1:x2]\n",
    "        peak_indices = find_peaks(sub_image)\n",
    "        for peak_index in peak_indices[0]:\n",
    "            peak_x = x1 + peak_index\n",
    "            peak_y = np.argmax(sub_image[peak_index])\n",
    "            peak_y += y1\n",
    "            peaks.append((peak_x, peak_y))\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the corridors from all subsets in a grid\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(Corridors[4][i], cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corridors coordinates, we can us them to write the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the corridors from Corridors[0] in a grid based on the frame\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(\n",
    "        frame[\n",
    "            Corridors[0][i][1] : Corridors[0][i][3],\n",
    "            Corridors[0][i][0] : Corridors[0][i][2],\n",
    "        ],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame[Corridors[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new directory for each corridor in each subset\n",
    "# frame\n",
    "# for i, subset in enumerate(Corridors):\n",
    "#     for j, corridor in enumerate(subset):\n",
    "#         os.makedirs(\n",
    "#             f\"/home/matthias/Videos/Test2_subsets/arena{i+1}/corridor_{j+1}\", exist_ok=True\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         cv2.imwrite(\n",
    "#             f\"/home/matthias/Videos/Test2_subsets/arena{i+1}/corridor_{j+1}/corridor_{j}.png\",\n",
    "#             corridor,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the same process but looping through all images in the Test2 folder\n",
    "\n",
    "# Create a list of all the images in the Test2 folder\n",
    "images = []\n",
    "for filename in os.listdir(\"/home/matthias/Videos/Test2\"):\n",
    "    images.append(filename)\n",
    "\n",
    "# sort the list of images by their number\n",
    "images.sort(key=lambda f: int(re.sub(\"\\D\", \"\", f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each image, find the corridors and save them in the corresponding folder\n",
    "# for i, image in enumerate(images):\n",
    "#     frame = cv2.imread(f\"/home/matthias/Videos/Test2/{image}\")\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     frame = np.rot90(frame)\n",
    "\n",
    "#     for j, subset in enumerate(Corridors):\n",
    "#         for k, corridor in enumerate(subset):\n",
    "#             os.makedirs(\n",
    "#                 f\"/home/matthias/Videos/Test2_subsets/arena{j+1}/corridor_{k+1}\",\n",
    "#                 exist_ok=True,\n",
    "#             )\n",
    "#             cv2.imwrite(\n",
    "#                 f\"/home/matthias/Videos/Test2_subsets/arena{j+1}/corridor_{k+1}/{image}\",\n",
    "#                 corridor,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same version but with a progress bar\n",
    "\n",
    "# for i, image in tqdm(enumerate(images), total=len(images)):\n",
    "#     frame = cv2.imread(f\"/home/matthias/Videos/Test2/{image}\")\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     frame = np.rot90(frame)\n",
    "\n",
    "#     for j, subset in enumerate(Corridors):\n",
    "#         for k, corridor in enumerate(subset):\n",
    "#             os.makedirs(\n",
    "#                 f\"/home/matthias/Videos/Test2_subsets/arena{j+1}/corridor_{k+1}\",\n",
    "#                 exist_ok=True,\n",
    "#             )\n",
    "#             # Write the image corresponding to the crop of the current frame\n",
    "#             cv2.imwrite(\n",
    "#                 f\"/home/matthias/Videos/Test2_subsets/arena{j+1}/corridor_{k+1}/{image}\",\n",
    "#                 corridor,\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in tqdm(enumerate(images), total=len(images)):\n",
    "    frame = cv2.imread(f\"/home/matthias/Videos/Test2/{image}\")\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = np.rot90(frame)\n",
    "\n",
    "    for j, subset in enumerate(Corridors):\n",
    "        for k, corridor in enumerate(subset):\n",
    "            # Create the subfolder if it doesn't exist\n",
    "            subfolder = f\"/home/matthias/Videos/Test2_subsets/arena{j+1}/corridor_{k+1}\"\n",
    "            os.makedirs(subfolder, exist_ok=True)\n",
    "\n",
    "            # Crop the image\n",
    "            x1, y1, x2, y2 = corridor\n",
    "            cropped_image = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Save the cropped image\n",
    "            cropped_image_file = f\"{os.path.splitext(image)[0]}_cropped.jpg\"\n",
    "            cv2.imwrite(os.path.join(subfolder, cropped_image_file), cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the root folder containing the subfolders\n",
    "root_folder = Path(\"/home/matthias/Videos/Test2_subsets\")\n",
    "\n",
    "# define the path to the output 'videos' folder\n",
    "videos_folder = Path(\"/home/matthias/Videos/Test2_subsets/Videos\")\n",
    "videos_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define the output video parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # video codec\n",
    "fps = 30  # frames per second\n",
    "\n",
    "# iterate over the subfolders that are one level below the root folder\n",
    "for subdir in root_folder.glob(\"*/*\"):\n",
    "    if not subdir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # read the first image in the subfolder to determine the frame size\n",
    "    first_image = cv2.imread(str(list(subdir.glob(\"*\"))[0]))\n",
    "    height, width, _ = first_image.shape\n",
    "    frame_size = (width, height)\n",
    "\n",
    "    # generate the output video filename from the folder and subfolder names\n",
    "    relative_path = subdir.relative_to(root_folder)\n",
    "    video_filename = videos_folder / f\"{relative_path}.mp4\"\n",
    "    \n",
    "    print(video_filename)\n",
    "\n",
    "    # open a VideoWriter object for the current subfolder\n",
    "    out = cv2.VideoWriter(str(video_filename), fourcc, fps, frame_size)\n",
    "\n",
    "    # iterate over the images in the current subfolder\n",
    "    for filename in tqdm(sorted(subdir.glob(\"*\")), desc=str(subdir)):\n",
    "        # read the image\n",
    "        image = cv2.imread(str(filename))\n",
    "\n",
    "        # convert the image from BGR to RGB color space\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # write the image to the video\n",
    "        out.write(image)\n",
    "\n",
    "    # release the VideoWriter object\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# define the path to the root folder containing the subfolders\n",
    "root_folder = Path(\"/home/matthias/Videos/Test2_subsets\")\n",
    "\n",
    "# define the path to the output 'videos' folder\n",
    "videos_folder = Path(\"/home/matthias/Videos/Test2_Videos/Videos_NumOrdered\")\n",
    "videos_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define the output video parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # video codec\n",
    "fps = 30  # frames per second\n",
    "\n",
    "# create a progress bar for the whole process\n",
    "pbar = tqdm(total=len(list(root_folder.glob(\"*/*\"))))\n",
    "\n",
    "\n",
    "def sort_by_number(filename):\n",
    "    # extract the number from the filename using a regular expression\n",
    "    number = re.search(r\"\\d+\", filename.name)\n",
    "    if number:\n",
    "        return int(number.group())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# iterate over the subfolders that are one level below the root folder\n",
    "for subdir in root_folder.glob(\"*/*\"):\n",
    "    if not subdir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # read the first image in the subfolder to determine the frame size\n",
    "    first_image_path = list(subdir.glob(\"*\"))[0]\n",
    "    first_image = cv2.imread(str(first_image_path))\n",
    "    if first_image is None:\n",
    "        print(f\"Error: Failed to read image {first_image_path}\")\n",
    "        continue\n",
    "\n",
    "    height, width, _ = first_image.shape\n",
    "    frame_size = (width, height)\n",
    "\n",
    "    # generate a unique output video filename from the subfolder name\n",
    "    video_filename = videos_folder / f\"{subdir.parent.name}_{subdir.name}.mp4\"\n",
    "\n",
    "    # open a VideoWriter object for the current subfolder\n",
    "    out = cv2.VideoWriter(str(video_filename), fourcc, fps, frame_size)\n",
    "\n",
    "    # iterate over the images in the current subfolder sorted by number\n",
    "    for filename in sorted(subdir.glob(\"*\"), key=sort_by_number):\n",
    "        # read the image\n",
    "        image = cv2.imread(str(filename))\n",
    "        if image is None:\n",
    "            print(f\"Error: Failed to read image {filename}\")\n",
    "            continue\n",
    "\n",
    "        # convert the image from BGR to RGB color space (if necessary)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # write the image to the video\n",
    "        out.write(image)\n",
    "\n",
    "    # release the VideoWriter object\n",
    "    out.release()\n",
    "\n",
    "    # update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try alternative method by writing videos with ffmpeg\n",
    "\n",
    "# define the path to the root folder containing the subfolders\n",
    "root_folder = Path(\"/home/matthias/Videos/Test2_subsets\")\n",
    "\n",
    "# define the path to the output 'videos' folder\n",
    "videos_folder = Path(\"/home/matthias/Videos/Test2_subsets/Videos_ffmpeg\")\n",
    "videos_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create a progress bar for the whole process\n",
    "pbar = tqdm(total=len(list(root_folder.glob(\"*/*\"))))\n",
    "# iterate over the subfolders that are one level below the root folder\n",
    "for subdir in root_folder.glob(\"*/*\"):\n",
    "    if not subdir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # generate a unique output video filename from the subfolder name\n",
    "    video_filename = videos_folder / f\"{subdir.name}.mp4\"\n",
    "\n",
    "    # generate the ffmpeg command\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",  # overwrite output files without asking\n",
    "        \"-framerate\",\n",
    "        \"30\",  # input frame rate\n",
    "        \"-pattern_type\",\n",
    "        \"glob\",  # use the glob pattern type\n",
    "        \"-i\",\n",
    "        f\"{subdir}/*.jpg\",  # input file pattern\n",
    "        \"-c:v\",\n",
    "        \"libx264\",  # use the h264 codec\n",
    "        \"-pix_fmt\",\n",
    "        \"yuv420p\",  # output pixel format\n",
    "        \"-crf\",\n",
    "        \"17\",  # constant rate factor\n",
    "        \"-vf\",\n",
    "        \"pad=ceil(iw/2)*2:ceil(ih/2)*2\",  # make the frame dimensions even\n",
    "        str(video_filename),  # output video filename\n",
    "    ]\n",
    "\n",
    "    # run the ffmpeg command\n",
    "    subprocess.run(command)\n",
    "\n",
    "    # update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# define the path to the input 'videos' folder\n",
    "videos_folder = \"/home/matthias/Videos/Test2_Videos/Videos_NumOrdered\"\n",
    "\n",
    "# define the path to the output 'grid' video\n",
    "grid_video_filename = \"/home/matthias/Videos/Test2_Videos/grid_video.mp4\"\n",
    "\n",
    "# define the output video parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # video codec\n",
    "fps = 30  # frames per second\n",
    "\n",
    "# define the grid size (number of rows and columns)\n",
    "grid_rows = 6\n",
    "grid_cols = 9\n",
    "\n",
    "# initialize a list to store the VideoCapture objects for each input video\n",
    "video_captures = []\n",
    "\n",
    "# open all of the input videos and store their VideoCapture objects in the list\n",
    "for y in range(1, grid_rows + 1):\n",
    "    for x in range(1, grid_cols + 1):\n",
    "        video_filename = f\"{videos_folder}/arena{x}_corridor_{y}.mp4\"\n",
    "        cap = cv2.VideoCapture(video_filename)\n",
    "        video_captures.append(cap)\n",
    "\n",
    "# read the first frame from the first video to determine the frame size\n",
    "ret, first_frame = video_captures[0].read()\n",
    "if not ret:\n",
    "    print(\"Error: Failed to read first frame from first video\")\n",
    "else:\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # calculate the size of the grid frame\n",
    "    grid_frame_width = width * grid_cols\n",
    "    grid_frame_height = height * grid_rows\n",
    "    grid_frame_size = (grid_frame_width, grid_frame_height)\n",
    "\n",
    "    # open a VideoWriter object for the output grid video\n",
    "    out = cv2.VideoWriter(grid_video_filename, fourcc, fps, grid_frame_size)\n",
    "\n",
    "    # initialize a variable to keep track of whether all videos have ended\n",
    "    all_videos_ended = False\n",
    "\n",
    "    # loop until all videos have ended\n",
    "    while not all_videos_ended:\n",
    "        # initialize an empty list to store the current frame from each video\n",
    "        frames = []\n",
    "\n",
    "        # read the current frame from each video\n",
    "        for cap in video_captures:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # resize the frame to the common size if necessary\n",
    "                if frame.shape[:2] != (height, width):\n",
    "                    frame = cv2.resize(frame, (width, height))\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                # if the video has ended, append a black frame\n",
    "                black_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "                frames.append(black_frame)\n",
    "\n",
    "        # check if all videos have ended\n",
    "        all_videos_ended = all(not cap.isOpened() for cap in video_captures)\n",
    "\n",
    "        # create an empty grid frame\n",
    "        grid_frame = np.zeros((grid_frame_height, grid_frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "        # copy each frame into its position in the grid frame\n",
    "        for i, frame in enumerate(frames):\n",
    "            row = i // grid_cols\n",
    "            col = i % grid_cols\n",
    "            x_start = col * width\n",
    "            x_end = x_start + width\n",
    "            y_start = row * height\n",
    "            y_end = y_start + height\n",
    "            grid_frame[y_start:y_end, x_start:x_end] = frame\n",
    "\n",
    "        # write the grid frame to the output video\n",
    "        out.write(grid_frame)\n",
    "\n",
    "    # release all of the VideoCapture objects and the VideoWriter object\n",
    "    for cap in video_captures:\n",
    "        cap.release()\n",
    "    out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
