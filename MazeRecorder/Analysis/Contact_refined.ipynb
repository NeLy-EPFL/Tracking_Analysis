{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_behavior\n",
    "\n",
    "from utils_behavior import Ballpushing_utils\n",
    "from utils_behavior import Utils\n",
    "from utils_behavior import Processing\n",
    "from utils_behavior import HoloviewsTemplates\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "#import pyarrow.feather as feather\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import importlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the data\n",
    "\n",
    "Datapath = Utils.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find folders with \"Learning or learning\" in the name as a list\n",
    "\n",
    "folders = [f for f in Datapath.glob(\"*FeedingState*\")]\n",
    "\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first \n",
    "\n",
    "exp = Ballpushing_utils.Experiment(folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Ballpushing_utils.Dataset(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_data = Dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compute the euclidean distance between the fly and the ball during events\n",
    "\n",
    "exfly = ball_data.loc[ball_data[\"fly\"] == ball_data[\"fly\"].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exfly[\"adjusted_frame\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each event, compute the distance between the fly and the ball\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    event_data = exfly.loc[exfly[\"interaction_event\"] == event]\n",
    "    event_data = event_data.sort_values(\"frame\")\n",
    "    event_data[\"distance\"] = np.sqrt(\n",
    "        (event_data[\"x_ball_0\"] - event_data[\"x_fly_0\"]) ** 2\n",
    "        + (event_data[\"y_ball_0\"] - event_data[\"y_fly_0\"]) ** 2\n",
    "    )\n",
    "    \n",
    "    # Add an \"adjusted_frame\" column that starts at 0 and goes up to the length of the event\n",
    "    event_data[\"adjusted_frame\"] = range(len(event_data))\n",
    "\n",
    "    # Assign the computed columns back to the original DataFrame\n",
    "    exfly.loc[exfly[\"interaction_event\"] == event, \"distance\"] = event_data[\"distance\"]\n",
    "    exfly.loc[exfly[\"interaction_event\"] == event, \"adjusted_frame\"] = event_data[\"adjusted_frame\"]\n",
    "\n",
    "print(exfly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exfly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find first minimum distance for each event\n",
    "min_distance = exfly.groupby(\"interaction_event\")[\"distance\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out NaN values from interaction_event\n",
    "exfly = exfly.dropna(subset=['interaction_event'])\n",
    "\n",
    "# Rest of your preprocessing code...\n",
    "\n",
    "# Find first minimum distance for each event\n",
    "min_distance = exfly.groupby(\"interaction_event\")[\"distance\"].idxmin()\n",
    "\n",
    "# Create a grid\n",
    "grid = sns.FacetGrid(exfly, col=\"interaction_event\", col_wrap=4)\n",
    "\n",
    "# Plot the distance for each event\n",
    "grid.map(plt.plot, \"adjusted_frame\", \"distance\")\n",
    "\n",
    "# Add markers for the minimum distance points\n",
    "for ax, event in zip(grid.axes.flat, exfly[\"interaction_event\"].unique()):\n",
    "    try:\n",
    "        min_idx = min_distance[event]\n",
    "        min_point = exfly.loc[min_idx]\n",
    "        ax.plot(min_point[\"adjusted_frame\"], min_point[\"distance\"], 'ro')\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No minimum distance found for event {event}\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250218_Refined_contacts/events_distance_withmarkers_shortevents_New.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exfly[\"interaction_event\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "def find_interaction_start(data, distance_col, frame_col, \n",
    "                          threshold_multiplier=1.5, window_size=30, \n",
    "                          min_plateau_length=50, peak_prominence=1,\n",
    "                          peak_window_size=10):\n",
    "    # Work on a copy to avoid modifying original data\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Smoothing and derivative calculation\n",
    "    data['smoothed_distance'] = savgol_filter(data[distance_col], \n",
    "                                            window_length=11, \n",
    "                                            polyorder=3)\n",
    "    data['smoothed_diff'] = data['smoothed_distance'].diff()\n",
    "    data['smoothed_accel'] = data['smoothed_diff'].diff()  # Second derivative\n",
    "\n",
    "    # Dynamic threshold for plateaus based on rolling standard deviation\n",
    "    rolling_std = data['smoothed_diff'].rolling(window=window_size).std()\n",
    "    dynamic_threshold = rolling_std.mean() * threshold_multiplier  # Adjust multiplier as needed\n",
    "\n",
    "    # Plateau detection with dynamic threshold\n",
    "    plateau_mask = (data['smoothed_diff'].abs() < dynamic_threshold)\n",
    "    plateau_groups = (plateau_mask != plateau_mask.shift()).cumsum()\n",
    "    \n",
    "    # Initialize plateau markers\n",
    "    data['plateau_start'] = 0\n",
    "    valid_plateaus = data[plateau_mask].groupby(plateau_groups).filter(\n",
    "        lambda x: len(x) >= min_plateau_length\n",
    "    )\n",
    "    if not valid_plateaus.empty:\n",
    "        start_indices = valid_plateaus.groupby(plateau_groups).head(1).index\n",
    "        data.loc[start_indices, 'plateau_start'] = 1\n",
    "\n",
    "    # Peak detection with stricter prominence\n",
    "    peaks, _ = find_peaks(-data['smoothed_distance'],\n",
    "                        prominence=peak_prominence,\n",
    "                        width=3)\n",
    "    \n",
    "    # Refine peak detection for better alignment\n",
    "    refined_peaks = []\n",
    "    for peak in peaks:\n",
    "        if peak > 0 and peak < len(data) - 1:\n",
    "            # Perform local search around the detected peak to refine position\n",
    "            local_region = data.iloc[max(0, peak - peak_window_size):min(len(data), peak + peak_window_size)]\n",
    "            true_peak_idx = local_region[distance_col].idxmin()  # Find true minimum in this region\n",
    "            refined_peaks.append(true_peak_idx)\n",
    "\n",
    "    # Combine plateau and refined peak detections\n",
    "    plateau_indices = data[data['plateau_start'] == 1].index\n",
    "    all_candidates = sorted(list(plateau_indices) + refined_peaks)\n",
    "    \n",
    "    # Fallback to minimum distance if no markers found\n",
    "    if not all_candidates:\n",
    "        return data[distance_col].idxmin()\n",
    "    \n",
    "    return all_candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert interaction_event to integer sequence first\n",
    "exfly['interaction_event'] = exfly['interaction_event'].astype(int)\n",
    "\n",
    "# Filter out NaN values from interaction_event\n",
    "exfly = exfly.dropna(subset=['interaction_event'])\n",
    "\n",
    "# Find first minimum distance and plateau/peak for each event\n",
    "min_distance = exfly.groupby(\"interaction_event\")[\"distance\"].idxmin()\n",
    "plateau_or_peak = exfly.groupby(\"interaction_event\").apply(\n",
    "    lambda x: find_interaction_start(x, 'distance', 'adjusted_frame',\n",
    "                                    )\n",
    ")\n",
    "\n",
    "# Create a grid\n",
    "grid = sns.FacetGrid(exfly, col=\"interaction_event\", col_wrap=4)\n",
    "\n",
    "# Plot the distance for each event\n",
    "grid.map(plt.plot, \"adjusted_frame\", \"distance\")\n",
    "\n",
    "# Add markers for the minimum distance points and plateau/peak points\n",
    "for ax, event in zip(grid.axes.flat, exfly[\"interaction_event\"].unique()):\n",
    "    try:\n",
    "        # Plot minimum distance point\n",
    "        min_idx = min_distance[event]\n",
    "        min_point = exfly.loc[min_idx]\n",
    "        ax.plot(min_point[\"adjusted_frame\"], min_point[\"distance\"], 'ro', label='Minimum')\n",
    "        \n",
    "        # Plot plateau/peak point\n",
    "        plateau_peak_idx = plateau_or_peak[event]\n",
    "        plateau_peak_point = exfly.loc[plateau_peak_idx]\n",
    "        ax.plot(plateau_peak_point[\"adjusted_frame\"], plateau_peak_point[\"distance\"], 'go', label='Plateau/Peak')\n",
    "        #ax.set_xlim(plateau_peak_point[\"adjusted_frame\"] - 20, plateau_peak_point[\"adjusted_frame\"] + 20)\n",
    "        \n",
    "        ax.legend()\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No data found for event {event}\")\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250218_Refined_contacts/events_distance_withmarkers_and_plateaus_New.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the video\n",
    "flypath = exfly[\"flypath\"].iloc[0]\n",
    "# Find the mp4 file in the folder\n",
    "video_folder = Path(flypath)\n",
    "video_files = list(video_folder.glob(\"*.mp4\"))\n",
    "\n",
    "video_path = video_files[0]\n",
    "print(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "# Check if the video is opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Store frames in a list\n",
    "frames = []\n",
    "\n",
    "# For each event, get the frame corresponding to the detected start point\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    # Get the start point for the event\n",
    "    start_point = exfly.loc[plateau_or_peak[event]]\n",
    "    \n",
    "    # Set the frame number to the start point\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_point[\"frame\"])\n",
    "    \n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read correctly\n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame for event {event}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the frame from BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Append the frame to the list\n",
    "    frames.append((event, frame))\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Plot the frames in a grid\n",
    "n_frames = len(frames)\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(n_frames / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "\n",
    "for i, (event, frame) in enumerate(frames):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(f\"Event: {event}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the video\n",
    "flypath = exfly[\"flypath\"].iloc[0]\n",
    "# Find the mp4 file in the folder\n",
    "video_folder = Path(flypath)\n",
    "video_files = list(video_folder.glob(\"*.mp4\"))\n",
    "\n",
    "if not video_files:\n",
    "    print(\"Error: No mp4 files found in the folder\")\n",
    "    sys.exit(1)\n",
    "\n",
    "video_path = video_files[0]\n",
    "print(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "# Check if the video is opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Parameters\n",
    "fps = 5\n",
    "frames_before = 20\n",
    "frames_after = 20\n",
    "total_frames = frames_before + frames_after + 1\n",
    "output_width = 3840\n",
    "output_height = 2160\n",
    "\n",
    "# Store frames in a dictionary\n",
    "frames_dict = {event: [] for event in exfly[\"interaction_event\"].unique()}\n",
    "\n",
    "# For each event, get the frames around the detected start point\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    # Get the start point for the event\n",
    "    start_point = exfly.loc[plateau_or_peak[event]][\"frame\"]\n",
    "    \n",
    "    for i in range(-frames_before, frames_after + 1):\n",
    "        frame_number = start_point + i\n",
    "        # Set the frame number\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Check if the frame is read correctly\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {frame_number} for event {event}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert the frame from BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Append the frame to the list\n",
    "        frames_dict[event].append(frame)\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Create a video writer\n",
    "output_video_path = \"grid_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "frame_height, frame_width, _ = next(iter(frames_dict.values()))[0].shape\n",
    "# Parameters (adjust as needed)\n",
    "# Modify the grid calculation section with this optimized version\n",
    "n_events = len(frames_dict)\n",
    "frame_height, frame_width, _ = next(iter(frames_dict.values()))[0].shape\n",
    "aspect_ratio = frame_width / frame_height\n",
    "\n",
    "# Calculate optimal grid dimensions for 16:9\n",
    "target_aspect = 16/9\n",
    "approx_cols = np.sqrt((target_aspect / aspect_ratio) * n_events)\n",
    "candidates = [int(np.floor(approx_cols)), int(np.ceil(approx_cols)), int(round(approx_cols))]\n",
    "candidates = np.unique(np.clip(candidates, 1, n_events))\n",
    "\n",
    "best_cols = 1\n",
    "best_error = float('inf')\n",
    "\n",
    "for cols in candidates:\n",
    "    rows = np.ceil(n_events / cols).astype(int)\n",
    "    grid_ar = (cols * aspect_ratio) / rows  # Combined grid aspect ratio\n",
    "    error = abs(grid_ar - target_aspect)\n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_cols = cols\n",
    "\n",
    "n_cols = best_cols\n",
    "n_rows = np.ceil(n_events / n_cols).astype(int)\n",
    "\n",
    "# Set output resolution to 4K\n",
    "output_width = 3840\n",
    "output_height = 2160\n",
    "\n",
    "# Calculate grid dimensions\n",
    "grid_width = frame_width * n_cols\n",
    "grid_height = frame_height * n_rows\n",
    "\n",
    "# Maintain aspect ratio in scaling\n",
    "scaling_factor = min(output_width/grid_width, output_height/grid_height)\n",
    "resized_width = int(grid_width * scaling_factor)\n",
    "resized_height = int(grid_height * scaling_factor)\n",
    "\n",
    "# Initialize video writer with 4K settings\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Better for 4K\n",
    "out = cv2.VideoWriter(str(output_video_path), fourcc, fps, \n",
    "                     (resized_width, resized_height))\n",
    "\n",
    "# Grid composition with optimized layout\n",
    "for i in range(total_frames):\n",
    "    grid_frame = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for event_idx, (event, frames) in enumerate(frames_dict.items()):\n",
    "        row = event_idx // n_cols\n",
    "        col = event_idx % n_cols\n",
    "        \n",
    "        if i < len(frames):\n",
    "            x = col * frame_width\n",
    "            y = row * frame_height\n",
    "            grid_frame[y:y+frame_height, x:x+frame_width] = frames[i]\n",
    "    \n",
    "    # High-quality scaling for 4K\n",
    "    resized_frame = cv2.resize(grid_frame, (resized_width, resized_height), \n",
    "                              interpolation=cv2.INTER_LANCZOS4)\n",
    "    resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2BGR)\n",
    "    out.write(resized_frame)\n",
    "\n",
    "out.release()\n",
    "\n",
    "\n",
    "print(f\"Grid video saved to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select event 65 and try different parameters for peak / plateau detection\n",
    "event_data = exfly.loc[exfly[\"interaction_event\"] == 94]\n",
    "\n",
    "# Create a single plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(event_data[\"frame\"], event_data[\"distance\"], label='Distance')\n",
    "\n",
    "# Try different parameters for peak / plateau detection\n",
    "\n",
    "# Default parameters\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame')\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='r', label='Default')\n",
    "\n",
    "# Increase window size\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame', window_size=50)\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='orange', label='Window Size 7')\n",
    "\n",
    "# Change peak window size\n",
    "\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame', peak_window_size=10)\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='blue', label='Peak Window Size 10')\n",
    "\n",
    "# Increase minimum plateau length\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame', min_plateau_length=40)\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='green', label='Min Plateau Length 10')\n",
    "\n",
    "# Increase peak prominence\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame', peak_prominence=1)\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='purple', label='Peak Prominence 2.0')\n",
    "\n",
    "# Increase dynamic threshold multiplier\n",
    "start_idx = find_interaction_start(event_data, 'distance', 'frame', threshold_multiplier=3)\n",
    "plt.axvline(event_data.loc[start_idx, 'frame'], color='brown', label='Threshold Multiplier 3')\n",
    "\n",
    "# Add legend and show plot\n",
    "plt.legend()\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Event 65: Distance with Different Parameters for Peak/Plateau Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick another fly to double check the detection code\n",
    "\n",
    "exfly = ball_data.loc[ball_data[\"fly\"] == ball_data[\"fly\"].unique()[19]]\n",
    "\n",
    "# for each event, compute the distance between the fly and the ball\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    event_data = exfly.loc[exfly[\"interaction_event\"] == event]\n",
    "    event_data = event_data.sort_values(\"frame\")\n",
    "    event_data[\"distance\"] = np.sqrt(\n",
    "        (event_data[\"x_ball_0\"] - event_data[\"x_fly_0\"]) ** 2\n",
    "        + (event_data[\"y_ball_0\"] - event_data[\"y_fly_0\"]) ** 2\n",
    "    )\n",
    "    \n",
    "    # Add an \"adjusted_frame\" column that starts at 0 and goes up to the length of the event\n",
    "    event_data[\"adjusted_frame\"] = range(len(event_data))\n",
    "\n",
    "    # Assign the computed columns back to the original DataFrame\n",
    "    exfly.loc[exfly[\"interaction_event\"] == event, \"distance\"] = event_data[\"distance\"]\n",
    "    exfly.loc[exfly[\"interaction_event\"] == event, \"adjusted_frame\"] = event_data[\"adjusted_frame\"]\n",
    "\n",
    "print(exfly)\n",
    "# Find first minimum distance for each event\n",
    "min_distance = exfly.groupby(\"interaction_event\")[\"distance\"].min()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "def find_interaction_start(data, distance_col, frame_col, \n",
    "                          threshold_multiplier=1.5, window_size=30, \n",
    "                          min_plateau_length=50, peak_prominence=1,\n",
    "                          peak_window_size=10):\n",
    "    # Work on a copy to avoid modifying original data\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Smoothing and derivative calculation\n",
    "    data['smoothed_distance'] = savgol_filter(data[distance_col], \n",
    "                                            window_length=11, \n",
    "                                            polyorder=3)\n",
    "    data['smoothed_diff'] = data['smoothed_distance'].diff()\n",
    "    data['smoothed_accel'] = data['smoothed_diff'].diff()  # Second derivative\n",
    "\n",
    "    # Dynamic threshold for plateaus based on rolling standard deviation\n",
    "    rolling_std = data['smoothed_diff'].rolling(window=window_size).std()\n",
    "    dynamic_threshold = rolling_std.mean() * threshold_multiplier  # Adjust multiplier as needed\n",
    "\n",
    "    # Plateau detection with dynamic threshold\n",
    "    plateau_mask = (data['smoothed_diff'].abs() < dynamic_threshold)\n",
    "    plateau_groups = (plateau_mask != plateau_mask.shift()).cumsum()\n",
    "    \n",
    "    # Initialize plateau markers\n",
    "    data['plateau_start'] = 0\n",
    "    valid_plateaus = data[plateau_mask].groupby(plateau_groups).filter(\n",
    "        lambda x: len(x) >= min_plateau_length\n",
    "    )\n",
    "    if not valid_plateaus.empty:\n",
    "        start_indices = valid_plateaus.groupby(plateau_groups).head(1).index\n",
    "        data.loc[start_indices, 'plateau_start'] = 1\n",
    "\n",
    "    # Peak detection with stricter prominence\n",
    "    peaks, _ = find_peaks(-data['smoothed_distance'],\n",
    "                        prominence=peak_prominence,\n",
    "                        width=3)\n",
    "    \n",
    "    # Refine peak detection for better alignment\n",
    "    refined_peaks = []\n",
    "    for peak in peaks:\n",
    "        if peak > 0 and peak < len(data) - 1:\n",
    "            # Perform local search around the detected peak to refine position\n",
    "            local_region = data.iloc[max(0, peak - peak_window_size):min(len(data), peak + peak_window_size)]\n",
    "            true_peak_idx = local_region[distance_col].idxmin()  # Find true minimum in this region\n",
    "            refined_peaks.append(true_peak_idx)\n",
    "\n",
    "    # Combine plateau and refined peak detections\n",
    "    plateau_indices = data[data['plateau_start'] == 1].index\n",
    "    all_candidates = sorted(list(plateau_indices) + refined_peaks)\n",
    "    \n",
    "    # Fallback to minimum distance if no markers found\n",
    "    if not all_candidates:\n",
    "        return data[distance_col].idxmin()\n",
    "    \n",
    "    return all_candidates[0]\n",
    "\n",
    "\n",
    "# Filter out NaN values from interaction_event\n",
    "exfly = exfly.dropna(subset=['interaction_event'])\n",
    "\n",
    "# Convert interaction_event to integer sequence first\n",
    "exfly['interaction_event'] = exfly['interaction_event'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Find first minimum distance and plateau/peak for each event\n",
    "min_distance = exfly.groupby(\"interaction_event\")[\"distance\"].idxmin()\n",
    "plateau_or_peak = exfly.groupby(\"interaction_event\").apply(\n",
    "    lambda x: find_interaction_start(x, 'distance', 'adjusted_frame',\n",
    "                                    )\n",
    ")\n",
    "\n",
    "# Create a grid\n",
    "grid = sns.FacetGrid(exfly, col=\"interaction_event\", col_wrap=4)\n",
    "\n",
    "# Plot the distance for each event\n",
    "grid.map(plt.plot, \"adjusted_frame\", \"distance\")\n",
    "\n",
    "# Add markers for the minimum distance points and plateau/peak points\n",
    "for ax, event in zip(grid.axes.flat, exfly[\"interaction_event\"].unique()):\n",
    "    try:\n",
    "        # Plot minimum distance point\n",
    "        min_idx = min_distance[event]\n",
    "        min_point = exfly.loc[min_idx]\n",
    "        ax.plot(min_point[\"adjusted_frame\"], min_point[\"distance\"], 'ro', label='Minimum')\n",
    "        \n",
    "        # Plot plateau/peak point\n",
    "        plateau_peak_idx = plateau_or_peak[event]\n",
    "        plateau_peak_point = exfly.loc[plateau_peak_idx]\n",
    "        ax.plot(plateau_peak_point[\"adjusted_frame\"], plateau_peak_point[\"distance\"], 'go', label='Plateau/Peak')\n",
    "        #ax.set_xlim(plateau_peak_point[\"adjusted_frame\"] - 20, plateau_peak_point[\"adjusted_frame\"] + 20)\n",
    "        \n",
    "        ax.legend()\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No data found for event {event}\")\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250218_Refined_contacts/events_distance_withmarkers_and_plateaus_New_SecondFly.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the video\n",
    "flypath = exfly[\"flypath\"].iloc[0]\n",
    "# Find the mp4 file in the folder\n",
    "video_folder = Path(flypath)\n",
    "video_files = list(video_folder.glob(\"*.mp4\"))\n",
    "\n",
    "video_path = video_files[0]\n",
    "print(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "# Check if the video is opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Store frames in a list\n",
    "frames = []\n",
    "\n",
    "# For each event, get the frame corresponding to the detected start point\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    # Get the start point for the event\n",
    "    start_point = exfly.loc[plateau_or_peak[event]]\n",
    "    \n",
    "    # Set the frame number to the start point\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_point[\"frame\"])\n",
    "    \n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read correctly\n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame for event {event}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the frame from BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Append the frame to the list\n",
    "    frames.append((event, frame))\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Plot the frames in a grid\n",
    "n_frames = len(frames)\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(n_frames / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "\n",
    "for i, (event, frame) in enumerate(frames):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(f\"Event: {event}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the video\n",
    "flypath = exfly[\"flypath\"].iloc[0]\n",
    "# Find the mp4 file in the folder\n",
    "video_folder = Path(flypath)\n",
    "video_files = list(video_folder.glob(\"*.mp4\"))\n",
    "\n",
    "if not video_files:\n",
    "    print(\"Error: No mp4 files found in the folder\")\n",
    "    sys.exit(1)\n",
    "\n",
    "video_path = video_files[0]\n",
    "print(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "# Check if the video is opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Parameters\n",
    "fps = 5\n",
    "frames_before = 20\n",
    "frames_after = 20\n",
    "total_frames = frames_before + frames_after + 1\n",
    "output_width = 3840\n",
    "output_height = 2160\n",
    "\n",
    "# Store frames in a dictionary\n",
    "frames_dict = {event: [] for event in exfly[\"interaction_event\"].unique()}\n",
    "\n",
    "# For each event, get the frames around the detected start point\n",
    "for event in exfly[\"interaction_event\"].unique():\n",
    "    # Get the start point for the event\n",
    "    start_point = exfly.loc[plateau_or_peak[event]][\"frame\"]\n",
    "    \n",
    "    for i in range(-frames_before, frames_after + 1):\n",
    "        frame_number = start_point + i\n",
    "        # Set the frame number\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Check if the frame is read correctly\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {frame_number} for event {event}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert the frame from BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Append the frame to the list\n",
    "        frames_dict[event].append(frame)\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Create a video writer\n",
    "output_video_path = \"grid_video_New.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "frame_height, frame_width, _ = next(iter(frames_dict.values()))[0].shape\n",
    "# Parameters (adjust as needed)\n",
    "# Modify the grid calculation section with this optimized version\n",
    "n_events = len(frames_dict)\n",
    "frame_height, frame_width, _ = next(iter(frames_dict.values()))[0].shape\n",
    "aspect_ratio = frame_width / frame_height\n",
    "\n",
    "# Calculate optimal grid dimensions for 16:9\n",
    "target_aspect = 16/9\n",
    "approx_cols = np.sqrt((target_aspect / aspect_ratio) * n_events)\n",
    "candidates = [int(np.floor(approx_cols)), int(np.ceil(approx_cols)), int(round(approx_cols))]\n",
    "candidates = np.unique(np.clip(candidates, 1, n_events))\n",
    "\n",
    "best_cols = 1\n",
    "best_error = float('inf')\n",
    "\n",
    "for cols in candidates:\n",
    "    rows = np.ceil(n_events / cols).astype(int)\n",
    "    grid_ar = (cols * aspect_ratio) / rows  # Combined grid aspect ratio\n",
    "    error = abs(grid_ar - target_aspect)\n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_cols = cols\n",
    "\n",
    "n_cols = best_cols\n",
    "n_rows = np.ceil(n_events / n_cols).astype(int)\n",
    "\n",
    "# Set output resolution to 4K\n",
    "output_width = 3840\n",
    "output_height = 2160\n",
    "\n",
    "# Calculate grid dimensions\n",
    "grid_width = frame_width * n_cols\n",
    "grid_height = frame_height * n_rows\n",
    "\n",
    "# Maintain aspect ratio in scaling\n",
    "scaling_factor = min(output_width/grid_width, output_height/grid_height)\n",
    "resized_width = int(grid_width * scaling_factor)\n",
    "resized_height = int(grid_height * scaling_factor)\n",
    "\n",
    "# Initialize video writer with 4K settings\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Better for 4K\n",
    "out = cv2.VideoWriter(str(output_video_path), fourcc, fps, \n",
    "                     (resized_width, resized_height))\n",
    "\n",
    "# Grid composition with optimized layout\n",
    "for i in range(total_frames):\n",
    "    grid_frame = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for event_idx, (event, frames) in enumerate(frames_dict.items()):\n",
    "        row = event_idx // n_cols\n",
    "        col = event_idx % n_cols\n",
    "        \n",
    "        if i < len(frames):\n",
    "            x = col * frame_width\n",
    "            y = row * frame_height\n",
    "            grid_frame[y:y+frame_height, x:x+frame_width] = frames[i]\n",
    "    \n",
    "    # High-quality scaling for 4K\n",
    "    resized_frame = cv2.resize(grid_frame, (resized_width, resized_height), \n",
    "                              interpolation=cv2.INTER_LANCZOS4)\n",
    "    resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2BGR)\n",
    "    out.write(resized_frame)\n",
    "\n",
    "out.release()\n",
    "\n",
    "\n",
    "print(f\"Grid video saved to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's crop the interaction events to 20 frames before and after the minimum distance point and plot the grid again\n",
    "\n",
    "# Create a grid\n",
    "\n",
    "grid = sns.FacetGrid(exfly, col=\"interaction_event\", col_wrap=4)\n",
    "\n",
    "# Plot the distance for each event\n",
    "\n",
    "grid.map(plt.plot, \"adjusted_frame\", \"distance\")\n",
    "\n",
    "# Add markers for the minimum distance points\n",
    "\n",
    "for ax, event in zip(grid.axes.flat, exfly[\"interaction_event\"].unique()):\n",
    "    \n",
    "    try:\n",
    "        min_idx = min_distance[event]\n",
    "        min_point = exfly.loc[min_idx]\n",
    "        ax.plot(min_point[\"adjusted_frame\"], min_point[\"distance\"], 'ro')\n",
    "        ax.set_xlim(min_point[\"adjusted_frame\"] - 20, min_point[\"adjusted_frame\"] + 20)\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No minimum distance found for event {event}\")\n",
    "        \n",
    "# Save the plot\n",
    "\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250218_Refined_contacts/events_distance_withmarkers_cropped.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contact data \n",
    "\n",
    "Contact_data = Ballpushing_utils.Dataset(exp, dataset_type=\"contact_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a column with the distance between the fly and the ball\n",
    "\n",
    "Contact_data.data[\"distance\"] = np.sqrt(\n",
    "    (Contact_data.data[\"x_centre_preprocessed\"] - Contact_data.data[\"x_Thorax\"]) ** 2\n",
    "    + (Contact_data.data[\"y_centre_preprocessed\"] - Contact_data.data[\"y_Thorax\"]) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a \"adjusted_frame\" column that starts at 0 and goes up to the length of the event. These should be computed grouped by contact_index\n",
    "\n",
    "Contact_data.data[\"adjusted_frame\"] = Contact_data.data.groupby(\"contact_index\")[\"frame\"].transform(\n",
    "    lambda x: x - x.min()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid and for each event plot the curve of the distance between the fly and the ball during the event\n",
    "\n",
    "# Create a grid\n",
    "\n",
    "grid = sns.FacetGrid(Contact_data.data, col=\"contact_index\", col_wrap=4)\n",
    "\n",
    "# Plot the distance for each event\n",
    "\n",
    "grid.map(plt.plot, \"adjusted_frame\", \"distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
