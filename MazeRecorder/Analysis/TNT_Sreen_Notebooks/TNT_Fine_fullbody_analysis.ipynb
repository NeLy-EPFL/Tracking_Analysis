{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will regroup analysis performed on full body tracking data related to the TNT screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pyarrow\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import label\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from shiny import App, Inputs, Outputs, Session, reactive, render, req, ui\n",
    "\n",
    "from utils_behavior import Sleap_utils, HoloviewsTemplates, Utils, Processing, Ballpushing_utils, Seaborn_Templates\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that my dataclasses are too heavy (~ 2 Gb each) to be easily computed directly in the notebook. That is why a script called \"DataSetBuilder.py\" was used to generate a dataset based on TNT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Utils.get_data_server()\n",
    "\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Split registry\n",
    "\n",
    "SplitRegistry = pd.read_csv(datapath / 'MD/MultiMazeRecorder/Datasets/SplitRegistry.csv')\n",
    "\n",
    "SplitRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Genotype column and rename the column Codename to Genotype\n",
    "\n",
    "SplitRegistry = SplitRegistry.drop(columns=['Genotype'])\n",
    "\n",
    "SplitRegistry = SplitRegistry.rename(columns={'Codename':'Genotype'})\n",
    "\n",
    "SplitRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short contacts\n",
    "\n",
    "Summary_data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250109_FinalEventCutoffData_norm/summary/250106_Pooled_summary.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in the fly column\n",
    "\n",
    "Summary_data['fly'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Split column from the SplitRegistry to the Disp_Data, merging based on the Genotype column\n",
    "\n",
    "Summary_data = pd.merge(Summary_data, SplitRegistry, on='Genotype', how='left')\n",
    "\n",
    "Summary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Split values with the correct values\n",
    "\n",
    "# If the Nickname is \"GMR70G12-Gal4\" or \"MB247-Gal4\" or \"Ple-Gal4.F a.k.a TH-Gal4\" or \"DDC-gal4\", set the Split to \"n\"\n",
    "\n",
    "Summary_data.loc[Summary_data['Nickname'].isin(['GMR70G12-Gal4', 'MB247-Gal4', 'Ple-Gal4.F a.k.a TH-Gal4', 'DDC-gal4']), 'Split'] = 'n'\n",
    "\n",
    "# If the Nickname is \"TNTxPR\" or \"TNTxCS\", set the Split to \"m\"\n",
    "\n",
    "Summary_data.loc[Summary_data['Nickname'].isin(['TNTxPR', 'TNTxCS']), 'Split'] = 'm'\n",
    "\n",
    "# If the Nickname is \"SS32219-Gal4 (LAL-2)\" or \"SS32230-Gal4 (LAL-1)\"  , set the Split to \"y\"\n",
    "\n",
    "Summary_data.loc[Summary_data['Nickname'].isin(['SS32219-Gal4 (LAL-2)', 'SS32230-Gal4 (LAL-1)']), 'Split'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_data=Summary_data[~Summary_data[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"CS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values in the Split column\n",
    "\n",
    "Summary_data['Split'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which Nicknames have NA values in the Split column\n",
    "\n",
    "Summary_data[Summary_data['Split'].isna()]['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = [#'TNTxCS', \n",
    "            #'TNTxPR', \n",
    "            'Empty-Gal4', 'Empty-Split'] # Replace with your list of genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics\n",
    "metrics = ['nb_events', 'max_event', 'max_event_time', 'max_distance',\n",
    "           'final_event', 'final_event_time', 'nb_significant_events',\n",
    "           'significant_ratio', 'first_significant_event',\n",
    "           'first_significant_event_time', 'aha_moment', 'aha_moment_time',\n",
    "           'insight_effect', 'cumulated_breaks_duration', 'pushed', 'pulled',\n",
    "           'pulling_ratio', 'interaction_proportion', 'distance_moved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which metrics have NA values\n",
    "\n",
    "Summary_data[metrics].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_metrics = ['nb_events', 'max_distance',\n",
    "            'nb_significant_events',\n",
    "           'significant_ratio', 'cumulated_breaks_duration', 'pushed', 'pulled',\n",
    "            'interaction_proportion', 'distance_moved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)\n",
    "\n",
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what is the maximum value of insight_effect\n",
    "\n",
    "Summary_data['insight_effect'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any NA values in the insight_effect column or Inf\n",
    "\n",
    "Summary_data['insight_effect'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = HoloviewsTemplates.jitter_boxplot(data=Summary_data, metric=\"pulling_ratio\", kdims=\"Nickname\",groupby=\"Brain region\", render=\"grouped\", control=controls, hline=\"bootstrap\")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plot = HoloviewsTemplates.jitter_boxplot(data=Summary_data, metric=metric, kdims=\"Nickname\",groupby=\"Brain region\", render=\"grouped\", control=controls, hline=\"bootstrap\")\n",
    "\n",
    "    hv.save(plot, f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250203_Summary/{metric}_3.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each of them for \n",
    "\n",
    "summary_plots = []\n",
    "\n",
    "for metric in metrics:\n",
    "    plot = Seaborn_Templates.sns_plot(Summary_data, metric, \"Nickname\", \"jitterboxplot\", group_by=\"Brain region\" )\n",
    "    \n",
    "    summary_plots.append(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_plots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics\n",
    "metrics = metrics\n",
    "\n",
    "# List of metadata columns\n",
    "metadata_columns = ['exit_time', 'fly', 'flypath', 'experiment', 'Nickname', \n",
    "                    'Brain region', 'Date', 'Genotype', 'Period', 'FeedingState', \n",
    "                    'Orientation', 'Light', 'Crossing', 'Split']\n",
    "\n",
    "# Replace infinity values with NaN\n",
    "Summary_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "cleaned_data = Summary_data.dropna(subset=metrics)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(cleaned_data[metrics])\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(normalized_data)\n",
    "pca_data = pca.transform(normalized_data)\n",
    "\n",
    "# Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(pca_data, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Concatenate the metadata columns with the PCA results\n",
    "pca_results = pd.concat([cleaned_data[metadata_columns].reset_index(drop=True), pca_df], axis=1)\n",
    "\n",
    "# Get explained variance and loadings\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "loadings = pca.components_\n",
    "\n",
    "# Create a DataFrame for the explained variance\n",
    "explained_variance_df = pd.DataFrame({\n",
    "    'Principal Component': [f'PC{i+1}' for i in range(n_components)],\n",
    "    'Explained Variance': explained_variance\n",
    "})\n",
    "\n",
    "# Create a DataFrame for the loadings\n",
    "loadings_df = pd.DataFrame(loadings.T, columns=[f'PC{i+1}' for i in range(n_components)], index=metrics)\n",
    "\n",
    "# Display the explained variance and loadings as tables\n",
    "print(\"Explained Variance:\")\n",
    "display(explained_variance_df.style.set_caption(\"Explained Variance\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [('color', 'black'), ('font-size', '16px')]\n",
    "}]))\n",
    "\n",
    "print(\"\\nLoadings:\")\n",
    "display(loadings_df.style.set_caption(\"Loadings\").set_table_styles([{\n",
    "    'selector': 'caption',\n",
    "    'props': [('color', 'black'), ('font-size', '16px')]\n",
    "}]))\n",
    "\n",
    "# Example plot for the first principal component\n",
    "#plot = HoloviewsTemplates.jitter_boxplot(data=pca_results, metric=\"PC1\", kdims=\"Nickname\", groupby=\"Brain region\", render=\"grouped\", control=controls, hline=\"boxplot\")\n",
    "#hv.save(plot, 'pca_plot.html')\n",
    "#plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PC2 the same way\n",
    "\n",
    "plot = HoloviewsTemplates.jitter_boxplot(data=pca_results, metric=\"PC2\", kdims=\"Nickname\",groupby=\"Brain region\", render=\"grouped\", control=controls, hline=\"boxplot\")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter plot of PC1 vs PC2\n",
    "\n",
    "plot = sns.jointplot(data=pca_results, x='PC1', y='PC2', hue='Brain region', kind='scatter')\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_nicknames = ['TNTxCS', 'TNTxPR', 'Empty-Gal4', 'Empty-Split']\n",
    "\n",
    "control_nicknames = ['Empty-Gal4', 'Empty-Split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames_dict = {\n",
    "    'y': 'Empty-Split',\n",
    "    'n': 'Empty-Gal4',\n",
    "    'm': 'TNTxPR'\n",
    "}\n",
    "nicknames = pca_results['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames_dict.values()]\n",
    "\n",
    "\n",
    "# Manually create a color dictionary for the brain regions\n",
    "color_dict = {\n",
    "    'MB': '#1f77b4',  # Blue\n",
    "    'Vision': '#ff7f0e',  # Orange\n",
    "    'LH': '#2ca02c',  # Green\n",
    "    'Neuropeptide': '#d62728',  # Red\n",
    "    'Olfaction': '#9467bd',  # Purple\n",
    "    'MB extrinsic neurons': '#8c564b',  # Brown\n",
    "    'CX': '#e377c2',  # Pink\n",
    "    'Control': '#7f7f7f',  # Gray\n",
    "    'None': '#bcbd22',  # Yellow-green\n",
    "    'fchON': '#17becf',  # Cyan\n",
    "    'JON': '#ffbb78',  # Light orange\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = pca_results[pca_results['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.scatterplot(data=subset_data[subset_data['Nickname'] == nickname], x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='o', s=100)\n",
    "    sns.scatterplot(data=subset_data[subset_data['Nickname'].isin(control_nicknames)], x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='X', s=100, legend=False)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{nickname} vs Controls')\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250109_SummaryMetrics/PC1_vs_PC2_Scatter_Full.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = pca_results[pca_results['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Compute bootstrap confidence intervals\n",
    "    nickname_data = subset_data[subset_data['Nickname'] == nickname]\n",
    "    control_data = subset_data[subset_data['Nickname'].isin(control_nicknames)]\n",
    "    \n",
    "    ci_nickname_pc1 = Processing.draw_bs_ci(nickname_data['PC1'], rg=rg)\n",
    "    ci_control_pc1 = Processing.draw_bs_ci(control_data['PC1'], rg=rg)\n",
    "    \n",
    "    ci_nickname_pc2 = Processing.draw_bs_ci(nickname_data['PC2'], rg=rg)\n",
    "    ci_control_pc2 = Processing.draw_bs_ci(control_data['PC2'], rg=rg)\n",
    "    \n",
    "    # Check for non-overlapping confidence intervals\n",
    "    pc1_lower = ci_nickname_pc1[1] < ci_control_pc1[0]\n",
    "    pc1_higher = ci_nickname_pc1[0] > ci_control_pc1[1]\n",
    "    pc2_lower = ci_nickname_pc2[1] < ci_control_pc2[0]\n",
    "    pc2_higher = ci_nickname_pc2[0] > ci_control_pc2[1]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.scatterplot(data=nickname_data, x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='o', s=100)\n",
    "    sns.scatterplot(data=control_data, x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='X', s=100, legend=False)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    title = f'{nickname} vs Controls'\n",
    "    if pc1_lower:\n",
    "        title += ' (PC1 lower)'\n",
    "    if pc1_higher:\n",
    "        title += ' (PC1 higher)'\n",
    "    if pc2_lower:\n",
    "        title += ' (PC2 lower)'\n",
    "    if pc2_higher:\n",
    "        title += ' (PC2 higher)'\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "    \n",
    "    # Change background color based on conditions\n",
    "    if pc1_lower and pc2_higher:\n",
    "        axes[i].set_facecolor('green')\n",
    "    elif pc1_higher and pc2_lower:\n",
    "        axes[i].set_facecolor('red')\n",
    "    elif (pc1_lower and pc2_lower) or (pc1_higher and pc2_higher):\n",
    "        axes[i].set_facecolor('yellow')\n",
    "    elif pc1_lower or pc2_higher:\n",
    "        axes[i].set_facecolor('lightgreen')\n",
    "    elif pc1_higher or pc2_lower:\n",
    "        axes[i].set_facecolor('lightcoral')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250109_SummaryMetrics/PC1_vs_PC2_Scatter_withstats_EmptyOnly.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bootstrapped confidence interval for each control group\n",
    "ci_controls = {}\n",
    "for split, control_nickname in control_nicknames_dict.items():\n",
    "    control_data = pca_results[pca_results['Nickname'] == control_nickname]\n",
    "    ci_controls[split] = {\n",
    "        'PC1': Processing.draw_bs_ci(control_data['PC1'], rg=rg),\n",
    "        'PC2': Processing.draw_bs_ci(control_data['PC2'], rg=rg)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by Brain region\n",
    "\n",
    "pca_results = pca_results.sort_values(by='Brain region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(nicknames):\n",
    "    print(f'Processing {nickname}...')\n",
    "    \n",
    "    # Subset the data for the current Nickname\n",
    "    nickname_data = pca_results[pca_results['Nickname'] == nickname]\n",
    "    \n",
    "    print(nickname_data[['Nickname', 'Split']].drop_duplicates())\n",
    "    \n",
    "    # Get the appropriate control group based on the Split column\n",
    "    split_value = nickname_data['Split'].iloc[0]\n",
    "    associated_control = control_nicknames_dict[split_value]\n",
    "    \n",
    "    print(f'Associated control is : {associated_control}')\n",
    "    \n",
    "    # Subset the data for the relevant control group\n",
    "    control_data = pca_results[pca_results['Nickname'] == associated_control]\n",
    "    \n",
    "    # Combine the nickname data with the relevant control data\n",
    "    subset_data = pd.concat([nickname_data, control_data])\n",
    "    \n",
    "    # Debugging information\n",
    "    #print(subset_data[['Nickname', 'Split']].drop_duplicates())\n",
    "    print(f'Associated control is : {associated_control}')\n",
    "    \n",
    "    # Map the colors based on the brain region\n",
    "    subset_data['color'] = subset_data['Brain region'].map(color_dict)\n",
    "    \n",
    "    # Subset the data for the relevant control group\n",
    "    control_data = pca_results[pca_results['Nickname'] == associated_control]\n",
    "    \n",
    "    # Compute bootstrap confidence intervals\n",
    "    ci_nickname_pc1 = Processing.draw_bs_ci(nickname_data['PC1'], rg=rg)\n",
    "    ci_control_pc1 = ci_controls[split_value]['PC1']\n",
    "    \n",
    "    ci_nickname_pc2 = Processing.draw_bs_ci(nickname_data['PC2'], rg=rg)\n",
    "    ci_control_pc2 = ci_controls[split_value]['PC2']\n",
    "    \n",
    "    # Check for non-overlapping confidence intervals\n",
    "    pc1_lower = ci_nickname_pc1[1] < ci_control_pc1[0]\n",
    "    pc1_higher = ci_nickname_pc1[0] > ci_control_pc1[1]\n",
    "    pc2_lower = ci_nickname_pc2[1] < ci_control_pc2[0]\n",
    "    pc2_higher = ci_nickname_pc2[0] > ci_control_pc2[1]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.scatterplot(data=nickname_data, x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='o', s=100)\n",
    "    sns.scatterplot(data=control_data, x='PC1', y='PC2', hue='Brain region', palette=color_dict, ax=axes[i], marker='X', s=100, legend=False)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    title = f'{nickname} vs Controls'\n",
    "    if pc1_lower:\n",
    "        title += ' (PC1 lower)'\n",
    "    if pc1_higher:\n",
    "        title += ' (PC1 higher)'\n",
    "    if pc2_lower:\n",
    "        title += ' (PC2 lower)'\n",
    "    if pc2_higher:\n",
    "        title += ' (PC2 higher)'\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "    \n",
    "    # Change background color based on conditions\n",
    "    if pc1_lower and pc2_higher:\n",
    "        axes[i].set_facecolor('green')\n",
    "    elif pc1_higher and pc2_lower:\n",
    "        axes[i].set_facecolor('red')\n",
    "    elif (pc1_lower and pc2_lower) or (pc1_higher and pc2_higher):\n",
    "        axes[i].set_facecolor('yellow')\n",
    "    elif pc1_lower or pc2_higher:\n",
    "        axes[i].set_facecolor('lightgreen')\n",
    "    elif pc1_higher or pc2_lower:\n",
    "        axes[i].set_facecolor('lightcoral')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250109_SummaryMetrics/PC1_vs_PC2_Scatter_withstats_RefinedCtrl.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of ball derivative for contact indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short contacts\n",
    "\n",
    "Disp_Data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/241218_FinalEventCutoffData_norm/Skeleton_contacts/241209_Pooled_Skeleton_contacts.feather\")\n",
    "\n",
    "# Long contacts\n",
    "\n",
    "# Disp_Data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250106_FinalEventCutoffData_norm/Skeleton_contacts/250106_Pooled_Skeleton_contacts.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disp_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Split column from the SplitRegistry to the Disp_Data, merging based on the Genotype column\n",
    "\n",
    "Disp_Data = pd.merge(Disp_Data, SplitRegistry, on='Genotype', how='left')\n",
    "\n",
    "Disp_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Split values with the correct values\n",
    "\n",
    "# If the Nickname is \"GMR70G12-Gal4\" or \"MB247-Gal4\" or \"Ple-Gal4.F a.k.a TH-Gal4\" or \"DDC-gal4\", set the Split to \"n\"\n",
    "\n",
    "Disp_Data.loc[Disp_Data['Nickname'].isin(['GMR70G12-Gal4', 'MB247-Gal4', 'Ple-Gal4.F a.k.a TH-Gal4', 'DDC-gal4']), 'Split'] = 'n'\n",
    "\n",
    "# If the Nickname is \"TNTxPR\" or \"TNTxCS\", set the Split to \"m\"\n",
    "\n",
    "Disp_Data.loc[Disp_Data['Nickname'].isin(['TNTxPR', 'TNTxCS']), 'Split'] = 'm'\n",
    "\n",
    "# If the Nickname is \"SS32219-Gal4 (LAL-2)\" or \"SS32230-Gal4 (LAL-1)\"  , set the Split to \"y\"\n",
    "\n",
    "Disp_Data.loc[Disp_Data['Nickname'].isin(['SS32219-Gal4 (LAL-2)', 'SS32230-Gal4 (LAL-1)']), 'Split'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disp_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disp_Data.ball_displacement.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long contacts\n",
    "count    51252.000000\n",
    "mean         0.036866\n",
    "std          0.072537\n",
    "min          0.000000\n",
    "25%          0.000000\n",
    "50%          0.008475\n",
    "75%          0.036659\n",
    "max          0.869565\n",
    "Name: ball_displacement, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short contacts\n",
    "count    58286.000000\n",
    "mean         0.070118\n",
    "std          0.114831\n",
    "min          0.000000\n",
    "25%          0.000000\n",
    "50%          0.025510\n",
    "75%          0.081967\n",
    "max          1.050000\n",
    "Name: ball_displacement, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column \"Aha_moment\" that is True if the average ball displacement grouped by Nickname is at any time greater than 0.2\n",
    "# Compute the mean ball displacement for each contact index within each group\n",
    "mean_displacement = Disp_Data.groupby(['Nickname', 'contact_index'])['ball_displacement'].mean().reset_index()\n",
    "\n",
    "# Check if the mean ball displacement exceeds 0.2 at any contact index for each group\n",
    "aha_moment = mean_displacement.groupby('Nickname')['ball_displacement'].transform(lambda x: (x > 0.2).any())\n",
    "\n",
    "# Create a dictionary to map Nickname to Aha_Moment\n",
    "aha_moment_dict = aha_moment.groupby(mean_displacement['Nickname']).first().to_dict()\n",
    "\n",
    "# Create the Aha_Moment column\n",
    "Disp_Data['Aha_Moment'] = Disp_Data['Nickname'].map(aha_moment_dict)\n",
    "\n",
    "# Display the DataFrame\n",
    "Disp_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disp_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TNT_Learn = Disp_Data[Disp_Data[\"Aha_Moment\"]==True]\n",
    "\n",
    "TNT_Learn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = TNT_Learn [TNT_Learn[\"ball_displacement\"]>0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the peaks using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=peaks, x='contact_index', y='ball_displacement', hue='Nickname')\n",
    "\n",
    "plt.xlabel('Contact Index')\n",
    "plt.ylabel('Ball Displacement')\n",
    "plt.title('Positions of Peaks > 0.2 of Ball Displacement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compute the first contact index where ball displacement is greater than 0.2 for each fly\n",
    "first_peak = peaks.groupby('fly').apply(lambda x: x.loc[x['contact_index'].idxmin()]).reset_index(drop=True)\n",
    "\n",
    "# Display the first peak for each fly\n",
    "\n",
    "first_peak.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sorted dataset based on median value grouped by Nickname\n",
    "\n",
    "sorted_data = first_peak.groupby('Nickname')['ball_displacement'].median().sort_values().index\n",
    "\n",
    "# Reorder the dataset based on the sorted Nicknames\n",
    "\n",
    "first_peak_sorted = first_peak.set_index('Nickname').loc[sorted_data].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the first peak for each fly using Seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(data=first_peak_sorted, x='contact_index', y='Nickname', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('Contact Index')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.title('First Peak of Ball Displacement > 0.2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Seaborn_Templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seaborn_Templates.sns_plot(plot_type=\"jitterboxplot\", data=first_peak, sort_by=\"median\", metric = \"contact_index\", kdims= \"Nickname\",colorby=\"Brain region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo with log scale\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(data=first_peak, x='contact_index', bins=range(0, 100, 1), kde=True, hue='Nickname')\n",
    "\n",
    "plt.xlabel('Contact Index')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.title('First Peak of Ball Displacement > 0.2')\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Transformed' is your DataFrame and 'Brain region' is the column to subset by\n",
    "control_region = 'Control'  # Define the Control Brain region\n",
    "brain_regions = Disp_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column that is y_centre * 10 to make it easier to make a detailed hist of it.\n",
    "\n",
    "Disp_Data[\"displacement_rescaled\"] = Disp_Data[\"ball_displacement\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(brain_regions) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 10 * n_rows))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Brain region and create a subplot\n",
    "for i, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = Disp_Data[Disp_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.histplot(data=subset_data, x='displacement_rescaled', kde=True, hue='Nickname', ax=axes[i], bins=range(0, 20, 1))\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{control_region} + {region}')\n",
    "    axes[i].set_xlabel('displacement_rescaled')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(0, 20)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter out displacement < 1 that might only be noise. \n",
    "\n",
    "#Disp_Data_Filtered = Disp_Data[Disp_Data[\"displacement_rescaled\"]> 1]\n",
    "\n",
    "\n",
    "Disp_Data_Filtered = Disp_Data\n",
    "\n",
    "Disp_Data_Filtered=Disp_Data_Filtered[~Disp_Data_Filtered[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"CS\"])]\n",
    "\n",
    "# Remove the TNTxCS and TNTxPR from the control list\n",
    "\n",
    "\n",
    "#Disp_Data_Filtered=Disp_Data_Filtered[~Disp_Data_Filtered[\"Nickname\"].isin([\"M6\", \"M7\", \"PR\", \"CS\", \"TNTxCS\", \"TNTxPR\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique Nicknames for the Brain region \"Control\"\n",
    "\n",
    "control_nicknames = Disp_Data_Filtered[Disp_Data_Filtered['Brain region'] == 'Control']['Nickname'].unique()\n",
    "\n",
    "control_nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(brain_regions) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 10 * n_rows))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Brain region and create a subplot\n",
    "for i, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = Disp_Data_Filtered[Disp_Data_Filtered['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.histplot(data=subset_data, x='displacement_rescaled', kde=True, hue='Nickname', ax=axes[i], bins=range(0, 20, 1))\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{control_region} + {region}')\n",
    "    axes[i].set_xlabel('displacement_rescaled')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(0, 20)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all individual brain regions\n",
    "\n",
    "brain_regions = Disp_Data_Filtered['Brain region'].unique()\n",
    "\n",
    "brain_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disp_Data_Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a color dictionary for the brain regions\n",
    "color_dict = {\n",
    "    'MB': '#1f77b4',  # Blue\n",
    "    'Vision': '#ff7f0e',  # Orange\n",
    "    'LH': '#2ca02c',  # Green\n",
    "    'Neuropeptide': '#d62728',  # Red\n",
    "    'Olfaction': '#9467bd',  # Purple\n",
    "    'MB extrinsic neurons': '#8c564b',  # Brown\n",
    "    'CX': '#e377c2',  # Pink\n",
    "    'Control': '#7f7f7f',  # Gray\n",
    "    'None': '#bcbd22',  # Yellow-green\n",
    "    'fchON': '#17becf',  # Cyan\n",
    "    'JON': '#ffbb78',  # Light orange\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames = {\n",
    "    'y': 'Empty-Split',\n",
    "    'n': 'Empty-Gal4',\n",
    "    'm': 'TNTxPR'\n",
    "}\n",
    "nicknames = Disp_Data_Filtered['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames.values()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and display missing values for Split. Display the associated Nicknames\n",
    "\n",
    "missing_split = Disp_Data_Filtered[Disp_Data_Filtered['Split'].isna()]['Nickname'].unique()\n",
    "\n",
    "missing_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Split values with the correct values\n",
    "\n",
    "# If the Nickname is \"GMR70G12-Gal4\" or \"MB247-Gal4\" or \"Ple-Gal4.F a.k.a TH-Gal4\" or \"DDC-gal4\", set the Split to \"n\"\n",
    "\n",
    "Disp_Data_Filtered.loc[Disp_Data_Filtered['Nickname'].isin(['GMR70G12-Gal4', 'MB247-Gal4', 'Ple-Gal4.F a.k.a TH-Gal4', 'DDC-gal4']), 'Split'] = 'n'\n",
    "\n",
    "# If the Nickname is \"TNTxPR\" or \"TNTxCS\", set the Split to \"m\"\n",
    "\n",
    "Disp_Data_Filtered.loc[Disp_Data_Filtered['Nickname'].isin(['TNTxPR', 'TNTxCS']), 'Split'] = 'm'\n",
    "\n",
    "# If the Nickname is \"SS32219-Gal4 (LAL-2)\" or \"SS32230-Gal4 (LAL-1)\"  , set the Split to \"y\"\n",
    "\n",
    "Disp_Data_Filtered.loc[Disp_Data_Filtered['Nickname'].isin(['SS32219-Gal4 (LAL-2)', 'SS32230-Gal4 (LAL-1)']), 'Split'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give everyone the same Split value, \"n\"\n",
    "\n",
    "Disp_Data_Filtered['Split'] = 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bootstrapped confidence interval for the control group\n",
    "control_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'].isin(control_nicknames)]['displacement_rescaled']\n",
    "ci_control = Processing.draw_bs_ci(control_data, func = np.median,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the medians for each Nickname\n",
    "medians = Disp_Data_Filtered.groupby('Nickname')['displacement_rescaled'].agg(lambda x: x.median()).reset_index()\n",
    "medians.columns = ['Nickname', 'Median']\n",
    "\n",
    "# Merge the medians with the original dataset\n",
    "Disp_Data_Filtered = Disp_Data_Filtered.merge(medians, on='Nickname')\n",
    "\n",
    "# Sort the dataset by Brain region and then by ascending median\n",
    "Disp_Data_Filtered = Disp_Data_Filtered.sort_values(by=['Brain region', 'Median'])\n",
    "\n",
    "# Get the sorted nicknames\n",
    "sorted_nicknames = Disp_Data_Filtered['Nickname'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "# Compute the bootstrapped confidence interval for each control group\n",
    "ci_controls = {}\n",
    "for split, control_nickname in control_nicknames.items():\n",
    "    control_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'] == control_nickname]['displacement_rescaled']\n",
    "    ci_controls[split] = Processing.draw_bs_ci(control_data, func=np.median)\n",
    "    \n",
    "# Print the confidence intervals for each control group\n",
    "\n",
    "ci_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All controls together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(sorted_nicknames)\n",
    "n_cols = 6  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure with increased size\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(8*n_cols, 8*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(sorted_nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Map the colors based on the brain region\n",
    "    subset_data['color'] = subset_data['Brain region'].map(color_dict)\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.histplot(data=subset_data, x='displacement_rescaled', kde=True, hue='Brain region', element=\"step\", stat=\"density\", ax=axes[i], bins=range(0, 20, 1), palette=color_dict)\n",
    "    \n",
    "    # Calculate and annotate the peak for the control and the current Nickname\n",
    "    control_peak = round(subset_data[subset_data['Nickname'].isin(control_nicknames)]['displacement_rescaled'].median(), 2)\n",
    "    nickname_peak = round(subset_data[subset_data['Nickname'] == nickname]['displacement_rescaled'].median(), 2)\n",
    "    \n",
    "    # Wrap the nickname text if it's too long\n",
    "    wrapped_nickname = \"\\n\".join(textwrap.wrap(nickname, width=15))\n",
    "    \n",
    "    axes[i].annotate(f'Control Peak: {control_peak}', xy=(control_peak, 0), xytext=(control_peak, 0.05),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05), fontsize=14, color='black')\n",
    "    axes[i].annotate(f'{wrapped_nickname} Peak: {nickname_peak}', xy=(nickname_peak, 0), xytext=(nickname_peak, 0.1),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05), fontsize=14, color='black')\n",
    "    \n",
    "    # Compute the bootstrapped confidence interval for the current Nickname\n",
    "    nickname_data = subset_data[subset_data['Nickname'] == nickname]['displacement_rescaled']\n",
    "    ci_nickname = Processing.draw_bs_ci(nickname_data, func=np.median)\n",
    "    \n",
    "    # Check if the confidence intervals overlap\n",
    "    if ci_nickname[1] < ci_control[0]:\n",
    "        axes[i].set_facecolor('lightcoral')\n",
    "    elif ci_nickname[0] > ci_control[1]:\n",
    "        axes[i].set_facecolor('lightgreen')\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{wrapped_nickname} vs Controls', fontsize=16)\n",
    "    axes[i].set_xlabel('displacement_rescaled', fontsize=14)\n",
    "    axes[i].set_ylabel('Density', fontsize=14)\n",
    "    \n",
    "    axes[i].set_xlim(0, 20)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/Displacement_Histograms.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(sorted_nicknames)\n",
    "n_cols = 6  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure with increased size\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(8*n_cols, 8*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(sorted_nicknames):\n",
    "    print(f'Processing {nickname}...')\n",
    "    \n",
    "    # Subset the data for the current Nickname\n",
    "    nickname_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'] == nickname]\n",
    "    \n",
    "    # Get the appropriate control group based on the Split column\n",
    "    split_value = nickname_data['Split'].iloc[0]\n",
    "    associated_control = control_nicknames[split_value]\n",
    "    \n",
    "    # Subset the data for the relevant control group\n",
    "    control_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'] == associated_control]\n",
    "    \n",
    "    # Combine the nickname data with the relevant control data\n",
    "    subset_data = pd.concat([nickname_data, control_data])\n",
    "    \n",
    "    # Debugging information\n",
    "    #print(subset_data[['Nickname', 'Split']].drop_duplicates())\n",
    "    print(f'Associated control is : {associated_control}')\n",
    "    \n",
    "    # Map the colors based on the brain region\n",
    "    subset_data['color'] = subset_data['Brain region'].map(color_dict)\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.histplot(data=subset_data, x='displacement_rescaled', kde=True, hue='Brain region', element=\"step\", stat=\"density\", ax=axes[i], bins=range(0, 20, 1), palette=color_dict)\n",
    "    \n",
    "    # Calculate and annotate the peak for the control and the current Nickname\n",
    "    control_peak = round(subset_data[subset_data['Nickname'].isin(control_nicknames.values())]['displacement_rescaled'].median(), 2)\n",
    "    nickname_peak = round(subset_data[subset_data['Nickname'] == nickname]['displacement_rescaled'].median(), 2)\n",
    "    \n",
    "    # Wrap the nickname text if it's too long\n",
    "    wrapped_nickname = \"\\n\".join(textwrap.wrap(nickname, width=15))\n",
    "    \n",
    "    axes[i].annotate(f'Control Peak: {control_peak}', xy=(control_peak, 0), xytext=(control_peak, 0.05),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05), fontsize=14, color='black')\n",
    "    axes[i].annotate(f'{wrapped_nickname} Peak: {nickname_peak}', xy=(nickname_peak, 0), xytext=(nickname_peak, 0.1),\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05), fontsize=14, color='black')\n",
    "    \n",
    "    # Compute the bootstrapped confidence interval for the current Nickname\n",
    "    nickname_data = subset_data[subset_data['Nickname'] == nickname]['displacement_rescaled']\n",
    "    ci_nickname = Processing.draw_bs_ci(nickname_data, func=np.median)\n",
    "    \n",
    "    # Get the right bootstrap confidence interval for the control group\n",
    "    \n",
    "    ci_control = ci_controls[split_value]\n",
    "    \n",
    "    # Check if the confidence intervals overlap\n",
    "    if ci_nickname[1] < ci_control[0]:\n",
    "        axes[i].set_facecolor('lightcoral')  # Light red\n",
    "    elif ci_nickname[0] > ci_control[1]:\n",
    "        axes[i].set_facecolor('lightgreen')\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{wrapped_nickname} vs {associated_control}', fontsize=16)\n",
    "    axes[i].set_xlabel('displacement_rescaled', fontsize=14)\n",
    "    axes[i].set_ylabel('Density', fontsize=14)\n",
    "    \n",
    "    axes[i].set_xlim(0, 20)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/250110_Displacement_Histograms_Refined_ctrls_zeroIncl.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(sorted_nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = Disp_Data_Filtered[Disp_Data_Filtered['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.violinplot(data=subset_data, x='displacement_rescaled', hue='Brain region', cut=0, ax=axes[i], palette=color_dict)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{nickname} vs Controls')\n",
    "    axes[i].set_xlabel('displacement_rescaled')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/Disp_violinplot.png\")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short contacts\n",
    "\n",
    "Transformed = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/241220_Transform/241220_Transformed_contact_data_mintsfresh.feather\")\n",
    "\n",
    "# Long contacts\n",
    "\n",
    "#Transformed = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250107_Transform/250107_Transformed_contact_data_mintsfresh.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out flies that have no brain region assigned\n",
    "\n",
    "Transformed[Transformed[\"Brain region\"]==\"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long contacts and full dataset\n",
    "\n",
    "Transformed = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Coordinates/250106_Transformed_contact_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Split column from the SplitRegistry to the Disp_Data, merging based on the Genotype column\n",
    "\n",
    "Transformed = pd.merge(Transformed, SplitRegistry, on='Genotype', how='left')\n",
    "\n",
    "Transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Split values with the correct values\n",
    "\n",
    "# If the Nickname is \"GMR70G12-Gal4\" or \"MB247-Gal4\" or \"Ple-Gal4.F a.k.a TH-Gal4\" or \"DDC-gal4\", set the Split to \"n\"\n",
    "\n",
    "Transformed.loc[Transformed['Nickname'].isin(['GMR70G12-Gal4', 'MB247-Gal4', 'Ple-Gal4.F a.k.a TH-Gal4', 'DDC-gal4']), 'Split'] = 'n'\n",
    "\n",
    "# If the Nickname is \"TNTxPR\" or \"TNTxCS\", set the Split to \"m\"\n",
    "\n",
    "Transformed.loc[Transformed['Nickname'].isin(['TNTxPR', 'TNTxCS']), 'Split'] = 'm'\n",
    "\n",
    "# If the Nickname is \"SS32219-Gal4 (LAL-2)\" or \"SS32230-Gal4 (LAL-1)\"  , set the Split to \"y\"\n",
    "\n",
    "Transformed.loc[Transformed['Nickname'].isin(['SS32219-Gal4 (LAL-2)', 'SS32230-Gal4 (LAL-1)']), 'Split'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed=Transformed[~Transformed[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"CS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values in the Split column\n",
    "\n",
    "Transformed['Split'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which Nicknames have NA values in the Split column\n",
    "\n",
    "Transformed[Transformed['Split'].isna()]['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed[\"identifier\"] = Transformed[\"fly\"] + str(Transformed[\"contact_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames = {\n",
    "    'y': 'Empty-Split',\n",
    "    'n': 'Empty-Gal4',\n",
    "    'm': 'TNTxPR'\n",
    "}\n",
    "nicknames = Transformed['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each of the columns\n",
    "\n",
    "for col in Transformed.columns:\n",
    "    \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all individual brain regions\n",
    "\n",
    "brain_regions = Transformed[\"Brain region\"].unique()\n",
    "\n",
    "brain_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a color dictionary for the brain regions\n",
    "color_dict = {\n",
    "    'MB': '#1f77b4',  # Blue\n",
    "    'Vision': '#ff7f0e',  # Orange\n",
    "    'LH': '#2ca02c',  # Green\n",
    "    'Neuropeptide': '#d62728',  # Red\n",
    "    'Olfaction': '#9467bd',  # Purple\n",
    "    'MB extrinsic neurons': '#8c564b',  # Brown\n",
    "    'CX': '#e377c2',  # Pink\n",
    "    'Control': '#7f7f7f',  # Gray\n",
    "    'None': '#bcbd22',  # Yellow-green\n",
    "    'fchON': '#17becf',  # Cyan\n",
    "    'JON': '#ffbb78',  # Light orange\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames_dict = {\n",
    "    'y': 'Empty-Split',\n",
    "    'n': 'Empty-Gal4',\n",
    "    'm': 'TNTxPR'\n",
    "}\n",
    "nicknames = Transformed['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = Transformed[Transformed['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Select the right control group based on the Split column\n",
    "    \n",
    "    split_value = subset_data['Split'].iloc[0]\n",
    "    \n",
    "    associated_control = control_nicknames[split_value]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.lineplot(data=subset_data, x='contact_index', y='median_euclidean_distance', hue='Brain region', ax=axes[i], palette=color_dict)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{nickname} vs Controls')\n",
    "    axes[i].set_xlabel('displacement_rescaled')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/euclidean_distance_index_line.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed[\"inverted_y_displacement\"] = Transformed[\"y_centre_preprocessed_disp_mean\"]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one random Nickname and get a subset of it\n",
    "# Get unique Nicknames\n",
    "\n",
    "nicknames = Transformed['Nickname'].unique()\n",
    "\n",
    "# Pick a random Nickname\n",
    "\n",
    "nickname = np.random.choice(nicknames)\n",
    "\n",
    "print(f'Random Nickname: {nickname}')\n",
    "\n",
    "# Get the associated control\n",
    "\n",
    "split_value = Transformed[Transformed['Nickname'] == nickname]['Split'].iloc[0]\n",
    "\n",
    "associated_control = control_nicknames[split_value]\n",
    "\n",
    "print(f'Associated control is : {associated_control}')\n",
    "\n",
    "# Get the subset of the data for the random Nickname\n",
    "\n",
    "subset_data = Transformed[Transformed['Nickname'] == nickname]\n",
    "\n",
    "# Get the subset of the data for the associated control\n",
    "\n",
    "control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "\n",
    "# Combine the nickname data with the relevant control data\n",
    "\n",
    "subset_data = pd.concat([subset_data, control_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of metric\n",
    "\n",
    "#metric = 'median_euclidean_distance'\n",
    "\n",
    "#metric = 'inverted_y_displacement'\n",
    "\n",
    "metric = 'raw_displacement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the subset data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the jointplot\n",
    "g = sns.JointGrid(data=subset_data, x='start', y=metric, hue='Brain region', palette=color_dict,)\n",
    "g.plot_joint(sns.scatterplot, s=30, alpha=.5,  style=subset_data['direction'])\n",
    "#g.plot_joint(sns.kdeplot, fill = True, alpha=.5)\n",
    "g.plot_marginals(sns.violinplot)\n",
    "# Set the title for the figure\n",
    "g.fig.suptitle(f'{nickname} vs {associated_control}', y=1.03)\n",
    "\n",
    "# Set the axis labels\n",
    "g.set_axis_labels('Start time', metric)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the subset data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the jointplot\n",
    "g = sns.JointGrid(data=subset_data, x='start', y=metric, hue='Brain region', palette=color_dict)\n",
    "g.plot(sns.scatterplot, sns.violinplot)\n",
    "# Set the title for the figure\n",
    "g.fig.suptitle(f'{nickname} vs {associated_control}', y=1.03)\n",
    "\n",
    "# Set the axis labels\n",
    "g.set_axis_labels('Start time', metric)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop through each Brain region and create a separate figure\n",
    "for brain_region in brain_regions:\n",
    "    # Check if the plot is already created\n",
    "    if os.path.exists(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250114_RegionPlots/StartTime_RawDisplacement_{brain_region}.png\"):\n",
    "        print(f\"Skipping Brain region {brain_region} as the plot already exists.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Subset the data for the current Brain region\n",
    "        region_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "        \n",
    "        # Get the unique nicknames for the current Brain region\n",
    "        nicknames = region_data['Nickname'].unique()\n",
    "        \n",
    "        # Calculate the number of rows and columns for the subplot grid\n",
    "        n_nicknames = len(nicknames)\n",
    "        n_cols = 5  # You can adjust this value\n",
    "        n_rows = math.ceil(n_nicknames / n_cols)\n",
    "        \n",
    "        # Create the main figure\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 30), squeeze=False)\n",
    "        \n",
    "        # Flatten the axes array for easier iteration\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Loop through each Nickname and create a subplot\n",
    "        for i, nickname in enumerate(nicknames):\n",
    "            # Subset the data for the current Nickname\n",
    "            nickname_data = region_data[region_data['Nickname'] == nickname]\n",
    "            \n",
    "            # Select the right control group based on the Split column\n",
    "            split_value = nickname_data['Split'].iloc[0]\n",
    "            associated_control = control_nicknames_dict[split_value]\n",
    "            \n",
    "            # Subset the data for the relevant control group\n",
    "            control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "            \n",
    "            # Combine the nickname data with the relevant control data\n",
    "            subset_data = pd.concat([nickname_data, control_data])\n",
    "            \n",
    "            # Plot the distribution\n",
    "            sns.kdeplot(data=subset_data, x='start', y='median_euclidean_distance', hue='Brain region', ax=axes[i], palette=color_dict, fill=True)\n",
    "            \n",
    "            # Set the title for the subplot\n",
    "            axes[i].set_title(f'{nickname} vs {associated_control}')\n",
    "            axes[i].set_xlabel('Start Time (s)')\n",
    "            axes[i].set_ylabel('Median Euclidean Distance')\n",
    "            \n",
    "            #axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "        \n",
    "        # Remove any unused subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "        \n",
    "        # Adjust the layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250114_RegionPlots/StartTime_RawDisplacement_{brain_region}.png\")\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Brain region {brain_region}: {e}\")\n",
    "        \n",
    "        # Skip to the next Brain region\n",
    "        \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by Brain region\n",
    "brain_regions = Transformed['Brain region'].unique()\n",
    "\n",
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "# Loop through each Brain region\n",
    "for brain_region in brain_regions:\n",
    "    # Create a directory for the current Brain region if it doesn't exist\n",
    "    directory = f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/250114_RegionPlots/{brain_region}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Subset the data for the current Brain region\n",
    "    region_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    \n",
    "    # Get the unique nicknames for the current Brain region\n",
    "    nicknames = region_data['Nickname'].unique()\n",
    "    \n",
    "    # Loop through each Nickname and create a separate figure\n",
    "    for nickname in nicknames:\n",
    "        # Check if the plot is already created\n",
    "        plot_path = f\"{directory}/StartTime_RawDisplacement_better_{nickname}.png\"\n",
    "        if os.path.exists(plot_path):\n",
    "            print(f\"Skipping Nickname {nickname} as the plot already exists.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Subset the data for the current Nickname\n",
    "            nickname_data = region_data[region_data['Nickname'] == nickname]\n",
    "            \n",
    "            # Select the right control group based on the Split column\n",
    "            split_value = nickname_data['Split'].iloc[0]\n",
    "            associated_control = control_nicknames_dict[split_value]\n",
    "            \n",
    "            # Subset the data for the relevant control group\n",
    "            control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "            \n",
    "            # Combine the nickname data with the relevant control data\n",
    "            subset_data = pd.concat([nickname_data, control_data])\n",
    "            \n",
    "            # Plot the subset data\n",
    "            plt.figure(figsize=(10, 6))\n",
    "\n",
    "            # Create the jointplot\n",
    "            g = sns.JointGrid(data=subset_data, x='start', y=metric, hue='Brain region', palette=color_dict,)\n",
    "            g.plot_joint(sns.scatterplot, s=30, alpha=.5,  style=subset_data['direction'])\n",
    "            #g.plot_joint(sns.kdeplot, fill = True, alpha=.5)\n",
    "            g.plot_marginals(sns.violinplot)\n",
    "            # Set the title for the figure\n",
    "            g.fig.suptitle(f'{nickname} vs {associated_control}', y=1.03)\n",
    "\n",
    "            # Set the axis labels\n",
    "            g.set_axis_labels('Start time', metric)\n",
    "            \n",
    "            # Save the plot\n",
    "            g.fig.savefig(plot_path)\n",
    "            \n",
    "            # Show the plot\n",
    "            plt.show()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing Nickname {nickname} in Brain region {brain_region}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_nicknames = len(nicknames)\n",
    "n_cols = 15  # You can adjust this value\n",
    "n_rows = math.ceil(n_nicknames / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20*n_cols, 10*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for region in brain_regions:\n",
    "# Loop through each Nickname and create a subplot\n",
    "for i, nickname in enumerate(nicknames):\n",
    "    # Subset the data for the Control Brain region and the current Nickname\n",
    "    subset_data = Transformed[Transformed['Nickname'].isin([nickname] + list(control_nicknames))]\n",
    "    \n",
    "    # Select the right control group based on the Split column\n",
    "    \n",
    "    split_value = subset_data['Split'].iloc[0]\n",
    "    \n",
    "    associated_control = control_nicknames[split_value]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.lineplot(data=subset_data, x='contact_index', y='median_euclidean_distance', hue='Brain region', ax=axes[i], palette=color_dict)\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{nickname} vs Controls')\n",
    "    axes[i].set_xlabel('displacement_rescaled')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/euclidean_distance_index_line.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the data by Brain region\n",
    "brain_regions = Transformed['Brain region'].unique()\n",
    "\n",
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "# Loop through each Brain region and create a separate figure\n",
    "for brain_region in brain_regions:\n",
    "    # Subset the data for the current Brain region\n",
    "    region_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    \n",
    "    # Get the unique nicknames for the current Brain region\n",
    "    nicknames = region_data['Nickname'].unique()\n",
    "    \n",
    "    # Calculate the number of rows and columns for the subplot grid\n",
    "    n_nicknames = len(nicknames)\n",
    "    n_cols = 5  # You can adjust this value\n",
    "    n_rows = math.ceil(n_nicknames / n_cols)\n",
    "    \n",
    "    # Create the main figure\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 10), squeeze=False)\n",
    "    \n",
    "    # Flatten the axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Loop through each Nickname and create a subplot\n",
    "    for i, nickname in enumerate(nicknames):\n",
    "        # Subset the data for the current Nickname\n",
    "        nickname_data = region_data[region_data['Nickname'] == nickname]\n",
    "        \n",
    "        # Select the right control group based on the Split column\n",
    "        split_value = nickname_data['Split'].iloc[0]\n",
    "        associated_control = control_nicknames[split_value]\n",
    "        \n",
    "        # Subset the data for the relevant control group\n",
    "        control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "        \n",
    "        # Combine the nickname data with the relevant control data\n",
    "        subset_data = pd.concat([nickname_data, control_data])\n",
    "        \n",
    "        # Plot the distribution\n",
    "        sns.lineplot(data=subset_data, x='contact_index', y='median_euclidean_distance', hue='Brain region', ax=axes[i], palette=color_dict)\n",
    "        \n",
    "        # Set the title for the subplot\n",
    "        axes[i].set_title(f'{nickname} vs {associated_control}')\n",
    "        axes[i].set_xlabel('Contact Index')\n",
    "        axes[i].set_ylabel('Median Euclidean Distance')\n",
    "        \n",
    "        #axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/euclidean_distance_index_line_{brain_region}.png\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distribution of y parameters for the ball\n",
    "\n",
    "# Get all columns with \"y_centre_preprocessed\" in the name\n",
    "\n",
    "y_columns = [col for col in Transformed.columns if 'y_centre_preprocessed' in col]\n",
    "\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Transformed' is your DataFrame and 'Brain region' is the column to subset by\n",
    "control_region = 'Control'  # Define the Control Brain region\n",
    "brain_regions = Transformed['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column that is y_centre * 10 to make it easier to make a detailed hist of it.\n",
    "\n",
    "Transformed[\"y_centre_preprocessed_disp_mean_rescaled\"] = Transformed[\"y_centre_preprocessed_disp_mean\"]*10\n",
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(brain_regions) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 10 * n_rows))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Brain region and create a subplot\n",
    "for i, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = Transformed[Transformed['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Plot the distribution\n",
    "    sns.histplot(data=subset_data, x='y_centre_preprocessed_disp_mean_rescaled', kde=True, hue='Nickname', ax=axes[i], bins=range(-30, 30, 1))\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(f'{control_region} + {region}')\n",
    "    axes[i].set_xlabel('y_centre_preprocessed_disp_mean')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    \n",
    "    axes[i].set_xlim(-30, 30)  # Adjust the limits as needed\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include contacts timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed['y_centre_preprocessed_disp_mean_abs'] = Transformed['y_centre_preprocessed_disp_mean'].abs()\n",
    "\n",
    "# Calculate the global minimum and maximum values of the absolute y_centre_preprocessed_disp_mean\n",
    "global_min = Transformed['y_centre_preprocessed_disp_mean_abs'].min()\n",
    "global_max = Transformed['y_centre_preprocessed_disp_mean_abs'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "brain_regions = Transformed['Brain region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by Nickname within each brain region\n",
    "Transformed = Transformed.sort_values(by=['Brain region', 'Nickname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique brain regions\n",
    "brain_regions = Transformed['Brain region'].unique()\n",
    "\n",
    "# Create log-normalized colormap\n",
    "metric = 'y_centre_preprocessed_disp_mean_abs'\n",
    "log_values = np.log1p(Transformed[metric])\n",
    "global_min = log_values.min()\n",
    "global_max = log_values.max()\n",
    "\n",
    "for brain_region in brain_regions:\n",
    "    subset_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    unique_combinations = subset_data[['Nickname', 'fly']].drop_duplicates()\n",
    "    \n",
    "    # Create figure with minimal height per fly\n",
    "    fig, ax = plt.subplots(figsize=(15, max(4, len(unique_combinations) * 0.2)))\n",
    "    \n",
    "    # Create logarithmic colormap\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    norm = mcolors.Normalize(vmin=global_min, vmax=global_max)\n",
    "    \n",
    "    # Plot events with minimal spacing\n",
    "    for i, (nickname, fly) in enumerate(unique_combinations.itertuples(index=False)):\n",
    "        fly_data = subset_data[(subset_data['Nickname'] == nickname) & \n",
    "                             (subset_data['fly'] == fly)]\n",
    "        for _, row in fly_data.iterrows():\n",
    "            log_value = np.log1p(row[metric])\n",
    "            ax.plot([row['start'], row['end']], [i, i], \n",
    "                   color=cmap(norm(log_value)), \n",
    "                   lw=4,  # Thicker lines for better visibility\n",
    "                   solid_capstyle='butt')\n",
    "    \n",
    "    # Compact y-axis with minimal spacing\n",
    "    ax.set_yticks(np.arange(len(unique_combinations)))\n",
    "    ax.set_yticklabels([f\"{nickname}-{fly}\" for nickname, fly in \n",
    "                        unique_combinations.itertuples(index=False)],\n",
    "                       fontsize=6)  # Even smaller font\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    ax.margins(y=0.01)  # Minimal margins\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Nickname-Fly')\n",
    "    ax.set_title(f'Raster Plot for {brain_region}')\n",
    "    \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(f'log({metric} + 1)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique brain regions\n",
    "brain_regions = Transformed['Brain region'].unique()\n",
    "\n",
    "# Create log-normalized colormap\n",
    "metric = 'y_centre_preprocessed_disp_mean_abs'\n",
    "log_values = np.log1p(Transformed[metric])\n",
    "global_min = log_values.min()\n",
    "global_max = log_values.max()\n",
    "\n",
    "for brain_region in brain_regions:\n",
    "    subset_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    \n",
    "    # Create a matrix representation\n",
    "    # First, get unique nicknames and time points\n",
    "    nicknames = subset_data['Nickname'].unique()\n",
    "    \n",
    "    # Check if start and end values are valid\n",
    "    start_min = subset_data['start'].min()\n",
    "    end_max = subset_data['end'].max()\n",
    "    if pd.isna(start_min) or pd.isna(end_max) or start_min >= end_max:\n",
    "        print(f\"Skipping brain region {brain_region} due to invalid start or end values.\")\n",
    "        continue\n",
    "    \n",
    "    time_points = np.arange(start_min, end_max, 0.1)  # Adjust step size as needed\n",
    "    \n",
    "    # Create empty matrix\n",
    "    matrix = np.zeros((len(nicknames), len(time_points)))\n",
    "    matrix_values = np.full_like(matrix, np.nan)\n",
    "    \n",
    "    # Fill matrix\n",
    "    for i, nickname in enumerate(nicknames):\n",
    "        nick_data = subset_data[subset_data['Nickname'] == nickname]\n",
    "        for _, row in nick_data.iterrows():\n",
    "            start_idx = int((row['start'] - time_points[0]) / 0.1)\n",
    "            end_idx = int((row['end'] - time_points[0]) / 0.1)\n",
    "            if start_idx < len(time_points) and end_idx < len(time_points):\n",
    "                matrix_values[i, start_idx:end_idx] = np.log1p(row[metric])\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, max(4, len(nicknames) * 0.3)))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(matrix_values,\n",
    "                cmap='viridis',\n",
    "                yticklabels=nicknames,\n",
    "                xticklabels=np.round(time_points[::100], 1),  # Show fewer x-ticks\n",
    "                cbar_kws={'label': f'log({metric} + 1)'},\n",
    "                mask=np.isnan(matrix_values))\n",
    "    \n",
    "    plt.title(f'Activity Heatmap for {brain_region}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Nickname')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/ShortContacts/Activity_Heatmap_{brain_region}_Short.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brain_region in brain_regions:\n",
    "    subset_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    \n",
    "    # Create a matrix representation\n",
    "    # First, get unique nicknames and time points\n",
    "    nicknames = subset_data['Nickname'].unique()\n",
    "    time_points = np.arange(subset_data['start'].min(), subset_data['end'].max(), 0.1)  # Adjust step size as needed\n",
    "    \n",
    "    # Create empty matrix\n",
    "    matrix = np.zeros((len(nicknames), len(time_points)))\n",
    "    matrix_values = np.full_like(matrix, np.nan)\n",
    "    \n",
    "    # Fill matrix\n",
    "    for i, nickname in enumerate(nicknames):\n",
    "        nick_data = subset_data[subset_data['Nickname'] == nickname]\n",
    "        for _, row in nick_data.iterrows():\n",
    "            start_idx = int((row['start'] - time_points[0]) / 0.1)\n",
    "            end_idx = int((row['end'] - time_points[0]) / 0.1)\n",
    "            if start_idx < len(time_points) and end_idx < len(time_points):\n",
    "                matrix_values[i, start_idx:end_idx] = np.log1p(row[metric])\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, max(4, len(nicknames) * 0.3)))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(matrix_values,\n",
    "                cmap='viridis',\n",
    "                yticklabels=nicknames,\n",
    "                xticklabels=np.round(time_points[::100], 1),  # Show fewer x-ticks\n",
    "                cbar_kws={'label': f'log({metric} + 1)'},\n",
    "                mask=np.isnan(matrix_values))\n",
    "    \n",
    "    plt.title(f'Activity Heatmap for {brain_region}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Nickname')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brain_region in brain_regions:\n",
    "    subset_data = Transformed[Transformed['Brain region'] == brain_region]\n",
    "    \n",
    "    # Get unique flies sorted by nickname\n",
    "    flies_df = subset_data[['Nickname', 'fly']].drop_duplicates()\n",
    "    flies_df = flies_df.sort_values(['Nickname', 'fly'])\n",
    "    fly_labels = [f\"{row.Nickname}-{row.fly}\" for idx, row in flies_df.iterrows()]\n",
    "    \n",
    "    # Create time points array\n",
    "    time_points = np.arange(subset_data['start'].min(), subset_data['end'].max(), 0.1)\n",
    "    \n",
    "    # Create empty matrix\n",
    "    matrix = np.zeros((len(fly_labels), len(time_points)))\n",
    "    matrix_values = np.full_like(matrix, np.nan)\n",
    "    \n",
    "    # Fill matrix\n",
    "    for i, (_, fly_row) in enumerate(flies_df.iterrows()):\n",
    "        fly_data = subset_data[\n",
    "            (subset_data['Nickname'] == fly_row['Nickname']) & \n",
    "            (subset_data['fly'] == fly_row['fly'])\n",
    "        ]\n",
    "        for _, row in fly_data.iterrows():\n",
    "            start_idx = int((row['start'] - time_points[0]) / 0.1)\n",
    "            end_idx = int((row['end'] - time_points[0]) / 0.1)\n",
    "            if start_idx < len(time_points) and end_idx < len(time_points):\n",
    "                matrix_values[i, start_idx:end_idx] = np.log1p(row[metric])\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(15, max(4, len(fly_labels) * 0.3)))\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(matrix_values,\n",
    "                cmap='viridis',\n",
    "                yticklabels=fly_labels,\n",
    "                xticklabels=np.round(time_points[::100], 1),\n",
    "                cbar_kws={'label': f'log({metric} + 1)'},\n",
    "                mask=np.isnan(matrix_values))\n",
    "    \n",
    "    plt.title(f'Activity Heatmap for {brain_region}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Fly')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate contact rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one random Nickname and get a subset of it\n",
    "# Get unique Nicknames\n",
    "\n",
    "nicknames = Transformed['Nickname'].unique()\n",
    "\n",
    "# Pick a random Nickname\n",
    "\n",
    "nickname = np.random.choice(nicknames)\n",
    "\n",
    "print(f'Random Nickname: {nickname}')\n",
    "\n",
    "# Get the associated control\n",
    "\n",
    "split_value = Transformed[Transformed['Nickname'] == nickname]['Split'].iloc[0]\n",
    "\n",
    "associated_control = control_nicknames[split_value]\n",
    "\n",
    "print(f'Associated control is : {associated_control}')\n",
    "\n",
    "# Get the subset of the data for the random Nickname\n",
    "\n",
    "subset_data = Transformed[Transformed['Nickname'] == nickname]\n",
    "\n",
    "# Get the subset of the data for the associated control\n",
    "\n",
    "control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "\n",
    "# Combine the nickname data with the relevant control data\n",
    "\n",
    "subset_data = pd.concat([subset_data, control_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time window (e.g., 10 seconds)\n",
    "time_window = 100\n",
    "\n",
    "# Determine the maximum time in the dataset\n",
    "max_time = subset_data['start'].max()\n",
    "\n",
    "# Create bins for the time windows\n",
    "bins = np.arange(0, max_time + time_window, time_window)\n",
    "\n",
    "# Create a new column 'time_window' that indicates the time window each 'start' time belongs to\n",
    "subset_data['time_window'] = pd.cut(subset_data['start'], bins=bins, right=False, labels=bins[:-1])\n",
    "\n",
    "# Group by 'time_window', 'Brain region', and 'fly' and count the number of unique contacts in each time window\n",
    "contact_rate = subset_data.groupby(['time_window', 'Brain region', 'fly'])['identifier'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "contact_rate.columns = ['time_window', 'Brain region', 'fly', 'contact_count']\n",
    "\n",
    "# Plot the contact rate over time with confidence intervals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=contact_rate, x='time_window', y='contact_count', hue='Brain region', marker='o', palette=color_dict, ci='sd')\n",
    "plt.xlabel('Time Window (s)')\n",
    "plt.ylabel('Number of Unique Contacts')\n",
    "plt.title(f'Contact Rate Over Time for {nickname} vs {associated_control}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a rugplot of the start times for the random Nickname\n",
    "\n",
    "# Plot the subset data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the rugplot\n",
    "sns.kdeplot(data=subset_data, x='start', hue='Brain region', palette=color_dict)\n",
    "\n",
    "sns.rugplot(data=subset_data, x='start', hue='Brain region', palette=color_dict)\n",
    "\n",
    "# Set the title for the figure\n",
    "\n",
    "plt.title(f'Start Times for {nickname} vs {associated_control}')\n",
    "\n",
    "# Set the axis labels\n",
    "\n",
    "plt.xlabel('Start time')\n",
    "\n",
    "plt.ylabel('Nickname')\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique Nicknames and filter with some key words\n",
    "\n",
    "# Get unique Nicknames\n",
    "\n",
    "nicknames = Transformed['Nickname'].unique()\n",
    "\n",
    "# Filter Nicknames with some key words\n",
    "\n",
    "key_words = ['E-PG']\n",
    "\n",
    "filtered_nicknames = [nickname for nickname in nicknames if any(word in nickname for word in key_words)]\n",
    "\n",
    "# Print the filtered Nicknames\n",
    "\n",
    "print(filtered_nicknames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a specific Nickname and get a subset of it with the control group\n",
    "\n",
    "nickname = filtered_nicknames[0]\n",
    "\n",
    "print(f'Nickname: {nickname}')\n",
    "\n",
    "# Get the associated control\n",
    "\n",
    "split_value = Transformed[Transformed['Nickname'] == nickname]['Split'].iloc[0]\n",
    "\n",
    "associated_control = control_nicknames[split_value]\n",
    "\n",
    "print(f'Associated control is : {associated_control}')\n",
    "\n",
    "# Get the subset of the data for the random Nickname\n",
    "\n",
    "subset_data = Transformed[Transformed['Nickname'] == nickname]\n",
    "\n",
    "# Get the subset of the data for the associated control\n",
    "\n",
    "control_data = Transformed[Transformed['Nickname'] == associated_control]\n",
    "\n",
    "# Combine the nickname data with the relevant control data\n",
    "\n",
    "subset_data = pd.concat([subset_data, control_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time window (e.g., 1 second for finer granularity)\n",
    "time_window = 1\n",
    "\n",
    "# Determine the maximum time in the dataset\n",
    "max_time = subset_data['start'].max()\n",
    "\n",
    "# Create bins for the time windows\n",
    "bins = np.arange(0, max_time + time_window, time_window)\n",
    "\n",
    "# Create a new column 'time_window' that indicates the time window each 'start' time belongs to\n",
    "subset_data['time_window'] = pd.cut(subset_data['start'], bins=bins, right=False, labels=bins[:-1])\n",
    "\n",
    "# Group by 'time_window' and 'Nickname' and count the number of unique contacts in each time window\n",
    "contact_rate = subset_data.groupby(['time_window', 'Nickname'])['identifier'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "contact_rate.columns = ['time_window', 'Nickname', 'contact_count']\n",
    "\n",
    "# Calculate the cumulative sum of contacts over time for each Nickname\n",
    "contact_rate['cumulative_contact_count'] = contact_rate.groupby('Nickname')['contact_count'].cumsum()\n",
    "\n",
    "# Plot the subset data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the rugplot\n",
    "sns.rugplot(data=subset_data, y='Nickname', x='start', hue='Brain region', palette=color_dict)\n",
    "\n",
    "# Overlay the cumulative contacts curve\n",
    "for nickname in subset_data['Nickname'].unique():\n",
    "    nickname_data = contact_rate[contact_rate['Nickname'] == nickname]\n",
    "    brain_region = subset_data[subset_data['Nickname'] == nickname]['Brain region'].iloc[0]\n",
    "    color = color_dict[brain_region]\n",
    "    plt.plot(nickname_data['time_window'], nickname_data['cumulative_contact_count'], label=f'Cumulative Contacts for {nickname}', color=color)\n",
    "\n",
    "# Set the title for the figure\n",
    "plt.title(f'Start Times and Cumulative Contacts for {nickname} vs {associated_control}')\n",
    "\n",
    "# Set the axis labels\n",
    "plt.xlabel('Start time')\n",
    "plt.ylabel('Nickname')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time window (e.g., 10 seconds)\n",
    "time_window = 100\n",
    "\n",
    "# Determine the maximum time in the dataset\n",
    "max_time = subset_data['start'].max()\n",
    "\n",
    "# Create bins for the time windows\n",
    "bins = np.arange(0, max_time + time_window, time_window)\n",
    "\n",
    "# Create a new column 'time_window' that indicates the time window each 'start' time belongs to\n",
    "subset_data['time_window'] = pd.cut(subset_data['start'], bins=bins, right=False, labels=bins[:-1])\n",
    "\n",
    "# Group by 'time_window', 'Brain region', and 'fly' and count the number of unique contacts in each time window\n",
    "contact_rate = subset_data.groupby(['time_window', 'Brain region', 'fly'])['identifier'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "contact_rate.columns = ['time_window', 'Brain region', 'fly', 'contact_count']\n",
    "\n",
    "# Calculate the cumulative sum of contacts over time for each Brain region and fly\n",
    "contact_rate['cumulative_contact_count'] = contact_rate.groupby(['Brain region', 'fly'])['contact_count'].cumsum()\n",
    "\n",
    "# Plot the cumulative contact rate over time with confidence intervals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=contact_rate, x='time_window', y='cumulative_contact_count', hue='Brain region', marker='o', palette=color_dict, ci='sd')\n",
    "plt.xlabel('Time Window (s)')\n",
    "plt.ylabel('Cumulative Number of Contacts')\n",
    "plt.title('Cumulative Contact Rate Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250106_FinalEventCutoffData_norm/coordinates/250106_Pooled_coordinates.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories = pd.read_feather(\"/Users/ulric/Documents/250113_CoordinatesPlots/250106_Pooled_coordinates.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Coordinates/240110_coordinates_Data/coordinates/250106_Pooled_coordinates.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories [BallTrajectories[\"Brain region\"] == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Split column from the SplitRegistry to the Disp_Data, merging based on the Genotype column\n",
    "\n",
    "BallTrajectories = pd.merge(BallTrajectories, SplitRegistry, on='Genotype', how='left')\n",
    "\n",
    "BallTrajectories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Split values with the correct values\n",
    "\n",
    "# If the Nickname is \"GMR70G12-Gal4\" or \"MB247-Gal4\" or \"Ple-Gal4.F a.k.a TH-Gal4\" or \"DDC-gal4\", set the Split to \"n\"\n",
    "\n",
    "BallTrajectories.loc[BallTrajectories['Nickname'].isin(['GMR70G12-Gal4', 'MB247-Gal4', 'Ple-Gal4.F a.k.a TH-Gal4', 'DDC-gal4']), 'Split'] = 'n'\n",
    "\n",
    "# If the Nickname is \"TNTxPR\" or \"TNTxCS\", set the Split to \"m\"\n",
    "\n",
    "BallTrajectories.loc[BallTrajectories['Nickname'].isin(['TNTxPR', 'TNTxCS']), 'Split'] = 'm'\n",
    "\n",
    "# If the Nickname is \"SS32219-Gal4 (LAL-2)\" or \"SS32230-Gal4 (LAL-1)\"  , set the Split to \"y\"\n",
    "\n",
    "BallTrajectories.loc[BallTrajectories['Nickname'].isin(['SS32219-Gal4 (LAL-2)', 'SS32230-Gal4 (LAL-1)']), 'Split'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories=BallTrajectories[~BallTrajectories[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"CS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values in the Split column\n",
    "\n",
    "BallTrajectories['Split'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which Nicknames have NA values in the Split column\n",
    "\n",
    "BallTrajectories[BallTrajectories['Split'].isna()]['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the names of unique Brain regions\n",
    "\n",
    "BallTrajectories['Brain region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the one row with Brain region \"None\"\n",
    "\n",
    "BallTrajectories = BallTrajectories[BallTrajectories['Brain region'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallTrajectories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a color dictionary for the brain regions\n",
    "color_dict = {\n",
    "    'MB': '#1f77b4',  # Blue\n",
    "    'Vision': '#ff7f0e',  # Orange\n",
    "    'LH': '#2ca02c',  # Green\n",
    "    'Neuropeptide': '#d62728',  # Red\n",
    "    'Olfaction': '#9467bd',  # Purple\n",
    "    'MB extrinsic neurons': '#8c564b',  # Brown\n",
    "    'CX': '#e377c2',  # Pink\n",
    "    'Control': '#7f7f7f',  # Gray\n",
    "    'None': '#bcbd22',  # Yellow-green\n",
    "    'fchON': '#17becf',  # Cyan\n",
    "    'JON': '#ffbb78',  # Light orange\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames = BallTrajectories[BallTrajectories['Brain region'] == control_region]['Nickname'].unique()\n",
    "nicknames = BallTrajectories['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames]\n",
    "\n",
    "# Combine all nicknames for consistent coloring\n",
    "all_nicknames = list(control_nicknames) + nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique nicknames\n",
    "control_region = 'Control'\n",
    "control_nicknames_dict = {\n",
    "    'y': 'Empty-Split',\n",
    "    'n': 'Empty-Gal4',\n",
    "    'm': 'TNTxPR'\n",
    "}\n",
    "nicknames = BallTrajectories['Nickname'].unique()\n",
    "nicknames = [nickname for nickname in nicknames if nickname not in control_nicknames_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Group the data by Brain region\n",
    "brain_regions = BallTrajectories['Brain region'].unique()\n",
    "\n",
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "# Loop through each Brain region and create a separate figure\n",
    "for brain_region in brain_regions:\n",
    "    # Check if the plot is already created\n",
    "    if os.path.exists(f\"/Users/ulric/Documents/250113_CoordinatesPlots/Plots/Full_euclidean_distance_coordinates_line_{brain_region}.png\"):\n",
    "        print(f\"Skipping Brain region {brain_region} as the plot already exists.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # Subset the data for the current Brain region\n",
    "        region_data = BallTrajectories[BallTrajectories['Brain region'] == brain_region]\n",
    "        \n",
    "        # Get the unique nicknames for the current Brain region\n",
    "        nicknames = region_data['Nickname'].unique()\n",
    "        \n",
    "        # Calculate the number of rows and columns for the subplot grid\n",
    "        n_nicknames = len(nicknames)\n",
    "        n_cols = 5  # You can adjust this value\n",
    "        n_rows = math.ceil(n_nicknames / n_cols)\n",
    "        \n",
    "        # Create the main figure\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 30), squeeze=False)\n",
    "        \n",
    "        # Flatten the axes array for easier iteration\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Loop through each Nickname and create a subplot\n",
    "        for i, nickname in enumerate(nicknames):\n",
    "            # Subset the data for the current Nickname\n",
    "            nickname_data = region_data[region_data['Nickname'] == nickname]\n",
    "            \n",
    "            # Select the right control group based on the Split column\n",
    "            split_value = nickname_data['Split'].iloc[0]\n",
    "            associated_control = control_nicknames_dict[split_value]\n",
    "            \n",
    "            # Subset the data for the relevant control group\n",
    "            control_data = BallTrajectories[BallTrajectories['Nickname'] == associated_control]\n",
    "            \n",
    "            # Combine the nickname data with the relevant control data\n",
    "            subset_data = pd.concat([nickname_data, control_data])\n",
    "            \n",
    "            # Plot the distribution\n",
    "            sns.lineplot(data=subset_data, x='time', y='distance_ball_0', hue='Brain region', ax=axes[i], palette=color_dict)\n",
    "            \n",
    "            # Set the title for the subplot\n",
    "            axes[i].set_title(f'{nickname} vs {associated_control}')\n",
    "            axes[i].set_xlabel('Time (s)')\n",
    "            axes[i].set_ylabel('Median Euclidean Distance')\n",
    "            \n",
    "            #axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "        \n",
    "        # Remove any unused subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "        \n",
    "        # Adjust the layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig(f\"/Users/ulric/Documents/250113_CoordinatesPlots/Plots/Full_euclidean_distance_coordinates_line_{brain_region}.png\")\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Brain region {brain_region}: {e}\")\n",
    "        \n",
    "        # Skip to the next Brain region\n",
    "        \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming BallTrajectories and control_nicknames_dict are already defined\n",
    "# Assuming color_dict is already defined\n",
    "\n",
    "# Group the data by Brain region\n",
    "brain_regions = BallTrajectories['Brain region'].unique()\n",
    "\n",
    "# Initialize random generator\n",
    "rg = np.random.default_rng()\n",
    "\n",
    "def plot_brain_region(brain_region, test_mode=False):\n",
    "    # Check if the plot is already created\n",
    "    if os.path.exists(f\"/Users/ulric/Documents/250113_CoordinatesPlots/Plots/Full_euclidean_distance_coordinates_line_{brain_region}.png\") and not test_mode:\n",
    "        print(f\"Skipping Brain region {brain_region} as the plot already exists.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Subset the data for the current Brain region\n",
    "        region_data = BallTrajectories[BallTrajectories['Brain region'] == brain_region]\n",
    "        \n",
    "        # Get the unique nicknames for the current Brain region\n",
    "        nicknames = region_data['Nickname'].unique()\n",
    "        \n",
    "        # Calculate the number of rows and columns for the subplot grid\n",
    "        n_nicknames = len(nicknames)\n",
    "        n_cols = 5  # You can adjust this value\n",
    "        n_rows = math.ceil(n_nicknames / n_cols)\n",
    "        \n",
    "        # Create the main figure\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 30), squeeze=False)\n",
    "        \n",
    "        # Flatten the axes array for easier iteration\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Loop through each Nickname and create a subplot\n",
    "        for i, nickname in enumerate(nicknames):\n",
    "            \n",
    "            # Subset the data for the current Nickname\n",
    "            nickname_data = region_data[region_data['Nickname'] == nickname]\n",
    "            \n",
    "            nickname_contacts = Transformed[Transformed['Nickname'] == nickname]\n",
    "            \n",
    "            # Select the right control group based on the Split column\n",
    "            split_value = nickname_data['Split'].iloc[0]\n",
    "            associated_control = control_nicknames_dict[split_value]\n",
    "            \n",
    "            # Subset the data for the relevant control group\n",
    "            control_data = BallTrajectories[BallTrajectories['Nickname'] == associated_control]\n",
    "            \n",
    "            control_contacts = Transformed[Transformed['Nickname'] == associated_control]\n",
    "            \n",
    "            # Combine the nickname data with the relevant control data\n",
    "            subset_data = pd.concat([nickname_data, control_data])\n",
    "            \n",
    "            # for fly in subset_data['fly'].unique():\n",
    "            #     fly_data = subset_data[subset_data['fly'] == fly]\n",
    "                \n",
    "            #     sns.lineplot(data=fly_data, x='time', y='distance_ball_0', hue='Brain region', ax=axes[i], palette=color_dict, legend=False, alpha=0.3, linewidth=0.5)\n",
    "                \n",
    "            sns.lineplot(data=subset_data, x='time', y='distance_ball_0', hue='Brain region', ax=axes[i], palette=color_dict, legend=False)\n",
    "            \n",
    "            sns.rugplot(data=Transformed, x=\"start\", y ='y_centre_preprocessed_disp_mean_abs')\n",
    "            \n",
    "            # Set the title for the subplot\n",
    "            axes[i].set_title(f'{nickname} vs {associated_control}')\n",
    "            axes[i].set_xlabel('Time (s)')\n",
    "            axes[i].set_ylabel('Median Euclidean Distance')\n",
    "            \n",
    "            #axes[i].set_xlim(0, 105)  # Adjust the limits as needed\n",
    "        \n",
    "        # Remove any unused subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "        \n",
    "        # Adjust the layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        if not test_mode:\n",
    "            plt.savefig(f\"/Users/ulric/Documents/250113_CoordinatesPlots/Plots/Full_euclidean_distance_coordinates_line_{brain_region}.png\")\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Brain region {brain_region}: {e}\")\n",
    "        # Skip to the next Brain region\n",
    "        return\n",
    "\n",
    "# Loop through each Brain region and create a separate figure\n",
    "# for brain_region in brain_regions:\n",
    "# plot_brain_region(brain_region)\n",
    "\n",
    "# For testing, generate only one subplot of one brain region\n",
    "test_brain_region = brain_regions[0]  # Replace with the desired brain region for testing\n",
    "plot_brain_region(test_brain_region, test_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 1 hyperparameters: perplexity=200, n_iter=1000, learning_rate=50 with silhouette score: -0.7468554973602295\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index                                                fly  ... Period     FeedingState Orientation Light Crossing\n",
    "0          10.883230           4.286128  2358.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "1          14.873262          16.487293  2455.344828            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "2          10.413638          -9.487800  1282.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "3           9.715000           5.564195  2362.758621            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "4           6.091566          21.285728  2720.655172            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor3  ...   PM14  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 2 hyperparameters: perplexity=100, n_iter=1000, learning_rate=50 with silhouette score: -0.7539008259773254\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index                                                fly  ... Period     FeedingState Orientation Light Crossing\n",
    "0          -2.590610         -18.850389  2358.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "1         -16.094278         -17.977493  2455.344828            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "2           4.676276         -11.664147  1282.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "3          -4.964800         -19.879776  2362.758621            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "4         -26.672768          -2.390280  2720.655172            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor3  ...   PM14  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 3 hyperparameters: perplexity=30, n_iter=1000, learning_rate=10 with silhouette score: -0.7554223537445068\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index                                                fly  ... Period     FeedingState Orientation Light Crossing\n",
    "0           3.501854           8.184855  2358.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "1           7.610272           1.943969  2455.344828            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "2          -1.560529           1.416402  1282.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "3           3.533784           5.891675  2362.758621            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "4           0.626166           8.606694  2720.655172            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor3  ...   PM14  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 4 hyperparameters: perplexity=50, n_iter=1000, learning_rate=10 with silhouette score: -0.7574962973594666\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index                                                fly  ... Period     FeedingState Orientation Light Crossing\n",
    "0           5.886286          -7.026634  2358.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "1          -4.130479          -2.292409  2455.344828            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "2          -0.019282          -3.753843  1282.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "3           4.238248          -5.427169  2362.758621            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "4           8.526094           3.055508  2720.655172            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor3  ...   PM14  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 5 hyperparameters: perplexity=30, n_iter=1000, learning_rate=50 with silhouette score: -0.7613591551780701\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index                                                fly  ... Period     FeedingState Orientation Light Crossing\n",
    "0          18.628777           3.270475  2358.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "1          12.675018           8.562227  2455.344828            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "2           8.560286          -7.566420  1282.827586            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor1  ...   PM14  starved_noWater         std    on        1\n",
    "3          18.594709           7.787344  2362.758621            1.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor2  ...   PM14  starved_noWater         std    on        1\n",
    "4          -7.982295          -9.636993  2720.655172            0.0  231115_TNT_Fine_1_Videos_Tracked_arena1_corridor3  ...   PM14  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_Data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/TSNE/241220_behavior_map_perplexity_200_niter_1000_lr_50.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mac path\n",
    "\n",
    "TSNE_Data = pd.read_feather(\"/Users/ulric/Documents/TSNE/241220_behavior_map_perplexity_200_niter_1000_lr_50.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the t-SNE data using Seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset with only the \"Brain region\" == \"Control\" and plot it side by side with the \"Brain region\" != \"Control\"\n",
    "\n",
    "control_data = TSNE_Data[TSNE_Data['Brain region'] == 'Control']\n",
    "\n",
    "experimental_data = TSNE_Data[TSNE_Data['Brain region'] != 'Control']\n",
    "\n",
    "# Plot the t-SNE data using Seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=control_data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map - Control')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=experimental_data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map - Experimental')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid with one plot for each Brain region\n",
    "\n",
    "# Get unique brain regions\n",
    "\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(30, 30))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Brain region and create a subplot\n",
    "\n",
    "for i, region in enumerate(brain_regions):\n",
    "    \n",
    "    # Subset the data for the current Brain region\n",
    "\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'] == region]\n",
    "\n",
    "    # Plot the distribution\n",
    "\n",
    "    sns.scatterplot(data=subset_data, x='t-SNE Component 1', y='t-SNE Component 2', hue='Nickname', ax=axes[i])\n",
    "\n",
    "    # Set the title for the subplot\n",
    "\n",
    "    axes[i].set_title(region)\n",
    "\n",
    "    axes[i].set_xlabel('t-SNE1')\n",
    "\n",
    "    axes[i].set_ylabel('t-SNE2')\n",
    "    \n",
    "# Remove any unused subplots\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    \n",
    "    fig.delaxes(axes[j])\n",
    "    \n",
    "# Adjust the layout\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the same but with density plots\n",
    "\n",
    "# Get unique brain regions\n",
    "\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(30, 30))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each Brain region and create a subplot\n",
    "\n",
    "for i, region in enumerate(brain_regions):\n",
    "    \n",
    "    # Subset the data for the current Brain region\n",
    "\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'] == region]\n",
    "\n",
    "    # Plot the distribution\n",
    "\n",
    "    sns.kdeplot(data=subset_data, x='t-SNE Component 1', y='t-SNE Component 2', fill=True, ax=axes[i])\n",
    "\n",
    "    # Set the title for the subplot\n",
    "\n",
    "    axes[i].set_title(region)\n",
    "\n",
    "    axes[i].set_xlabel('t-SNE1')\n",
    "\n",
    "    axes[i].set_ylabel('t-SNE2')\n",
    "    \n",
    "# Remove any unused subplots\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    \n",
    "    fig.delaxes(axes[j])\n",
    "    \n",
    "    \n",
    "# Adjust the layout\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a density plot of the t-SNE data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', fill=True)\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Density Plot of Behavior Map')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Transformed' is your DataFrame and 'Brain region' is the column to subset by\n",
    "control_region = 'Control'  # Define the Control Brain region\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(brain_regions) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Loop through each brain region and create a subplot\n",
    "for i, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Get the current axis\n",
    "    ax = axes[i // n_cols, i % n_cols]\n",
    "    \n",
    "    # Plot the t-SNE data with different shapes for the control region\n",
    "    sns.scatterplot(data=subset_data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\", style=\"Brain region\", markers={'Control': 'X', region: 'o'}, ax=ax)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    ax.set_xlabel('t-SNE1')\n",
    "    ax.set_ylabel('t-SNE2')\n",
    "    ax.set_title(f't-SNE Plot: {region} vs Control')\n",
    "    ax.legend(title='Brain region', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j // n_cols, j % n_cols])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Extract t-SNE components\n",
    "x = TSNE_Data['t-SNE Component 1']\n",
    "y = TSNE_Data['t-SNE Component 2']\n",
    "\n",
    "# Compute the KDE\n",
    "kde = gaussian_kde([x, y], bw_method=0.05)\n",
    "\n",
    "# Evaluate the KDE on a grid\n",
    "xmin, xmax = x.min(), x.max()\n",
    "ymin, ymax = y.min(), y.max()\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "kde_values = kde(positions).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE and extract contour levels\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\")\n",
    "plt.colorbar(label=\"Density\")\n",
    "plt.title(\"KDE Contour Plot\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 5 density levels (darkest shades)\n",
    "top_levels = contour.levels[-12:]  # Adjust number of levels if needed\n",
    "threshold = top_levels[0]  # Use the lowest value of the top 5 levels as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the area of contour levels above the threshold\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, kde_values, levels=top_levels, cmap=\"Blues\")\n",
    "\n",
    "plt.colorbar(label=\"Density\")\n",
    "\n",
    "plt.title(\"KDE Contour Plot (Top 5 Levels)\")\n",
    "\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TSNE data with contour around the top 5 density levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=top_levels, colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo but get only the lowest contour level among the selected levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the distinct areas of the contour plot\n",
    "\n",
    "contour_areas = []\n",
    "\n",
    "for i in range(len(top_levels) - 1):\n",
    "    \n",
    "    # Get the area of the contour between the current and next levels\n",
    "    area = np.sum(kde_values * (kde_values >= top_levels[i]) * (kde_values < top_levels[i + 1]))\n",
    "    \n",
    "    contour_areas.append(area)\n",
    "    \n",
    "# Display the areas of the contour plot\n",
    "\n",
    "contour_areas\n",
    "\n",
    "# Find the indices of the points that are within the contour area\n",
    "\n",
    "points_in_contour = np.where(kde_values >= threshold)\n",
    "\n",
    "# Extract the x and y coordinates of the points within the contour area\n",
    "\n",
    "x_in_contour = xx[points_in_contour]\n",
    "\n",
    "y_in_contour = yy[points_in_contour]\n",
    "\n",
    "# Plot the points within the contour area\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(x_in_contour, y_in_contour, alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Points within the Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Extract t-SNE components\n",
    "x = TSNE_Data['t-SNE Component 1']\n",
    "y = TSNE_Data['t-SNE Component 2']\n",
    "\n",
    "# Compute the KDE\n",
    "kde = gaussian_kde([x, y], bw_method=0.05)\n",
    "\n",
    "# Evaluate the KDE on a grid\n",
    "xmin, xmax = x.min(), x.max()\n",
    "ymin, ymax = y.min(), y.max()\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "kde_values = kde(positions).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE and extract contour levels\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\")\n",
    "plt.colorbar(label=\"Density\")\n",
    "plt.title(\"KDE Contour Plot\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 5 density levels (darkest shades)\n",
    "top_levels = contour.levels[-12:]  # Adjust number of levels if needed\n",
    "threshold = top_levels[0]  # Use the lowest value of the top 5 levels as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the area of contour levels above the threshold\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, kde_values, levels=top_levels, cmap=\"Blues\")\n",
    "\n",
    "plt.colorbar(label=\"Density\")\n",
    "\n",
    "plt.title(\"KDE Contour Plot (Top 5 Levels)\")\n",
    "\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TSNE data with contour around the top 5 density levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=top_levels, colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo but get only the lowest contour level among the selected levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the distinct areas of the contour plot\n",
    "\n",
    "contour_areas = []\n",
    "\n",
    "for i in range(len(top_levels) - 1):\n",
    "    \n",
    "    # Get the area of the contour between the current and next levels\n",
    "    area = np.sum(kde_values * (kde_values >= top_levels[i]) * (kde_values < top_levels[i + 1]))\n",
    "    \n",
    "    contour_areas.append(area)\n",
    "    \n",
    "# Display the areas of the contour plot\n",
    "\n",
    "contour_areas\n",
    "\n",
    "# Find the indices of the points that are within the contour area\n",
    "\n",
    "points_in_contour = np.where(kde_values >= threshold)\n",
    "\n",
    "# Extract the x and y coordinates of the points within the contour area\n",
    "\n",
    "x_in_contour = xx[points_in_contour]\n",
    "\n",
    "y_in_contour = yy[points_in_contour]\n",
    "\n",
    "# Plot the points within the contour area\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(x_in_contour, y_in_contour, alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Points within the Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in_contour\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Create a binary mask for high-density areas\n",
    "high_density_mask = kde_values >= threshold\n",
    "\n",
    "# Label connected components in the binary mask\n",
    "labeled_array, num_features = label(high_density_mask)\n",
    "\n",
    "# Create subsets for each distinct area\n",
    "subsets = []\n",
    "for i in range(1, num_features + 1):\n",
    "    area_mask = labeled_array == i\n",
    "    x_in_area = xx[area_mask]\n",
    "    y_in_area = yy[area_mask]\n",
    "    \n",
    "    # Find points from the original dataset that fall within this area\n",
    "    points_in_area = TSNE_Data[\n",
    "        (TSNE_Data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] <= y_in_area.max())\n",
    "    ]\n",
    "    \n",
    "    # If the area is not empty, save it to a subset list and a file\n",
    "    \n",
    "    if len(points_in_area) > 0:\n",
    "        #points_in_area.to_feather(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/Cluster_data/241210_behavior_map_tsne_area_{i}.feather\")\n",
    "        subsets.append(points_in_area)\n",
    "    \n",
    "    \n",
    "\n",
    "# Plot each distinct area with a different color\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\", alpha=0.3)\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, num_features))\n",
    "for i, subset in enumerate(subsets):\n",
    "    plt.scatter(subset['t-SNE Component 1'], subset['t-SNE Component 2'], \n",
    "                color=colors[i], label=f'Area {i+1}', alpha=0.6)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Distinct High-Density Areas in t-SNE Plot')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print information about each subset\n",
    "for i, subset in enumerate(subsets):\n",
    "    print(f\"Area {i+1}: {len(subset)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Create a binary mask for high-density areas\n",
    "high_density_mask = kde_values >= threshold\n",
    "\n",
    "# Label connected components in the binary mask\n",
    "labeled_array, num_features = label(high_density_mask)\n",
    "\n",
    "# Create subsets for each distinct area\n",
    "subsets = []\n",
    "for i in range(1, num_features + 1):\n",
    "    area_mask = labeled_array == i\n",
    "    x_in_area = xx[area_mask]\n",
    "    y_in_area = yy[area_mask]\n",
    "    \n",
    "    # Find points from the original dataset that fall within this area\n",
    "    points_in_area = TSNE_Data[\n",
    "        (TSNE_Data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] <= y_in_area.max())\n",
    "    ]\n",
    "    \n",
    "    # If the area is not empty, \n",
    "    # it to a subset list and a file\n",
    "    if len(points_in_area) > 0:\n",
    "        #points_in_area.to_feather(f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/Cluster_data/241210_behavior_map_tsne_area_{i}.feather\")\n",
    "        subsets.append(points_in_area)\n",
    "\n",
    "# Calculate the proportion of points for each \"Nickname\" within each high-density area\n",
    "nickname_proportions = {}\n",
    "\n",
    "for i, subset in enumerate(subsets):\n",
    "    area_name = f'Area {i+1}'\n",
    "    nickname_counts = subset['Nickname'].value_counts()\n",
    "    total_points = len(subset)\n",
    "    \n",
    "    for nickname, count in nickname_counts.items():\n",
    "        if nickname not in nickname_proportions:\n",
    "            nickname_proportions[nickname] = {}\n",
    "        nickname_proportions[nickname][area_name] = count / total_points\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier analysis\n",
    "nickname_proportions_df = pd.DataFrame(nickname_proportions).fillna(0)\n",
    "\n",
    "# Plot the proportions for each Nickname\n",
    "nickname_proportions_df.T.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "plt.title('Proportion of Points in High-Density Areas by Nickname')\n",
    "plt.xlabel('Nickname')\n",
    "plt.ylabel('Proportion of Points')\n",
    "# plt.invert_xaxis()\n",
    "# plt.invert_yaxis()\n",
    "plt.legend(title='High-Density Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Contacts/BehaviorProps.png\")\n",
    "#plt.show()\n",
    "\n",
    "# Print the proportions for each Nickname\n",
    "print(nickname_proportions_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the control region and get unique brain regions\n",
    "control_region = 'Control'\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]\n",
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_regions = len(brain_regions)\n",
    "n_cols = 3  # You can adjust this value\n",
    "n_rows = math.ceil(n_regions / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 6*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Create subsets for each distinct area\n",
    "    area_counts = {}\n",
    "    for i in range(1, num_features + 1):\n",
    "        area_mask = labeled_array == i\n",
    "        x_in_area = xx[area_mask]\n",
    "        y_in_area = yy[area_mask]\n",
    "\n",
    "        points_in_area = subset_data[\n",
    "            (subset_data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "            (subset_data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 2'] <= y_in_area.max())\n",
    "        ]\n",
    "\n",
    "        if len(points_in_area) > 0:\n",
    "            area_name = f'Area {i}'\n",
    "            nickname_counts = points_in_area['Nickname'].value_counts()\n",
    "            area_counts[area_name] = nickname_counts\n",
    "\n",
    "    # Combine all area counts into a single DataFrame\n",
    "    combined_counts = pd.DataFrame(area_counts).fillna(0)\n",
    "\n",
    "    # Calculate the total count for each Nickname\n",
    "    total_counts = combined_counts.sum(axis=1)\n",
    "\n",
    "    # Normalize counts to get proportions\n",
    "    normalized_proportions = combined_counts.div(total_counts, axis=0)\n",
    "\n",
    "    # Plot the normalized proportions\n",
    "    ax = axes_flat[idx]\n",
    "    normalized_proportions.plot(kind='barh', stacked=True, ax=ax)\n",
    "    ax.set_title(f'{region} vs {control_region}')\n",
    "    ax.set_xlabel('Proportion of Points')\n",
    "    ax.set_ylabel('Nickname')\n",
    "    ax.legend(title='High-Density Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Adjust layout for better readability\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(idx+1, len(axes_flat)):\n",
    "    fig.delaxes(axes_flat[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Contacts/BehaviorProps_Grid.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print the proportions for each Nickname (optional)\n",
    "#print(combined_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import label\n",
    "import math\n",
    "\n",
    "# Assuming TSNE_Data, labeled_array, xx, yy, and num_features are already defined\n",
    "\n",
    "# Create a list to store the data for each contact\n",
    "contacts_data = []\n",
    "\n",
    "# Define the control region and get unique brain regions\n",
    "control_region = 'Control'\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]\n",
    "\n",
    "for region in brain_regions:\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Create subsets for each distinct area\n",
    "    for i in range(1, num_features + 1):\n",
    "        area_mask = labeled_array == i\n",
    "        x_in_area = xx[area_mask]\n",
    "        y_in_area = yy[area_mask]\n",
    "\n",
    "        points_in_area = subset_data[\n",
    "            (subset_data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "            (subset_data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 2'] <= y_in_area.max())\n",
    "        ]\n",
    "\n",
    "        if len(points_in_area) > 0:\n",
    "            area_name = f'Area {i}'\n",
    "            for _, row in points_in_area.iterrows():\n",
    "                contact_info = row.to_dict()\n",
    "                contact_info['Area'] = area_name\n",
    "                contacts_data.append(contact_info)\n",
    "\n",
    "# Create a DataFrame from the contacts data\n",
    "contacts_df = pd.DataFrame(contacts_data)\n",
    "\n",
    "contacts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming contacts_df is already defined and contains a 'fly' column\n",
    "\n",
    "# Calculate the total number of contacts for each fly\n",
    "total_contacts_per_fly = contacts_df.groupby('fly').size()\n",
    "\n",
    "# Calculate the number of contacts for each fly in each Area\n",
    "contacts_per_area_fly = contacts_df.groupby(['Area', 'fly']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportion of contacts in each Area for each fly\n",
    "proportions_per_area_fly = contacts_per_area_fly.div(total_contacts_per_fly, axis=1).fillna(0)\n",
    "\n",
    "# Transpose the DataFrame to get the 'fly' values back as a column\n",
    "proportions_per_area_fly = proportions_per_area_fly.T\n",
    "\n",
    "# Reset the index to convert the DataFrame to a long format suitable for merging with metadata\n",
    "proportions_long = proportions_per_area_fly.reset_index().rename(columns={'index': 'fly'})\n",
    "\n",
    "# Ensure the 'fly' column is present in proportions_long\n",
    "#print(\"Columns in proportions_long:\", proportions_long.columns)\n",
    "\n",
    "# Merge the proportions with the metadata\n",
    "metadata = contacts_df[['fly', 'Nickname', 'Brain region']].drop_duplicates().set_index('fly')\n",
    "#print(\"Metadata index:\", metadata.index)\n",
    "\n",
    "proportions_with_metadata = proportions_long.merge(metadata, left_on='fly', right_index=True)\n",
    "\n",
    "# Print the first few rows of the new dataset\n",
    "#print(proportions_with_metadata.head())\n",
    "\n",
    "# Now you can use this dataset for further analysis or visualization\n",
    "# For example, create a boxplot with the proportions, using the Nickname as the hue\n",
    "proportions_melted = proportions_with_metadata.melt(id_vars=['fly', 'Nickname', 'Brain region'], var_name='Area', value_name='Proportion')\n",
    "\n",
    "\n",
    "proportions_melted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use this dataset for further analysis or visualization\n",
    "# For example, create a boxplot with the proportions, using the Nickname as the hue\n",
    "proportions_melted = proportions_with_metadata.melt(id_vars=['fly', 'Nickname', 'Brain region'], var_name='Area', value_name='Proportion')\n",
    "\n",
    "# Create a grid of boxplots with one plot per Brain region\n",
    "g = sns.FacetGrid(proportions_melted, col='Brain region', col_wrap=3, height=4, sharey=False)\n",
    "g.map_dataframe(sns.boxplot, x='Area', y='Proportion', hue='Nickname', palette='Set2')\n",
    "g.add_legend(title='Nickname')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.set_axis_labels('Area', 'Proportion of Contacts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create individual plots for each Area\n",
    "unique_areas = proportions_melted['Area'].unique()\n",
    "\n",
    "for area in unique_areas:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='Brain region', y='Proportion', hue='Nickname', data=proportions_melted[proportions_melted['Area'] == area], palette='Set2')\n",
    "    plt.title(f'Proportion of Contacts in {area} by Brain Region and Nickname')\n",
    "    plt.xlabel('Brain Region')\n",
    "    plt.ylabel('Proportion of Contacts')\n",
    "    plt.legend(title='Nickname', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique Nicknames associated with Brain region \"Control\"\n",
    "\n",
    "proportions_melted[proportions_melted['Brain region'] == 'Control']['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['TNTxCS', 'TNTxPR', 'Empty-Gal4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Area1 = proportions_melted[proportions_melted['Area'] == 'Area 1']\n",
    "\n",
    "Area1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPlot = HoloviewsTemplates.jitter_boxplot(data=Area1, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"grouped\",groupby='Brain region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(TestPlot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/Area1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the plots\n",
    "plots = []\n",
    "\n",
    "# Loop through each area and generate the plot\n",
    "for area in nickname_proportions_df.index:\n",
    "    area_data = proportions_melted[proportions_melted['Area'] == area]\n",
    "    \n",
    "    # Check if there are controls in the subset\n",
    "    if not any(control in area_data['Nickname'].unique() for control in controls):\n",
    "        print(f\"No controls found in {area}, skipping this area.\")\n",
    "        continue\n",
    "    \n",
    "    plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot', render=\"grouped\", groupby='Brain region')\n",
    "    plot.opts(title=f'Proportion of Points in {area}')\n",
    "    plots.append(plot)\n",
    "\n",
    "# Combine the plots into a layout\n",
    "layout = hv.Layout(plots).cols(3)\n",
    "\n",
    "# Save the layout to an HTML file\n",
    "hv.save(layout, '/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/proportion_plots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the plots\n",
    "plots = []\n",
    "\n",
    "# Loop through each area and generate the plot\n",
    "for area in nickname_proportions_df.index:\n",
    "    area_data = proportions_melted[proportions_melted['Area'] == area]\n",
    "    \n",
    "    # Check if there are controls in the subset\n",
    "    has_controls = any(control in area_data['Nickname'].unique() for control in controls)\n",
    "    \n",
    "    if has_controls:\n",
    "        plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot', render=\"grouped\", groupby='Brain region')\n",
    "        plot = plot.opts(title=f'Proportion of Points in {area}')\n",
    "    else:\n",
    "        plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=None, hline=None, render=\"grouped\", groupby='Brain region')\n",
    "        plot = plot.opts(title=f'Proportion of Points in {area} (No Controls)', fontsize={'title': '12pt'})\n",
    "        annotation = hv.Text(0.5, 0.5, 'No Controls', halign='center', valign='center').opts(style=dict(text_font_size='20pt', text_color='red'))\n",
    "        plot = plot * annotation\n",
    "    \n",
    "    plot.opts(title=f'Proportion of Points in {area}')\n",
    "    plots.append(plot)\n",
    "\n",
    "# Combine the plots into a layout\n",
    "layout = hv.Layout(plots).cols(3)\n",
    "\n",
    "# Save the layout to an HTML file\n",
    "hv.save(layout, '/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/proportion_plots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's focus on areas instead of brain regions\n",
    "\n",
    "Area14 = proportions_melted[proportions_melted['Area'] == 'Area 14']\n",
    "\n",
    "Area14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pooled14 = HoloviewsTemplates.jitter_boxplot(data=Area1, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"pooled\",colorby='Brain region')\n",
    "\n",
    "hv.save(Pooled14, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/Area14.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AreaNum = 10\n",
    "\n",
    "AreaData = proportions_melted[proportions_melted['Area'] == f'Area {AreaNum}']\n",
    "\n",
    "PooledArea = HoloviewsTemplates.jitter_boxplot(data=AreaData, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"pooled\",colorby='Brain region')\n",
    "\n",
    "hv.save(PooledArea, f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/Area{AreaNum}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming proportions_with_metadata is already defined\n",
    "\n",
    "# Define the control region and control nicknames\n",
    "control_region = 'Control'  # Replace with your actual control region\n",
    "control_nicknames = ['Empty-Gal4']  # Replace with your actual control nicknames\n",
    "\n",
    "# Calculate baseline for the subset of control Nicknames\n",
    "control_data = proportions_with_metadata[(proportions_with_metadata['Brain region'] == control_region) & (proportions_with_metadata['Nickname'].isin(control_nicknames))]\n",
    "control_proportions = control_data.drop(columns=['fly', 'Nickname', 'Brain region']).set_index(control_data['fly'])\n",
    "control_proportions = control_proportions.div(control_proportions.sum(axis=1), axis=0)\n",
    "\n",
    "baseline_mean = control_proportions.mean()\n",
    "baseline_std = control_proportions.std()\n",
    "\n",
    "print(\"Baseline Mean:\")\n",
    "print(baseline_mean)\n",
    "print(\"Baseline Std:\")\n",
    "print(baseline_std)\n",
    "\n",
    "# Function to calculate z-scores\n",
    "def calculate_zscore(row):\n",
    "    return (row - baseline_mean) / baseline_std\n",
    "\n",
    "# Calculate z-scores for all flies\n",
    "fly_proportions = proportions_with_metadata.drop(columns=['Brain region']).set_index('fly')\n",
    "fly_proportions = fly_proportions.div(fly_proportions.sum(axis=1), axis=0)\n",
    "zscores = fly_proportions.drop(columns=['Nickname']).apply(calculate_zscore, axis=1)\n",
    "\n",
    "print(\"Z-Scores:\")\n",
    "print(zscores.head())\n",
    "\n",
    "# Group the z-scores by Nickname and calculate the mean z-scores for each Nickname\n",
    "nickname_zscores = zscores.reset_index().groupby('Nickname').mean()\n",
    "\n",
    "print(\"Nickname Z-Scores:\")\n",
    "print(nickname_zscores.head())\n",
    "\n",
    "# Function to identify significant deviations\n",
    "def identify_significant_deviations(zscores, threshold):\n",
    "    significant_deviations = (zscores.abs() > threshold)\n",
    "    return significant_deviations[significant_deviations.any(axis=1)]\n",
    "\n",
    "# Try different thresholds\n",
    "thresholds = [3.0, 2.5, 2.0, 1.96, 1.65, 1.5]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    significant_deviations = identify_significant_deviations(nickname_zscores, threshold)\n",
    "    \n",
    "    if not significant_deviations.empty:\n",
    "        print(f\"\\nSignificant deviations (threshold = {threshold}):\")\n",
    "        for nickname in significant_deviations.index:\n",
    "            sig_areas = significant_deviations.loc[nickname][significant_deviations.loc[nickname]]\n",
    "            if not sig_areas.empty:\n",
    "                print(f\"  {nickname}:\")\n",
    "                for area in sig_areas.index:\n",
    "                    print(f\"    {area}: z-score = {nickname_zscores.loc[nickname, area]:.2f}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"No significant deviations found even at the lowest threshold.\")\n",
    "\n",
    "# Visualize the z-scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(nickname_zscores, cmap='RdBu_r', center=0, vmin=-3, vmax=3)\n",
    "plt.title('Z-scores of Area Proportions (Compared to Subset of Control Baseline)')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Contacts/Zscore_Heatmap_Subset_Controls.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(nickname_zscores.abs().max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique Nicknames associated with Brain region \"Control\"\n",
    "\n",
    "proportions_with_metadata[proportions_with_metadata['Brain region'] == 'Control']['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and control nicknames\n",
    "control_region = 'Control'  # Replace with your actual control region\n",
    "control_nicknames = ['Empty-Gal4']  # Replace with your actual control nicknames\n",
    "\n",
    "control_subset = proportions_melted[proportions_melted[\"Nickname\"].isin(control_nicknames)]\n",
    "\n",
    "control_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for area in proportions_melted[\"Area\"].unique():\n",
    "    \n",
    "    controls = control_subset[control_subset[\"Area\"] == area]\n",
    "    \n",
    "    control_baseline = controls[\"Proportion\"].mean()\n",
    "    control_std = controls[\"Proportion\"].std()\n",
    "    \n",
    "    proportions_melted[\"Z-Score\"] = (proportions_melted[\"Proportion\"] - control_baseline) / control_std\n",
    "    \n",
    "    # Get average Z-Score for each Nickname\n",
    "    \n",
    "    z_scores = proportions_melted.groupby(\"Nickname\")[\"Z-Score\"].mean()\n",
    "    \n",
    "    # Get the Nicknames with Z-Scores above a certain threshold\n",
    "    \n",
    "    threshold = 3.0\n",
    "    \n",
    "    significant_nicknames = z_scores[abs(z_scores) > threshold]\n",
    "    \n",
    "    print(f\"Significant Nicknames for Area {area}:\")\n",
    "    \n",
    "    for nickname, z_score in significant_nicknames.items():\n",
    "        print(f\"  {nickname}: Z-Score = {z_score:.2f}\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming proportions_melted and control_subset are already defined\n",
    "\n",
    "# Initialize an empty DataFrame to store the Z-scores\n",
    "z_scores_df = pd.DataFrame()\n",
    "\n",
    "# Calculate Z-scores for each area\n",
    "for area in proportions_melted[\"Area\"].unique():\n",
    "    \n",
    "    controls = control_subset[control_subset[\"Area\"] == area]\n",
    "    \n",
    "    control_baseline = controls[\"Proportion\"].mean()\n",
    "    control_std = controls[\"Proportion\"].std()\n",
    "    \n",
    "    proportions_melted[\"Z-Score\"] = (proportions_melted[\"Proportion\"] - control_baseline) / control_std\n",
    "    \n",
    "    # Get average Z-Score for each Nickname\n",
    "    z_scores = proportions_melted.groupby([\"Brain region\", \"Nickname\", \"Area\"])[\"Z-Score\"].mean().reset_index()\n",
    "    \n",
    "    # Append to the Z-scores DataFrame\n",
    "    z_scores_df = pd.concat([z_scores_df, z_scores], ignore_index=True)\n",
    "\n",
    "# Pivot the DataFrame to get a matrix of Z-scores with Nicknames and Brain regions\n",
    "z_scores_pivot = z_scores_df.pivot_table(index=[\"Nickname\", \"Brain region\"], columns=\"Area\", values=\"Z-Score\")\n",
    "\n",
    "# Get the unique Brain regions\n",
    "brain_regions = z_scores_df[\"Brain region\"].unique()\n",
    "\n",
    "# Create a grid of heatmaps, one for each Brain region\n",
    "n_cols = 3  # Number of columns in the grid\n",
    "n_rows = int(np.ceil(len(brain_regions) / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(25, 7 * n_rows), squeeze=False)\n",
    "\n",
    "for i, brain_region in enumerate(brain_regions):\n",
    "    ax = axes[i // n_cols, i % n_cols]\n",
    "    brain_region_data = z_scores_pivot.xs(brain_region, level='Brain region')\n",
    "    sns.heatmap(brain_region_data, cmap='RdBu_r', center=0, vmin=-3, vmax=3, annot=False, fmt=\".2f\", ax=ax)\n",
    "    ax.set_title(f'Brain Region: {brain_region}')\n",
    "    ax.set_xlabel('Area')\n",
    "    ax.set_ylabel('Nickname')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j // n_cols, j % n_cols])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/ulric/Pictures/TSNE_TNT/Zscore_heatmaps.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(z_scores_pivot.abs().max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscore(row):\n",
    "    return (row - baseline_mean) / baseline_std\n",
    "\n",
    "zscore_df = normalized_proportions.apply(calculate_zscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "significant_deviations = (zscore_df.abs() > threshold).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(zscore_df, cmap='RdBu_r', center=0, vmin=-3, vmax=3)\n",
    "plt.title('Z-scores of Area Proportions (Compared to Control Baseline)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nickname in zscore_df.index[significant_deviations]:\n",
    "    significant_areas = zscore_df.loc[nickname][zscore_df.loc[nickname].abs() > threshold]\n",
    "    print(f\"Nickname: {nickname}\")\n",
    "    for area, zscore in significant_areas.items():\n",
    "        print(f\"  {area}: z-score = {zscore:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(brain_regions) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Loop through each brain region and create a subplot\n",
    "for i, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = nickname_proportions_df.loc[:, [control_region, region]].T\n",
    "    \n",
    "    # Get the current axis\n",
    "    ax = axes[i // n_cols, i % n_cols]\n",
    "    \n",
    "    # Plot the proportions for each Nickname\n",
    "    subset_data.plot(kind='bar', stacked=True, ax=ax)\n",
    "    \n",
    "    # Set plot labels and title\n",
    "    ax.set_title(f'Proportion of Points in High-Density Areas: {region} vs Control')\n",
    "    ax.set_xlabel('Nickname')\n",
    "    ax.set_ylabel('Proportion of Points')\n",
    "    ax.legend(title='High-Density Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Invert the axes\n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, n_rows * n_cols):\n",
    "    fig.delaxes(axes[j // n_cols, j % n_cols])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the proportions for each Nickname\n",
    "print(nickname_proportions_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source data \n",
    "\n",
    "source_data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/241209_ContactData/241209_Pooled_contact_data.feather\")\n",
    "\n",
    "source_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data based on the threshold\n",
    "\n",
    "dense_data = TSNE_Data[kde([x, y]) > threshold]\n",
    "\n",
    "# Plot the dense data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=dense_data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Dense Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-density regions based on threshold\n",
    "high_density_mask = kde_values > threshold\n",
    "high_density_coords = positions[:, high_density_mask.ravel()].T\n",
    "\n",
    "# Fine-tune DBSCAN parameters with a grid search\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "max_clusters = 0\n",
    "\n",
    "eps_values = np.arange(1.0, 20.0, 1.0)  # Adjust step size as needed\n",
    "min_samples_values = range(3, 10)\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        clusters = dbscan.fit_predict(high_density_coords)\n",
    "        n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)  # Exclude noise\n",
    "\n",
    "        if n_clusters > max_clusters:\n",
    "            max_clusters = n_clusters\n",
    "            best_eps = eps\n",
    "            best_min_samples = min_samples\n",
    "\n",
    "# Apply DBSCAN with the best parameters found\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "clusters = dbscan.fit_predict(high_density_coords)\n",
    "\n",
    "# Assign clusters to original data points using nearest neighbors\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(high_density_coords)\n",
    "\n",
    "distances, indices = nn.kneighbors(np.column_stack([x, y]))\n",
    "TSNE_Data['cluster'] = -1  # Initialize with -1 (noise)\n",
    "for i, dist in enumerate(distances):\n",
    "    if dist[0] < best_eps:  # Use best_eps as distance threshold\n",
    "        TSNE_Data.at[i, 'cluster'] = clusters[indices[i][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid plot with each subplot being one brain region\n",
    "\n",
    "g = sns.FacetGrid(TSNE_Data, col='Brain region', col_wrap=3, height=4)\n",
    "\n",
    "g.map(sns.scatterplot, 't-SNE Component 1', 't-SNE Component 2')\n",
    "\n",
    "g.set_axis_labels('t-SNE1', 't-SNE2')\n",
    "\n",
    "g.set_titles('Brain Region: {col_name}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same but with density plots\n",
    "\n",
    "g = sns.FacetGrid(TSNE_Data, col='Brain region', col_wrap=3, height=4)\n",
    "\n",
    "g.map(sns.kdeplot, 't-SNE Component 1', 't-SNE Component 2', fill=True)\n",
    "\n",
    "g.set_axis_labels('t-SNE1', 't-SNE2')\n",
    "\n",
    "g.set_titles('Brain Region: {col_name}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = Path(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/TSNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all feather files in the source folder\n",
    "datasets = list(source_folder.glob(\"*.feather\"))\n",
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = (len(datasets) + n_cols - 1) // n_cols\n",
    "\n",
    "# Create a figure and axes for the grid of plots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each dataset and create a subplot\n",
    "for i, dataset_path in enumerate(datasets):\n",
    "    # Load the dataset\n",
    "    TSNE_Data = pd.read_feather(dataset_path)\n",
    "    \n",
    "    # Create a scatter plot for the t-SNE data\n",
    "    sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', ax=axes[i])\n",
    "    \n",
    "    # Set the title for the subplot\n",
    "    axes[i].set_title(dataset_path.stem)\n",
    "    axes[i].set_xlabel('t-SNE1')\n",
    "    axes[i].set_ylabel('t-SNE2')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source PCA\n",
    "PCA_results = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/PCA/241210_pca_data_transformed_New.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2 first components of the PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=PCA_results, x='PCA Component 1', y='PCA Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "plt.title('PCA Plot of Behavior Map')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " PCA_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New contact detection\n",
    "\n",
    "\n",
    "Top 1 hyperparameters: perplexity=50, n_iter=1000, learning_rate=10 with silhouette score: -0.5253688097000122\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index  ...     FeedingState Orientation Light Crossing\n",
    "0          -0.796520          -7.562983   394.551724           11.0  ...  starved_noWater         std    on        1\n",
    "1          -7.100704           2.590583  1319.103448            1.0  ...  starved_noWater         std    on        1\n",
    "2          -5.851017          -4.949097  2744.896552            3.0  ...  starved_noWater         std    on        1\n",
    "3          -3.388800           1.686573   843.344828           19.0  ...  starved_noWater         std    on        1\n",
    "4          -0.277017           1.683173  3526.310345           17.0  ...  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 2 hyperparameters: perplexity=200, n_iter=5000, learning_rate=50 with silhouette score: -0.5325548052787781\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index  ...     FeedingState Orientation Light Crossing\n",
    "0          55.607502         -26.979675   394.551724           11.0  ...  starved_noWater         std    on        1\n",
    "1          10.197291          46.760166  1319.103448            1.0  ...  starved_noWater         std    on        1\n",
    "2         -72.722794         -18.586565  2744.896552            3.0  ...  starved_noWater         std    on        1\n",
    "3          48.255417          34.470398   843.344828           19.0  ...  starved_noWater         std    on        1\n",
    "4          -7.197774          36.139503  3526.310345           17.0  ...  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 3 hyperparameters: perplexity=50, n_iter=5000, learning_rate=100 with silhouette score: -0.5325877070426941\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index  ...     FeedingState Orientation Light Crossing\n",
    "0           1.066561          98.725868   394.551724           11.0  ...  starved_noWater         std    on        1\n",
    "1         -53.978603           8.107977  1319.103448            1.0  ...  starved_noWater         std    on        1\n",
    "2           5.527220         -24.406395  2744.896552            3.0  ...  starved_noWater         std    on        1\n",
    "3         -47.274208          17.580278   843.344828           19.0  ...  starved_noWater         std    on        1\n",
    "4          13.933846           8.760972  3526.310345           17.0  ...  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 4 hyperparameters: perplexity=200, n_iter=1000, learning_rate=100 with silhouette score: -0.5335649847984314\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index  ...     FeedingState Orientation Light Crossing\n",
    "0          -8.378110          -8.162753   394.551724           11.0  ...  starved_noWater         std    on        1\n",
    "1           8.194536           9.751060  1319.103448            1.0  ...  starved_noWater         std    on        1\n",
    "2         -22.439581         -24.771296  2744.896552            3.0  ...  starved_noWater         std    on        1\n",
    "3          -1.444729           8.410954   843.344828           19.0  ...  starved_noWater         std    on        1\n",
    "4           7.490497           3.037580  3526.310345           17.0  ...  starved_noWater         std    on        1\n",
    "\n",
    "[5 rows x 16 columns]\n",
    "Top 5 hyperparameters: perplexity=50, n_iter=1000, learning_rate=100 with silhouette score: -0.5589737892150879\n",
    "   t-SNE Component 1  t-SNE Component 2        start  contact_index  ...     FeedingState Orientation Light Crossing\n",
    "0           5.109833         -26.232237   394.551724           11.0  ...  starved_noWater         std    on        1\n",
    "1         -19.058266           1.213729  1319.103448            1.0  ...  starved_noWater         std    on        1\n",
    "2          14.584683         -33.341496  2744.896552            3.0  ...  starved_noWater         std    on        1\n",
    "3          -9.849553          -2.875611   843.344828           19.0  ...  starved_noWater         std    on        1\n",
    "4          -9.443474           6.185652  3526.310345           17.0  ...  starved_noWater         std    on        1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_Data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/TSNE/250107_behavior_map_perplexity_50_niter_5000_lr_100.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the t-SNE data using Seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset with only the \"Brain region\" == \"Control\" and plot it side by side with the \"Brain region\" != \"Control\"\n",
    "\n",
    "control_data = TSNE_Data[TSNE_Data['Brain region'] == 'Control']\n",
    "\n",
    "experimental_data = TSNE_Data[TSNE_Data['Brain region'] != 'Control']\n",
    "\n",
    "# Plot the t-SNE data using Seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=control_data, x='t-SNE Component 1', y='t-SNE Component 2', hue=\"Brain region\")\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map - Control')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract t-SNE components\n",
    "x = TSNE_Data['t-SNE Component 1']\n",
    "y = TSNE_Data['t-SNE Component 2']\n",
    "\n",
    "# Compute the KDE\n",
    "kde = gaussian_kde([x, y], bw_method=0.05)\n",
    "\n",
    "# Evaluate the KDE on a grid\n",
    "xmin, xmax = x.min(), x.max()\n",
    "ymin, ymax = y.min(), y.max()\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "kde_values = kde(positions).reshape(xx.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the KDE and extract contour levels\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\")\n",
    "plt.colorbar(label=\"Density\")\n",
    "plt.title(\"KDE Contour Plot\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the top 5 density levels (darkest shades)\n",
    "top_levels = contour.levels[-12:]  # Adjust number of levels if needed\n",
    "threshold = top_levels[0]  # Use the lowest value of the top 5 levels as threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the area of contour levels above the threshold\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, kde_values, levels=top_levels, cmap=\"Blues\")\n",
    "\n",
    "plt.colorbar(label=\"Density\")\n",
    "\n",
    "plt.title(\"KDE Contour Plot (Top 5 Levels)\")\n",
    "\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the TSNE data with contour around the top 5 density levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=top_levels, colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Redo but get only the lowest contour level among the selected levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=TSNE_Data, x='t-SNE Component 1', y='t-SNE Component 2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('t-SNE Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a list of the distinct areas of the contour plot\n",
    "\n",
    "contour_areas = []\n",
    "\n",
    "for i in range(len(top_levels) - 1):\n",
    "    \n",
    "    # Get the area of the contour between the current and next levels\n",
    "    area = np.sum(kde_values * (kde_values >= top_levels[i]) * (kde_values < top_levels[i + 1]))\n",
    "    \n",
    "    contour_areas.append(area)\n",
    "    \n",
    "# Display the areas of the contour plot\n",
    "\n",
    "contour_areas\n",
    "\n",
    "# Find the indices of the points that are within the contour area\n",
    "\n",
    "points_in_contour = np.where(kde_values >= threshold)\n",
    "\n",
    "# Extract the x and y coordinates of the points within the contour area\n",
    "\n",
    "x_in_contour = xx[points_in_contour]\n",
    "\n",
    "y_in_contour = yy[points_in_contour]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the points within the contour area\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(x_in_contour, y_in_contour, alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "plt.xlabel('t-SNE1')\n",
    "\n",
    "plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Points within the Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming TSNE_Data, xx, yy, kde_values, and threshold are already defined\n",
    "import os\n",
    "# Create a binary mask for high-density areas\n",
    "high_density_mask = kde_values >= threshold\n",
    "\n",
    "# Label connected components in the binary mask\n",
    "labeled_array, num_features = label(high_density_mask)\n",
    "\n",
    "# Create subsets for each distinct area\n",
    "subsets = []\n",
    "for i in range(1, num_features + 1):\n",
    "    area_mask = labeled_array == i\n",
    "    x_in_area = xx[area_mask]\n",
    "    y_in_area = yy[area_mask]\n",
    "    \n",
    "    # Find points from the original dataset that fall within this area\n",
    "    points_in_area = TSNE_Data[\n",
    "        (TSNE_Data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "        (TSNE_Data['t-SNE Component 2'] <= y_in_area.max())\n",
    "    ]\n",
    "    \n",
    "    # If the area is not empty, save it to a subset list and a file\n",
    "    if len(points_in_area) > 0:\n",
    "        filename = f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/Cluster_data/250107_LooseContacts_Mapped/250107_behavior_map_tsne_area_{i}.feather\"\n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"File {filename} already exists, skipping save.\")\n",
    "        else:\n",
    "            points_in_area.to_feather(filename)\n",
    "        subsets.append((i, points_in_area))\n",
    "        print(f\"Saved Area {i} with {len(points_in_area)} points to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot each distinct area with a different color\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\", alpha=0.3)\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, num_features))\n",
    "for i, (area_index, subset) in enumerate(subsets):\n",
    "    plt.scatter(subset['t-SNE Component 1'], subset['t-SNE Component 2'], \n",
    "                color=colors[area_index - 1], label=f'Area {area_index}', alpha=0.6)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Distinct High-Density Areas in t-SNE Plot')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print information about each subset\n",
    "for area_index, subset in subsets:\n",
    "    print(f\"Area {area_index}: {len(subset)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the control region and get unique brain regions\n",
    "control_region = 'Control'\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]\n",
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_regions = len(brain_regions)\n",
    "n_cols = 4  # You can adjust this value\n",
    "n_rows = math.ceil(n_regions / n_cols)\n",
    "\n",
    "# Create the main figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 6*n_rows), squeeze=False)\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, region in enumerate(brain_regions):\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Create subsets for each distinct area\n",
    "    area_counts = {}\n",
    "    for i in range(1, num_features + 1):\n",
    "        area_mask = labeled_array == i\n",
    "        x_in_area = xx[area_mask]\n",
    "        y_in_area = yy[area_mask]\n",
    "\n",
    "        points_in_area = subset_data[\n",
    "            (subset_data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "            (subset_data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 2'] <= y_in_area.max())\n",
    "        ]\n",
    "\n",
    "        if len(points_in_area) > 0:\n",
    "            area_name = f'Area {i}'\n",
    "            nickname_counts = points_in_area['Nickname'].value_counts()\n",
    "            area_counts[area_name] = nickname_counts\n",
    "\n",
    "    # Combine all area counts into a single DataFrame\n",
    "    combined_counts = pd.DataFrame(area_counts).fillna(0)\n",
    "\n",
    "    # Calculate the total count for each Nickname\n",
    "    total_counts = combined_counts.sum(axis=1)\n",
    "\n",
    "    # Normalize counts to get proportions\n",
    "    normalized_proportions = combined_counts.div(total_counts, axis=0)\n",
    "\n",
    "    # Plot the normalized proportions\n",
    "    ax = axes_flat[idx]\n",
    "    normalized_proportions.plot(kind='barh', stacked=True, ax=ax)\n",
    "    ax.set_title(f'{region} vs {control_region}')\n",
    "    ax.set_xlabel('Proportion of Points')\n",
    "    ax.set_ylabel('Nickname')\n",
    "    ax.legend(title='High-Density Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Adjust layout for better readability\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(idx+1, len(axes_flat)):\n",
    "    fig.delaxes(axes_flat[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Contacts/250203BehaviorProps_Grid.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print the proportions for each Nickname (optional)\n",
    "#print(combined_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming TSNE_Data, labeled_array, xx, yy, and num_features are already defined\n",
    "\n",
    "# Create a list to store the data for each contact\n",
    "contacts_data = []\n",
    "\n",
    "# Define the control region and get unique brain regions\n",
    "control_region = 'Control'\n",
    "brain_regions = TSNE_Data['Brain region'].unique()\n",
    "brain_regions = [region for region in brain_regions if region != control_region]\n",
    "\n",
    "for region in brain_regions:\n",
    "    # Subset the data for the Control Brain region and the current Brain region\n",
    "    subset_data = TSNE_Data[TSNE_Data['Brain region'].isin([control_region, region])]\n",
    "    \n",
    "    # Create subsets for each distinct area\n",
    "    for i in range(1, num_features + 1):\n",
    "        area_mask = labeled_array == i\n",
    "        x_in_area = xx[area_mask]\n",
    "        y_in_area = yy[area_mask]\n",
    "\n",
    "        points_in_area = subset_data[\n",
    "            (subset_data['t-SNE Component 1'] >= x_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 1'] <= x_in_area.max()) &\n",
    "            (subset_data['t-SNE Component 2'] >= y_in_area.min()) &\n",
    "            (subset_data['t-SNE Component 2'] <= y_in_area.max())\n",
    "        ]\n",
    "\n",
    "        if len(points_in_area) > 0:\n",
    "            area_name = f'Area {i}'\n",
    "            for _, row in points_in_area.iterrows():\n",
    "                contact_info = row.to_dict()\n",
    "                contact_info['Area'] = area_name\n",
    "                contacts_data.append(contact_info)\n",
    "\n",
    "# Create a DataFrame from the contacts data\n",
    "contacts_df = pd.DataFrame(contacts_data)\n",
    "\n",
    "contacts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming contacts_df is already defined and contains a 'fly' column\n",
    "\n",
    "# Calculate the total number of contacts for each fly\n",
    "total_contacts_per_fly = contacts_df.groupby('fly').size()\n",
    "\n",
    "# Calculate the number of contacts for each fly in each Area\n",
    "contacts_per_area_fly = contacts_df.groupby(['Area', 'fly']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportion of contacts in each Area for each fly\n",
    "proportions_per_area_fly = contacts_per_area_fly.div(total_contacts_per_fly, axis=1).fillna(0)\n",
    "\n",
    "# Transpose the DataFrame to get the 'fly' values back as a column\n",
    "proportions_per_area_fly = proportions_per_area_fly.T\n",
    "\n",
    "# Reset the index to convert the DataFrame to a long format suitable for merging with metadata\n",
    "proportions_long = proportions_per_area_fly.reset_index().rename(columns={'index': 'fly'})\n",
    "\n",
    "# Ensure the 'fly' column is present in proportions_long\n",
    "#print(\"Columns in proportions_long:\", proportions_long.columns)\n",
    "\n",
    "# Merge the proportions with the metadata\n",
    "metadata = contacts_df[['fly', 'Nickname', 'Brain region']].drop_duplicates().set_index('fly')\n",
    "#print(\"Metadata index:\", metadata.index)\n",
    "\n",
    "proportions_with_metadata = proportions_long.merge(metadata, left_on='fly', right_index=True)\n",
    "\n",
    "# Print the first few rows of the new dataset\n",
    "#print(proportions_with_metadata.head())\n",
    "\n",
    "# Now you can use this dataset for further analysis or visualization\n",
    "# For example, create a boxplot with the proportions, using the Nickname as the hue\n",
    "proportions_melted = proportions_with_metadata.melt(id_vars=['fly', 'Nickname', 'Brain region'], var_name='Area', value_name='Proportion')\n",
    "\n",
    "\n",
    "proportions_melted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique Nicknames associated with Brain region \"Control\"\n",
    "\n",
    "proportions_melted[proportions_melted['Brain region'] == 'Control']['Nickname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['TNTxCS', 'TNTxPR', 'Empty-Gal4', 'Empty-Split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Area24 = proportions_melted[proportions_melted['Area'] == 'Area 24']\n",
    "\n",
    "Area24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPlot = HoloviewsTemplates.jitter_boxplot(data=Area24, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"grouped\",groupby='Brain region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(TestPlot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/Area1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the plots\n",
    "plots = []\n",
    "\n",
    "# Loop through each area and generate the plot\n",
    "for area in nickname_proportions_df.index:\n",
    "    area_data = proportions_melted[proportions_melted['Area'] == area]\n",
    "    \n",
    "    # Check if there are controls in the subset\n",
    "    if not any(control in area_data['Nickname'].unique() for control in controls):\n",
    "        print(f\"No controls found in {area}, skipping this area.\")\n",
    "        continue\n",
    "    \n",
    "    plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot', render=\"grouped\", groupby='Brain region')\n",
    "    plot.opts(title=f'Proportion of Points in {area}')\n",
    "    plots.append(plot)\n",
    "\n",
    "# Combine the plots into a layout\n",
    "layout = hv.Layout(plots).cols(3)\n",
    "\n",
    "# Save the layout to an HTML file\n",
    "hv.save(layout, '/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/proportion_plots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the plots\n",
    "plots = []\n",
    "\n",
    "# Loop through each area and generate the plot\n",
    "for area in nickname_proportions_df.index:\n",
    "    area_data = proportions_melted[proportions_melted['Area'] == area]\n",
    "    \n",
    "    # Check if there are controls in the subset\n",
    "    has_controls = any(control in area_data['Nickname'].unique() for control in controls)\n",
    "    \n",
    "    if has_controls:\n",
    "        plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot', render=\"grouped\", groupby='Brain region')\n",
    "        plot = plot.opts(title=f'Proportion of Points in {area}')\n",
    "    else:\n",
    "        plot = HoloviewsTemplates.jitter_boxplot(data=area_data, metric='Proportion', kdims='Nickname', control=None, hline=None, render=\"grouped\", groupby='Brain region')\n",
    "        plot = plot.opts(title=f'Proportion of Points in {area} (No Controls)', fontsize={'title': '12pt'})\n",
    "        annotation = hv.Text(0.5, 0.5, 'No Controls', halign='center', valign='center').opts(style=dict(text_font_size='20pt', text_color='red'))\n",
    "        plot = plot * annotation\n",
    "    \n",
    "    plot.opts(title=f'Proportion of Points in {area}')\n",
    "    plots.append(plot)\n",
    "\n",
    "# Combine the plots into a layout\n",
    "layout = hv.Layout(plots).cols(3)\n",
    "\n",
    "# Save the layout to an HTML file\n",
    "hv.save(layout, '/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/proportion_plots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's focus on areas instead of brain regions\n",
    "\n",
    "Area14 = proportions_melted[proportions_melted['Area'] == 'Area 14']\n",
    "\n",
    "Area14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pooled14 = HoloviewsTemplates.jitter_boxplot(data=Area1, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"pooled\",colorby='Brain region')\n",
    "\n",
    "hv.save(Pooled14, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/Area14.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for area in proportions_melted['Area'].unique():\n",
    "    AreaData = proportions_melted[proportions_melted['Area'] == area]\n",
    "    PooledArea = HoloviewsTemplates.jitter_boxplot(data=AreaData, metric='Proportion', kdims='Nickname', control=controls, hline='boxplot',render=\"pooled\",colorby='Brain region')\n",
    "    hv.save(PooledArea, f\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/{area}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each area, compute the bootstrapped confidence intervals for the proportion of points in each Nickname and compare it to the control region. If the confidence interval does not overlap with the control region, flag it as significant and print the results.\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "areas = proportions_melted['Area'].unique()\n",
    "nicknames = proportions_melted['Nickname'].unique()\n",
    "results_df = pd.DataFrame(index=nicknames, columns=areas)\n",
    "\n",
    "\n",
    "#For each area, compute the bootstrapped confidence intervals for the proportion of points in each Nickname and compare it to the control region\n",
    "for area in areas:\n",
    "    AreaData = proportions_melted[proportions_melted['Area'] == area]\n",
    "    \n",
    "    # Compute the bootstrapped confidence intervals for controls\n",
    "    control_data = AreaData[AreaData['Brain region'] == 'Control']\n",
    "    ctrl_bs_ci = Processing.draw_bs_ci(control_data['Proportion'], np.mean)\n",
    "    \n",
    "    # Compute the bootstrapped confidence intervals for each Nickname\n",
    "    for nickname in AreaData['Nickname'].unique():\n",
    "        nickname_data = AreaData[AreaData['Nickname'] == nickname]\n",
    "        nickname_bs_ci = Processing.draw_bs_ci(nickname_data['Proportion'], np.mean)\n",
    "        \n",
    "        # Compute the difference between the Nickname and control proportions\n",
    "        diff = np.mean(nickname_data['Proportion']) - np.mean(control_data['Proportion'])\n",
    "        \n",
    "        # Check if the confidence intervals overlap\n",
    "        if nickname_bs_ci[1] < ctrl_bs_ci[0]:\n",
    "            results_df.at[nickname, area] = diff  # Significant negative difference\n",
    "        elif nickname_bs_ci[0] > ctrl_bs_ci[1]:\n",
    "            results_df.at[nickname, area] = diff  # Significant positive difference\n",
    "        else:\n",
    "            results_df.at[nickname, area] = 0  # No significant difference\n",
    "\n",
    "# Normalize the differences\n",
    "max_diff = results_df.abs().max().max()\n",
    "results_df = results_df / max_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cleaned = results_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "results_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a heatmap to visualize the results\n",
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(results_df_cleaned, annot=False, cmap='vlag_r', center=0, linewidths=.5, linecolor='black', cbar_kws={'label': 'Normalized Difference'})\n",
    "plt.title('Significant Differences in Proportions by Area and Nickname')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Nickname')\n",
    "\n",
    "plt.savefig(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/TNT_Fine_TSNE/250203_AreasHeatmap.png\")\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
