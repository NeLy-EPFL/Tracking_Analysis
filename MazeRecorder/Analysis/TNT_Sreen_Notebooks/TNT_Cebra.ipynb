{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cebra\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data = pd.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250106_FinalEventCutoffData_norm/contact_data/250106_Pooled_contact_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation \n",
    "\n",
    "Here we'll start by creating a key column, that should be a unique identifier for each contact in the dataset (basically one number per interaction between fly and contact_index)\n",
    "\n",
    "Then we remove anything that is not tracking data. We also remove the ball centre to only keep the preprocessed tracking data. \n",
    "\n",
    "Finally, we save to h5 file and load it to cebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Contact_data.columns:\n",
    "    print(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a trial column that is an index for each unique combination of fly and contact_index\n",
    "\n",
    "Contact_data['trial'] = Contact_data.groupby(['fly', 'contact_index']).ngroup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trial, shift the time column so that the first time is 0\n",
    "\n",
    "Contact_data['time_shifted'] = Contact_data.groupby('trial')['time'].transform(lambda x: x - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list of columns to keep\n",
    "\n",
    "columns_to_keep = ['frame', 'time', 'x_Head', 'y_Head', 'x_Thorax',\n",
    "       'y_Thorax', 'x_Abdomen', 'y_Abdomen', 'x_Rfront', 'y_Rfront',\n",
    "       'x_Lfront', 'y_Lfront', 'x_Rmid', 'y_Rmid', 'x_Lmid', 'y_Lmid',\n",
    "       'x_Rhind', 'y_Rhind', 'x_Lhind', 'y_Lhind', 'x_Rwing', 'y_Rwing',\n",
    "       'x_Lwing', 'y_Lwing', 'contact_index',\n",
    "       'euclidean_distance', 'x_centre_preprocessed', 'y_centre_preprocessed',\n",
    "       'fly', 'flypath', 'experiment', 'Nickname', 'Brain region', 'Date',\n",
    "       'Genotype', 'Period', 'FeedingState', 'Orientation', 'Light',\n",
    "       'Crossing', 'trial', 'time_shifted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (coordinates)\n",
    "feature_columns = ['x_Head', 'y_Head', 'x_Thorax', 'y_Thorax', 'x_Abdomen', 'y_Abdomen', \n",
    "                   'x_Rfront', 'y_Rfront', 'x_Lfront', 'y_Lfront', 'x_Rmid', 'y_Rmid', \n",
    "                   'x_Lmid', 'y_Lmid', 'x_Rhind', 'y_Rhind', 'x_Lhind', 'y_Lhind', \n",
    "                   'x_Rwing', 'y_Rwing', 'x_Lwing', 'y_Lwing', 'x_centre_preprocessed', \n",
    "                   'y_centre_preprocessed']\n",
    "\n",
    "# Time dimension\n",
    "time_column = 'time_shifted'\n",
    "\n",
    "# Metadata (you can choose relevant columns for auxiliary variables)\n",
    "metadata_columns = ['frame','fly', 'flypath', 'experiment', 'Nickname', 'Brain region', 'Date',\n",
    "       'Genotype', 'Period', 'FeedingState', 'Orientation', 'Light',\n",
    "       'Crossing', 'euclidean_distance', ]\n",
    "\n",
    "X = Contact_data[feature_columns].values\n",
    "T = Contact_data[time_column].values\n",
    "metadata = Contact_data[metadata_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare data lists for MultiCEBRA\n",
    "X_list = []\n",
    "T_list = []\n",
    "auxiliary_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Iterate through trials\n",
    "for trial in Contact_data['trial'].unique():\n",
    "    trial_data = Contact_data[Contact_data['trial'] == trial]\n",
    "    \n",
    "    # Features\n",
    "    X_trial = scaler.fit_transform(trial_data[feature_columns].values)\n",
    "    X_list.append(X_trial)\n",
    "    \n",
    "    # Time\n",
    "    T_trial = trial_data[time_column].values\n",
    "    T_list.append(T_trial)\n",
    "    \n",
    "    # Auxiliary data (including time)\n",
    "    auxiliary_trial = pd.get_dummies(trial_data[metadata_columns], columns=['fly', 'flypath', 'experiment', 'Nickname', 'Brain region', 'Date', 'Genotype', 'Period', 'FeedingState', 'Orientation', 'Light', 'Crossing'])\n",
    "    auxiliary_trial = np.column_stack((T_trial, auxiliary_trial.values))\n",
    "    auxiliary_list.append(auxiliary_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up CEBRA model\n",
    "model = cebra.CEBRA(\n",
    "    model_architecture='offset10-model',\n",
    "    batch_size=512,\n",
    "    learning_rate=3e-4,\n",
    "    temperature=1,\n",
    "    output_dimension=3,  # You can adjust this\n",
    "    max_iterations=10000,\n",
    "    device=device,\n",
    "    conditional='time_delta'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_list, auxiliary=auxiliary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.transform(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as h5 \n",
    "\n",
    "Contact_data.to_hdf(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250106_FinalEventCutoffData_norm/contact_data/250106_Pooled_contact_data.h5\", key=\"df\", mode=\"w\", format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cebra_df = cebra.load_data(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Skeleton_TNT/250106_FinalEventCutoffData_norm/contact_data/250106_Pooled_contact_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
