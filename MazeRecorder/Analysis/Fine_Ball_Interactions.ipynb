{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll explore how we can explore the interactions between the fly and the ball precisely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_behavior import Sleap_utils\n",
    "from utils_behavior import Ballpushing_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Sleap_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some fly\n",
    "\n",
    "Fly1 = Ballpushing_utils.Fly(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Videos/231115_TNT_Fine_2_Videos_Tracked/arena9/corridor6/\", as_individual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>time</th>\n",
       "      <th>object</th>\n",
       "      <th>x_Head</th>\n",
       "      <th>y_Head</th>\n",
       "      <th>x_Thorax</th>\n",
       "      <th>y_Thorax</th>\n",
       "      <th>x_Abdomen</th>\n",
       "      <th>y_Abdomen</th>\n",
       "      <th>x_Rfront</th>\n",
       "      <th>...</th>\n",
       "      <th>x_Lmid</th>\n",
       "      <th>y_Lmid</th>\n",
       "      <th>x_Rhind</th>\n",
       "      <th>y_Rhind</th>\n",
       "      <th>x_Lhind</th>\n",
       "      <th>y_Lhind</th>\n",
       "      <th>x_Rwing</th>\n",
       "      <th>y_Rwing</th>\n",
       "      <th>x_Lwing</th>\n",
       "      <th>y_Lwing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>57.455917</td>\n",
       "      <td>388.273091</td>\n",
       "      <td>64.928861</td>\n",
       "      <td>394.060352</td>\n",
       "      <td>75.895535</td>\n",
       "      <td>403.306849</td>\n",
       "      <td>55.151600</td>\n",
       "      <td>...</td>\n",
       "      <td>87.766828</td>\n",
       "      <td>384.591616</td>\n",
       "      <td>91.575229</td>\n",
       "      <td>392.377867</td>\n",
       "      <td>54.831080</td>\n",
       "      <td>382.995934</td>\n",
       "      <td>88.810369</td>\n",
       "      <td>412.621368</td>\n",
       "      <td>56.538371</td>\n",
       "      <td>407.212202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>57.510805</td>\n",
       "      <td>388.400650</td>\n",
       "      <td>64.935366</td>\n",
       "      <td>394.142799</td>\n",
       "      <td>75.812320</td>\n",
       "      <td>403.320089</td>\n",
       "      <td>55.210681</td>\n",
       "      <td>...</td>\n",
       "      <td>87.766828</td>\n",
       "      <td>384.591616</td>\n",
       "      <td>91.383685</td>\n",
       "      <td>392.466464</td>\n",
       "      <td>54.831080</td>\n",
       "      <td>382.995934</td>\n",
       "      <td>88.636561</td>\n",
       "      <td>412.568267</td>\n",
       "      <td>56.538371</td>\n",
       "      <td>407.212202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>57.565692</td>\n",
       "      <td>388.528210</td>\n",
       "      <td>64.941871</td>\n",
       "      <td>394.225246</td>\n",
       "      <td>75.729106</td>\n",
       "      <td>403.333329</td>\n",
       "      <td>55.269762</td>\n",
       "      <td>...</td>\n",
       "      <td>87.766828</td>\n",
       "      <td>384.591616</td>\n",
       "      <td>91.192140</td>\n",
       "      <td>392.555062</td>\n",
       "      <td>54.831080</td>\n",
       "      <td>382.995934</td>\n",
       "      <td>88.462753</td>\n",
       "      <td>412.515167</td>\n",
       "      <td>56.538371</td>\n",
       "      <td>407.212202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>57.620580</td>\n",
       "      <td>388.655769</td>\n",
       "      <td>64.948376</td>\n",
       "      <td>394.307693</td>\n",
       "      <td>75.645891</td>\n",
       "      <td>403.346568</td>\n",
       "      <td>55.328842</td>\n",
       "      <td>...</td>\n",
       "      <td>87.766828</td>\n",
       "      <td>384.591616</td>\n",
       "      <td>91.000596</td>\n",
       "      <td>392.643660</td>\n",
       "      <td>54.831080</td>\n",
       "      <td>382.995934</td>\n",
       "      <td>88.288945</td>\n",
       "      <td>412.462066</td>\n",
       "      <td>56.538371</td>\n",
       "      <td>407.212202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>57.675468</td>\n",
       "      <td>388.783328</td>\n",
       "      <td>64.954881</td>\n",
       "      <td>394.390140</td>\n",
       "      <td>75.562677</td>\n",
       "      <td>403.359808</td>\n",
       "      <td>55.387923</td>\n",
       "      <td>...</td>\n",
       "      <td>87.766828</td>\n",
       "      <td>384.591616</td>\n",
       "      <td>90.809051</td>\n",
       "      <td>392.732258</td>\n",
       "      <td>54.831080</td>\n",
       "      <td>382.995934</td>\n",
       "      <td>88.115137</td>\n",
       "      <td>412.408966</td>\n",
       "      <td>56.538371</td>\n",
       "      <td>407.212202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104397</th>\n",
       "      <td>104398</td>\n",
       "      <td>3599.931034</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>75.450094</td>\n",
       "      <td>151.973438</td>\n",
       "      <td>76.588968</td>\n",
       "      <td>164.451002</td>\n",
       "      <td>60.464414</td>\n",
       "      <td>187.067531</td>\n",
       "      <td>69.585263</td>\n",
       "      <td>...</td>\n",
       "      <td>56.394679</td>\n",
       "      <td>118.159847</td>\n",
       "      <td>73.969588</td>\n",
       "      <td>263.921224</td>\n",
       "      <td>55.299029</td>\n",
       "      <td>138.910192</td>\n",
       "      <td>71.225608</td>\n",
       "      <td>273.634950</td>\n",
       "      <td>63.643709</td>\n",
       "      <td>202.177225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104398</th>\n",
       "      <td>104399</td>\n",
       "      <td>3599.965517</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>75.538659</td>\n",
       "      <td>151.241812</td>\n",
       "      <td>76.662850</td>\n",
       "      <td>163.723538</td>\n",
       "      <td>60.401104</td>\n",
       "      <td>186.355874</td>\n",
       "      <td>69.585263</td>\n",
       "      <td>...</td>\n",
       "      <td>56.394679</td>\n",
       "      <td>118.159847</td>\n",
       "      <td>73.969588</td>\n",
       "      <td>263.921224</td>\n",
       "      <td>55.299029</td>\n",
       "      <td>138.910192</td>\n",
       "      <td>71.225608</td>\n",
       "      <td>273.634950</td>\n",
       "      <td>63.578517</td>\n",
       "      <td>201.459421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104399</th>\n",
       "      <td>104400</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>75.627224</td>\n",
       "      <td>150.510186</td>\n",
       "      <td>76.736733</td>\n",
       "      <td>162.996074</td>\n",
       "      <td>60.337794</td>\n",
       "      <td>185.644216</td>\n",
       "      <td>69.585263</td>\n",
       "      <td>...</td>\n",
       "      <td>56.394679</td>\n",
       "      <td>118.159847</td>\n",
       "      <td>73.969588</td>\n",
       "      <td>263.921224</td>\n",
       "      <td>55.299029</td>\n",
       "      <td>138.910192</td>\n",
       "      <td>71.225608</td>\n",
       "      <td>273.634950</td>\n",
       "      <td>63.513326</td>\n",
       "      <td>200.741618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104400</th>\n",
       "      <td>104401</td>\n",
       "      <td>3600.034483</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>75.715789</td>\n",
       "      <td>149.778560</td>\n",
       "      <td>76.810616</td>\n",
       "      <td>162.268610</td>\n",
       "      <td>60.274484</td>\n",
       "      <td>184.932559</td>\n",
       "      <td>69.585263</td>\n",
       "      <td>...</td>\n",
       "      <td>56.394679</td>\n",
       "      <td>118.159847</td>\n",
       "      <td>73.969588</td>\n",
       "      <td>263.921224</td>\n",
       "      <td>55.299029</td>\n",
       "      <td>138.910192</td>\n",
       "      <td>71.225608</td>\n",
       "      <td>273.634950</td>\n",
       "      <td>63.448134</td>\n",
       "      <td>200.023814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104401</th>\n",
       "      <td>104402</td>\n",
       "      <td>3600.068966</td>\n",
       "      <td>fly_1</td>\n",
       "      <td>75.804355</td>\n",
       "      <td>149.046934</td>\n",
       "      <td>76.884498</td>\n",
       "      <td>161.541146</td>\n",
       "      <td>60.211174</td>\n",
       "      <td>184.220902</td>\n",
       "      <td>69.585263</td>\n",
       "      <td>...</td>\n",
       "      <td>56.394679</td>\n",
       "      <td>118.159847</td>\n",
       "      <td>73.969588</td>\n",
       "      <td>263.921224</td>\n",
       "      <td>55.299029</td>\n",
       "      <td>138.910192</td>\n",
       "      <td>71.225608</td>\n",
       "      <td>273.634950</td>\n",
       "      <td>63.382942</td>\n",
       "      <td>199.306010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104402 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         frame         time object     x_Head      y_Head   x_Thorax  \\\n",
       "0            1     0.034483  fly_1  57.455917  388.273091  64.928861   \n",
       "1            2     0.068966  fly_1  57.510805  388.400650  64.935366   \n",
       "2            3     0.103448  fly_1  57.565692  388.528210  64.941871   \n",
       "3            4     0.137931  fly_1  57.620580  388.655769  64.948376   \n",
       "4            5     0.172414  fly_1  57.675468  388.783328  64.954881   \n",
       "...        ...          ...    ...        ...         ...        ...   \n",
       "104397  104398  3599.931034  fly_1  75.450094  151.973438  76.588968   \n",
       "104398  104399  3599.965517  fly_1  75.538659  151.241812  76.662850   \n",
       "104399  104400  3600.000000  fly_1  75.627224  150.510186  76.736733   \n",
       "104400  104401  3600.034483  fly_1  75.715789  149.778560  76.810616   \n",
       "104401  104402  3600.068966  fly_1  75.804355  149.046934  76.884498   \n",
       "\n",
       "          y_Thorax  x_Abdomen   y_Abdomen   x_Rfront  ...     x_Lmid  \\\n",
       "0       394.060352  75.895535  403.306849  55.151600  ...  87.766828   \n",
       "1       394.142799  75.812320  403.320089  55.210681  ...  87.766828   \n",
       "2       394.225246  75.729106  403.333329  55.269762  ...  87.766828   \n",
       "3       394.307693  75.645891  403.346568  55.328842  ...  87.766828   \n",
       "4       394.390140  75.562677  403.359808  55.387923  ...  87.766828   \n",
       "...            ...        ...         ...        ...  ...        ...   \n",
       "104397  164.451002  60.464414  187.067531  69.585263  ...  56.394679   \n",
       "104398  163.723538  60.401104  186.355874  69.585263  ...  56.394679   \n",
       "104399  162.996074  60.337794  185.644216  69.585263  ...  56.394679   \n",
       "104400  162.268610  60.274484  184.932559  69.585263  ...  56.394679   \n",
       "104401  161.541146  60.211174  184.220902  69.585263  ...  56.394679   \n",
       "\n",
       "            y_Lmid    x_Rhind     y_Rhind    x_Lhind     y_Lhind    x_Rwing  \\\n",
       "0       384.591616  91.575229  392.377867  54.831080  382.995934  88.810369   \n",
       "1       384.591616  91.383685  392.466464  54.831080  382.995934  88.636561   \n",
       "2       384.591616  91.192140  392.555062  54.831080  382.995934  88.462753   \n",
       "3       384.591616  91.000596  392.643660  54.831080  382.995934  88.288945   \n",
       "4       384.591616  90.809051  392.732258  54.831080  382.995934  88.115137   \n",
       "...            ...        ...         ...        ...         ...        ...   \n",
       "104397  118.159847  73.969588  263.921224  55.299029  138.910192  71.225608   \n",
       "104398  118.159847  73.969588  263.921224  55.299029  138.910192  71.225608   \n",
       "104399  118.159847  73.969588  263.921224  55.299029  138.910192  71.225608   \n",
       "104400  118.159847  73.969588  263.921224  55.299029  138.910192  71.225608   \n",
       "104401  118.159847  73.969588  263.921224  55.299029  138.910192  71.225608   \n",
       "\n",
       "           y_Rwing    x_Lwing     y_Lwing  \n",
       "0       412.621368  56.538371  407.212202  \n",
       "1       412.568267  56.538371  407.212202  \n",
       "2       412.515167  56.538371  407.212202  \n",
       "3       412.462066  56.538371  407.212202  \n",
       "4       412.408966  56.538371  407.212202  \n",
       "...            ...        ...         ...  \n",
       "104397  273.634950  63.643709  202.177225  \n",
       "104398  273.634950  63.578517  201.459421  \n",
       "104399  273.634950  63.513326  200.741618  \n",
       "104400  273.634950  63.448134  200.023814  \n",
       "104401  273.634950  63.382942  199.306010  \n",
       "\n",
       "[104402 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the ball images\n",
    "\n",
    "Fly1.fly_skeleton\n",
    "\n",
    "# Display the frame\n",
    "#plt.imshow(some_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get interaction events between fly Rfront and Lfront and ball centre\n",
    "\n",
    "Events = Ballpushing_utils.find_interaction_events(Fly1.fly_skeleton, Fly1.balltrack.objects[0].dataset, [\"Rfront\", \"Lfront\"], [\"centre\"], threshold = [0,11], gap_between_events = 1/29, event_min_length = 1/29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each event, get the derivative of the ball position\n",
    "\n",
    "ball_velocities = []\n",
    "\n",
    "for event in Events:\n",
    "    # Get the ball positions for the event\n",
    "    ball_positions = Fly1.balltrack.objects[0].dataset[event[0]:event[1]]\n",
    "    # Get the derivative of the ball positions\n",
    "    \n",
    "    ball_velocity = abs(np.diff(ball_positions[\"y_centre\"], axis = 0))\n",
    "    \n",
    "    ball_velocities.append(ball_velocity)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc765c12b10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ball velocities as a function of event number\n",
    "\n",
    "plt.plot([np.mean(vel) for vel in ball_velocities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sleap_Tracks' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the annotated frames for event 4\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Events[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;241m0\u001b[39m], Events[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mFly1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflytrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_annotated_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/utils_behavior/utils_behavior/Sleap_utils.py:188\u001b[0m, in \u001b[0;36mSleap_Tracks.generate_annotated_frame\u001b[0;34m(self, frame, nodes, labels, edges, colorby)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_annotated_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame, nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, colorby\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates an annotated frame image for a specific frame.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     frame_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m frame]\n\u001b[1;32m    190\u001b[0m     cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo))\n\u001b[1;32m    191\u001b[0m     cap\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_POS_FRAMES, frame \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sleap_Tracks' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "# Get the annotated frames for event 4\n",
    "\n",
    "for frame in range(Events[4][0], Events[4][1]):\n",
    "    Fly1.flytrack.generate_annotated_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Sleap_utils.CombinedSleapTracks(video_path=\"/mnt/upramdya_data/MD/MultiMazeRecorder/Videos/231115_TNT_Fine_2_Videos_Tracked/arena9/corridor6/corridor6_preprocessed.mp4\", sleap_tracks_list=[Fly1, Ball1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLytrack = Fly1.dataset\n",
    "\n",
    "FLytrack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balltrack = Ball1.dataset\n",
    "\n",
    "Balltrack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold distance\n",
    "threshold = 11\n",
    "\n",
    "# Compute the Euclidean distance for Lfront and Rfront\n",
    "distances_Lfront = np.sqrt((FLytrack[\"x_Lfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Lfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "distances_Rfront = np.sqrt((FLytrack[\"x_Rfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Rfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "\n",
    "# Find frames where either Lfront or Rfront is within the threshold distance\n",
    "contacts = FLytrack[(distances_Lfront < threshold) | (distances_Rfront < threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the frames where the fly is in contact with the ball\n",
    "\n",
    "for index, row in contacts.iterrows():\n",
    "    frame = Fly1.generate_annotated_frame(index)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    #print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contact_events(\n",
    "        FLytrack,\n",
    "        Balltrack,\n",
    "        threshold=11,\n",
    "        gap_between_events=4,\n",
    "        event_min_length=2,\n",
    "        fps=29\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function finds contact events where the fly's legs are touching the ball for a minimum amount of time.\n",
    "\n",
    "    Parameters:\n",
    "    FLytrack (DataFrame): DataFrame containing the fly's tracking data.\n",
    "    Balltrack (DataFrame): DataFrame containing the ball's tracking data.\n",
    "    threshold (int): The distance threshold (in pixels) for the fly's legs to be considered in contact with the ball.\n",
    "    gap_between_events (int): The minimum gap required between two events, expressed in seconds.\n",
    "    event_min_length (int): The minimum length of an event, expressed in seconds.\n",
    "    fps (int): Frames per second of the video.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of contact events, where each event is represented as [start_frame, end_frame, duration].\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the gap between events and the minimum event length from seconds to frames\n",
    "    gap_between_events = gap_between_events * fps\n",
    "    event_min_length = event_min_length * fps\n",
    "\n",
    "    # Compute the Euclidean distance for Lfront and Rfront\n",
    "    distances_Lfront = np.sqrt((FLytrack[\"x_Lfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Lfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "    distances_Rfront = np.sqrt((FLytrack[\"x_Rfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Rfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "\n",
    "    # Find frames where either Lfront or Rfront is within the threshold distance\n",
    "    contact_frames = np.where((distances_Lfront < threshold) | (distances_Rfront < threshold))[0]\n",
    "\n",
    "    # If no contact frames are found, return an empty list\n",
    "    if len(contact_frames) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find the distance between consecutive contact frames\n",
    "    distance_betw_frames = np.diff(contact_frames)\n",
    "\n",
    "    # Find the points where the distance between frames is greater than the gap between events\n",
    "    split_points = np.where(distance_betw_frames > gap_between_events)[0]\n",
    "\n",
    "    # Add the first and last points to the split points\n",
    "    split_points = np.insert(split_points, 0, -1)\n",
    "    split_points = np.append(split_points, len(contact_frames) - 1)\n",
    "\n",
    "    # Initialize the list of contact events\n",
    "    contact_events = []\n",
    "\n",
    "    # Iterate over the split points to find events\n",
    "    for f in range(0, len(split_points) - 1):\n",
    "        # Define the start and end of the region of interest (ROI)\n",
    "        start_roi = contact_frames[split_points[f] + 1]\n",
    "        end_roi = contact_frames[split_points[f + 1]]\n",
    "\n",
    "        # Calculate the duration of the event\n",
    "        duration = end_roi - start_roi\n",
    "\n",
    "        # If the duration of the event is greater than the minimum length, add the event to the list\n",
    "        if duration > event_min_length:\n",
    "            contact_events.append([start_roi, end_roi, duration])\n",
    "\n",
    "    return contact_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contact events\n",
    "contact_events = find_contact_events(FLytrack, Balltrack, threshold=16, gap_between_events=1/2, event_min_length=1/2, fps=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make clips of the contact events\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/Frontlegs_long\"\n",
    "\n",
    "# Make clips of the contact events\n",
    "for i, event in enumerate(contact_events):\n",
    "    # Define the start and end frames of the event\n",
    "    start_frame = event[0]\n",
    "    end_frame = event[1]\n",
    "\n",
    "    # Define the output file name\n",
    "    output_file = f\"{output_dir}/contact_event_{i}.mp4\"\n",
    "\n",
    "    # Make the clip\n",
    "    Fly1.generate_annotated_video(save=True, output_path=output_file, start=start_frame, end=end_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contact_events(\n",
    "        FLytrack,\n",
    "        Balltrack,\n",
    "        nodes=[\"Lfront\", \"Rfront\"],\n",
    "        threshold=11,\n",
    "        gap_between_events=4,\n",
    "        event_min_length=2,\n",
    "        fps=29\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function finds contact events where the fly's specified nodes are touching the ball for a minimum amount of time.\n",
    "\n",
    "    Parameters:\n",
    "    FLytrack (DataFrame): DataFrame containing the fly's tracking data.\n",
    "    Balltrack (DataFrame): DataFrame containing the ball's tracking data.\n",
    "    nodes (list): List of nodes to check the distance with the ball (e.g., [\"Lfront\", \"Rfront\", \"Head\"]).\n",
    "    threshold (int): The distance threshold (in pixels) for the fly's nodes to be considered in contact with the ball.\n",
    "    gap_between_events (int): The minimum gap required between two events, expressed in seconds.\n",
    "    event_min_length (int): The minimum length of an event, expressed in seconds.\n",
    "    fps (int): Frames per second of the video.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of contact events, where each event is represented as [start_frame, end_frame, duration].\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the gap between events and the minimum event length from seconds to frames\n",
    "    gap_between_events = gap_between_events * fps\n",
    "    event_min_length = event_min_length * fps\n",
    "\n",
    "    # Initialize a list to store distances for all specified nodes\n",
    "    distances = []\n",
    "\n",
    "    # Compute the Euclidean distance for each specified node\n",
    "    for node in nodes:\n",
    "        distances_node = np.sqrt((FLytrack[f\"x_{node}\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[f\"y_{node}\"] - Balltrack[\"y_centre\"])**2)\n",
    "        distances.append(distances_node)\n",
    "\n",
    "    # Combine distances to find frames where any node is within the threshold distance\n",
    "    combined_distances = np.min(distances, axis=0)\n",
    "    contact_frames = np.where(combined_distances < threshold)[0]\n",
    "\n",
    "    # If no contact frames are found, return an empty list\n",
    "    if len(contact_frames) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find the distance between consecutive contact frames\n",
    "    distance_betw_frames = np.diff(contact_frames)\n",
    "\n",
    "    # Find the points where the distance between frames is greater than the gap between events\n",
    "    split_points = np.where(distance_betw_frames > gap_between_events)[0]\n",
    "\n",
    "    # Add the first and last points to the split points\n",
    "    split_points = np.insert(split_points, 0, -1)\n",
    "    split_points = np.append(split_points, len(contact_frames) - 1)\n",
    "\n",
    "    # Initialize the list of contact events\n",
    "    contact_events = []\n",
    "\n",
    "    # Iterate over the split points to find events\n",
    "    for f in range(0, len(split_points) - 1):\n",
    "        # Define the start and end of the region of interest (ROI)\n",
    "        start_roi = contact_frames[split_points[f] + 1]\n",
    "        end_roi = contact_frames[split_points[f + 1]]\n",
    "\n",
    "        # Calculate the duration of the event\n",
    "        duration = end_roi - start_roi\n",
    "\n",
    "        # If the duration of the event is greater than the minimum length, add the event to the list\n",
    "        if duration > event_min_length:\n",
    "            contact_events.append([start_roi, end_roi, duration])\n",
    "\n",
    "    return contact_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check head contacts\n",
    "contact_events_head = find_contact_events(FLytrack, Balltrack, nodes=[\"Head\"], threshold=16, gap_between_events=1/2, event_min_length=1/2, fps=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_events_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make clips of the contact events\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/Head\"\n",
    "\n",
    "# Make clips of the contact events\n",
    "for i, event in enumerate(contact_events_head):\n",
    "    # Define the start and end frames of the event\n",
    "    start_frame = event[0]\n",
    "    end_frame = event[1]\n",
    "\n",
    "    # Define the output file name\n",
    "    output_file = f\"{output_dir}/contact_event_{i}.mp4\"\n",
    "\n",
    "    # Make the clip\n",
    "    Fly1.generate_annotated_video(save=True, output_path=output_file, start=start_frame, end=end_frame)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find contact events that would be in head but not in front legs\n",
    "\n",
    "specific_contact_events = []\n",
    "\n",
    "for event in contact_events_head:\n",
    "    start_frame = event[0]\n",
    "    end_frame = event[1]\n",
    "\n",
    "    # Check if the event is in the front legs contact events\n",
    "    is_in_front_legs = False\n",
    "    for event_front_legs in contact_events:\n",
    "        if start_frame >= event_front_legs[0] and end_frame <= event_front_legs[1]:\n",
    "            is_in_front_legs = True\n",
    "            break\n",
    "\n",
    "    # If the event is not in the front legs contact events, add it to the specific contact events\n",
    "    if not is_in_front_legs:\n",
    "        specific_contact_events.append(event)\n",
    "        \n",
    "        \n",
    "specific_contact_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try connected components methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def find_contact_events_connected_components(\n",
    "        video_path,\n",
    "        threshold=11,\n",
    "        gap_between_events=4,\n",
    "        event_min_length=2,\n",
    "        fps=30\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function finds contact events where the fly's legs are touching the ball for a minimum amount of time using connected components analysis.\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): Path to the video file.\n",
    "    threshold (int): The distance threshold (in pixels) for the fly's legs to be considered in contact with the ball.\n",
    "    gap_between_events (int): The minimum gap required between two events, expressed in seconds.\n",
    "    event_min_length (int): The minimum length of an event, expressed in seconds.\n",
    "    fps (int): Frames per second of the video.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of contact events, where each event is represented as [start_frame, end_frame, duration].\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the gap between events and the minimum event length from seconds to frames\n",
    "    gap_between_events = gap_between_events * fps\n",
    "    event_min_length = event_min_length * fps\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return []\n",
    "\n",
    "    # Initialize the list of contact events\n",
    "    contact_events = []\n",
    "\n",
    "    # Initialize variables to store the current event\n",
    "    current_event_start = None\n",
    "    current_event_end = None\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the image\n",
    "        _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find connected components\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "\n",
    "        # Check if there is only one shape (indicating contact)\n",
    "        if num_labels == 2:  # Background + one shape\n",
    "            if current_event_start is None:\n",
    "                current_event_start = frame_count\n",
    "            current_event_end = frame_count\n",
    "        else:\n",
    "            if current_event_start is not None:\n",
    "                duration = current_event_end - current_event_start\n",
    "                if duration > event_min_length:\n",
    "                    contact_events.append([current_event_start, current_event_end, duration])\n",
    "                current_event_start = None\n",
    "                current_event_end = None\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Handle the last event if it was still ongoing\n",
    "    if current_event_start is not None:\n",
    "        duration = current_event_end - current_event_start\n",
    "        if duration > event_min_length:\n",
    "            contact_events.append([current_event_start, current_event_end, duration])\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Merge close events\n",
    "    merged_events = []\n",
    "    for event in contact_events:\n",
    "        if not merged_events or event[0] - merged_events[-1][1] > gap_between_events:\n",
    "            merged_events.append(event)\n",
    "        else:\n",
    "            merged_events[-1][1] = event[1]\n",
    "            merged_events[-1][2] = merged_events[-1][1] - merged_events[-1][0]\n",
    "\n",
    "    return merged_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Get a random frame from the video\n",
    "video_path = \"/mnt/upramdya_data/MD/MultiMazeRecorder/Videos/231115_TNT_Fine_2_Videos_Tracked/arena9/corridor6/corridor6_preprocessed.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frame at 2109\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 2109)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display the frame\n",
    "\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arena_mask(binary_frame, dilation_iterations=1):\n",
    "    \"\"\"Create a mask that keeps only the area inside the detected arena.\"\"\"\n",
    "    contours, _ = cv2.findContours(\n",
    "        binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    mask = np.zeros_like(binary_frame)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
    "        \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "    \n",
    "    return dilated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarise(frame, postpros = True):\n",
    "    \"\"\"Detect the corridors in a frame using a simple threshold.\"\"\"\n",
    "    if len(frame.shape) == 3:  # Convert to grayscale if needed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(frame, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    if postpros:\n",
    "        kernel = np.ones((60, 20), np.uint8)  # Smaller kernel to avoid losing details\n",
    "        closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    else:\n",
    "        closing = binary\n",
    "\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make  a mask of the arena\n",
    "binary_frame = binarise(frame)\n",
    "\n",
    "mask = create_arena_mask(binary_frame, dilation_iterations=0)\n",
    "\n",
    "# Display the mask\n",
    "\n",
    "plt.imshow(mask, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_binarise(frame, block_size=11, c=2):\n",
    "    if len(frame.shape) == 3:  # Convert to grayscale if needed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    \n",
    "    binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def apply_asymmetric_morphological_operations(binary_frame, kernel_size=2, open_iterations=1, close_iterations=2):\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply morphological opening (erosion followed by dilation)\n",
    "    opened_frame = cv2.morphologyEx(binary_frame, cv2.MORPH_OPEN, kernel, iterations=open_iterations)\n",
    "    \n",
    "    # Apply morphological closing (dilation followed by erosion)\n",
    "    closed_frame = cv2.morphologyEx(opened_frame, cv2.MORPH_CLOSE, kernel, iterations=close_iterations)\n",
    "    \n",
    "    return closed_frame\n",
    "\n",
    "\n",
    "# Apply adaptive thresholding to the frame\n",
    "binary_frame = adaptive_binarise(frame, block_size=31, c=5)\n",
    "\n",
    "# Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10)\n",
    "\n",
    "# Apply the mask to the processed frame\n",
    "masked_frame = cv2.bitwise_and(processed_frame, processed_frame, mask=mask)\n",
    "\n",
    "# Display the masked frame\n",
    "plt.imshow(masked_frame, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can detect inside the mask how many objects of a given size are present\n",
    "\n",
    "def detect_objects(frame, min_area=500, max_area=1000):\n",
    "    # Find contours in the frame\n",
    "    contours, _ = cv2.findContours(frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area\n",
    "    objects = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area <= area <= max_area:\n",
    "            objects.append(contour)\n",
    "    \n",
    "    return objects\n",
    "\n",
    "# Detect objects in the masked frame\n",
    "\n",
    "objects = detect_objects(masked_frame, min_area=300, max_area=1000)\n",
    "\n",
    "print(f\"Number of objects detected: {len(objects)}\")\n",
    "# Draw the detected objects on the frame\n",
    "\n",
    "frame_with_objects = cv2.drawContours(frame.copy(), objects, -1, (0, 255, 0), thickness=2)\n",
    "\n",
    "# Display the frame with the detected objects\n",
    "\n",
    "plt.imshow(frame_with_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this kind of treatment to 1000 frames to see how the video looks like\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/ConnectedComponents\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the total number of frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Pick start and end, and make a video with processed frames\n",
    "start_frame = 10000\n",
    "end_frame = 12000\n",
    "\n",
    "# Set the frame position to the start frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Initialize the video writer\n",
    "output_file = f\"{output_dir}/processed_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 29\n",
    "\n",
    "# Get the frame size\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Process the frames\n",
    "for frame_count in range(start_frame, end_frame):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Create the arena mask\n",
    "    mask = create_arena_mask(binary, dilation_iterations=0)\n",
    "\n",
    "    # Apply adaptive thresholding to the frame\n",
    "    binary_frame = adaptive_binarise(frame, block_size=31, c=5)\n",
    "\n",
    "    # Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "    processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10)\n",
    "\n",
    "    # Apply the mask to the processed frame\n",
    "    masked_frame = cv2.bitwise_and(processed_frame, processed_frame, mask=mask)\n",
    "\n",
    "    # Detect objects in the masked frame\n",
    "    objects = detect_objects(masked_frame, min_area=300, max_area=1000)\n",
    "\n",
    "    # Draw the detected objects on the frame\n",
    "    frame_with_objects = cv2.drawContours(frame.copy(), objects, -1, (0, 255, 0), thickness=2)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame_with_objects)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"Video processing complete. Output saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the total number of frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize the list of contact events\n",
    "contact_events = []\n",
    "\n",
    "# Initialize variables to store the current event\n",
    "current_event_start = None\n",
    "current_event_end = None\n",
    "\n",
    "event_min_length = 1\n",
    "frame_count = 0\n",
    "max_frames = 1000  # Process only the first 1000 frames\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Apply the mask to the frame\n",
    "    masked_frame = cv2.bitwise_and(binary, binary, mask=mask)\n",
    "    \n",
    "    # Apply adaptive thresholding to the frame\n",
    "    binary_frame = adaptive_binarise(frame, block_size=21, c=9)\n",
    "    \n",
    "    # Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "    processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=3)\n",
    "    \n",
    "    # Apply the mask to the processed frame\n",
    "    masked_frame = cv2.bitwise_and(processed_frame, processed_frame, mask=mask)\n",
    "    \n",
    "    # Detect objects in the masked frame\n",
    "    objects = detect_objects(masked_frame, min_area=300, max_area=1000)\n",
    "    \n",
    "    # Check if there is only one shape (indicating contact)\n",
    "    if len(objects) == 1:\n",
    "        if current_event_start is None:\n",
    "            current_event_start = frame_count\n",
    "        current_event_end = frame_count\n",
    "    else:\n",
    "        if current_event_start is not None:\n",
    "            duration = current_event_end - current_event_start\n",
    "            if duration > event_min_length:\n",
    "                contact_events.append([current_event_start, current_event_end, duration])\n",
    "            current_event_start = None\n",
    "            current_event_end = None\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "# Handle the last event if it was still ongoing\n",
    "if current_event_start is not None:\n",
    "    duration = current_event_end - current_event_start\n",
    "    if duration > event_min_length:\n",
    "        contact_events.append([current_event_start, current_event_end, duration])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"Contact events:\", contact_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make clips of the contact events\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/ConnectedComponents\"\n",
    "\n",
    "# Make clips of the contact events\n",
    "\n",
    "for i, event in enumerate(contact_events):\n",
    "    # Define the start and end frames of the event\n",
    "    start_frame = event[0]\n",
    "    end_frame = event[1]\n",
    "\n",
    "    # Define the output file name\n",
    "    output_file = f\"{output_dir}/contact_event_{i}.mp4\"\n",
    "\n",
    "    # Make the clip\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # Get the frame width and height\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_file, fourcc, 30, (frame_width, frame_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or cap.get(cv2.CAP_PROP_POS_FRAMES) > end_frame:\n",
    "            break\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Saved contact event {i} to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's first detect event where the fly is in contact with the ball and then crop the frames around the fly and the ball and apply the connected components analysis to detect contacts.\n",
    "\n",
    "# Detect proximity events\n",
    "\n",
    "# Define the threshold distance\n",
    "threshold = 50\n",
    "\n",
    "events = find_contact_events(FLytrack, Balltrack, threshold=threshold, gap_between_events=4, event_min_length=2, fps=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first event and crop the frames around the fly and the ball\n",
    "\n",
    "# Load the first frame of the video corresponding to the first event\n",
    "\n",
    "# Get the first event\n",
    "event = events[0]\n",
    "\n",
    "# Get the start and end frames of the event\n",
    "\n",
    "start_frame = event[0]\n",
    "\n",
    "end_frame = event[1]\n",
    "\n",
    "# Load the video\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Set the frame position to the start frame\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Read the frame\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Release the video capture object\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display the frame\n",
    "\n",
    "plt.imshow(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the frame around the fly and the ball so 50 pixels after the fly and 20 before the ball\n",
    "\n",
    "# Get the fly and ball coordinates\n",
    "\n",
    "fly_x = FLytrack.loc[event[0], \"x_Thorax\"]\n",
    "\n",
    "fly_y = FLytrack.loc[event[0], \"y_Thorax\"]\n",
    "\n",
    "ball_x = Balltrack.loc[event[0], \"x_centre\"]\n",
    "\n",
    "ball_y = Balltrack.loc[event[0], \"y_centre\"]\n",
    "\n",
    "# Define the crop box\n",
    "\n",
    "crop_box = (int(fly_x - 15), int(ball_y - 50), int(fly_x + 15), int(fly_y + 50))\n",
    "\n",
    "# Crop the frame\n",
    "\n",
    "cropped_frame = frame[crop_box[1]:crop_box[3], crop_box[0]:crop_box[2]]\n",
    "\n",
    "# Display the cropped frame\n",
    "\n",
    "plt.imshow(cropped_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try classic binarisation\n",
    "\n",
    "# Apply binary thresholding to the cropped frame\n",
    "\n",
    "binary_frame = cv2.threshold(cropped_frame, 80, 255, cv2.THRESH_BINARY )[1]\n",
    "\n",
    "# invert the binary frame\n",
    "\n",
    "binary_frame = cv2.bitwise_not(binary_frame)\n",
    "\n",
    "# Display the binary frame\n",
    "\n",
    "plt.imshow(binary_frame, cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try adaptive binarisation\n",
    "\n",
    "# Apply adaptive thresholding to the cropped frame\n",
    "\n",
    "binary_frame = adaptive_binarise(cropped_frame, block_size=51, c=3)\n",
    "\n",
    "\n",
    "\n",
    "# Display the binary frame\n",
    "\n",
    "plt.imshow(binary_frame, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply connected components analysis to the cropped frame\n",
    "\n",
    "# Apply adaptive thresholding to the cropped frame\n",
    "\n",
    "binary_frame = adaptive_binarise(cropped_frame, block_size=51, c=3)\n",
    "\n",
    "# Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "\n",
    "processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=20)\n",
    "\n",
    "# Apply connected components analysis to the processed frame\n",
    "\n",
    "objects = detect_objects(processed_frame, min_area=300, max_area=2000)\n",
    "\n",
    "# Draw the detected objects on the cropped frame\n",
    "\n",
    "frame_with_objects = cv2.drawContours(cropped_frame.copy(), objects, -1, (0, 255, 0), thickness=2)\n",
    "\n",
    "# Display the frame with the detected objects\n",
    "\n",
    "plt.imshow(frame_with_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_binarise(frame, block_size=31, c=5):\n",
    "    if len(frame.shape) == 3:  # Convert to grayscale if needed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10):\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply morphological opening (erosion followed by dilation)\n",
    "    opened_frame = cv2.morphologyEx(binary_frame, cv2.MORPH_OPEN, kernel, iterations=open_iterations)\n",
    "    \n",
    "    # Apply morphological closing (dilation followed by erosion)\n",
    "    closed_frame = cv2.morphologyEx(opened_frame, cv2.MORPH_CLOSE, kernel, iterations=close_iterations)\n",
    "    \n",
    "    return closed_frame\n",
    "\n",
    "def detect_objects(frame, min_area=500, max_area=1000):\n",
    "    # Find contours in the frame\n",
    "    contours, _ = cv2.findContours(frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area\n",
    "    objects = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area <= area <= max_area:\n",
    "            objects.append(contour)\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def create_arena_mask(binary_frame, dilation_iterations=0):\n",
    "    # Create a mask for the arena\n",
    "    mask = np.zeros_like(binary_frame)\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    if dilation_iterations > 0:\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def check_contact(binary_frame):\n",
    "    # Perform connected component analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_frame)\n",
    "    \n",
    "    # Exclude the background label (0)\n",
    "    num_objects = num_labels - 1\n",
    "    \n",
    "    # If there is only one object, the fly and the ball are touching\n",
    "    if num_objects == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/ConnectedComponents\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the total number of frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Pick start and end, and make a video with processed frames\n",
    "start_frame = 12000\n",
    "end_frame = 13000\n",
    "\n",
    "# Set the frame position to the start frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Initialize the video writer\n",
    "output_file = f\"{output_dir}/cropped_process_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 29\n",
    "\n",
    "# Get the frame size\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Process the frames\n",
    "for frame_count in range(start_frame, end_frame):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary thresholding to the frame\n",
    "    _, binary_frame = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Invert the binary frame\n",
    "    binary_frame = cv2.bitwise_not(binary_frame)\n",
    "\n",
    "    # Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "    processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10)\n",
    "\n",
    "    # Check if the fly and the ball are touching\n",
    "    contact = check_contact(processed_frame)\n",
    "\n",
    "    # Draw the result on the frame\n",
    "    frame_with_contact = frame.copy()\n",
    "    if contact:\n",
    "        cv2.putText(frame_with_contact, \"Contact\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame_with_contact, \"No Contact\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame_with_contact)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"Video processing complete. Output saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_binarise(frame, block_size=31, c=5):\n",
    "    if len(frame.shape) == 3:  # Convert to grayscale if needed\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    binary = cv2.bitwise_not(binary)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10):\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply morphological opening (erosion followed by dilation)\n",
    "    opened_frame = cv2.morphologyEx(binary_frame, cv2.MORPH_OPEN, kernel, iterations=open_iterations)\n",
    "    \n",
    "    # Apply morphological closing (dilation followed by erosion)\n",
    "    closed_frame = cv2.morphologyEx(opened_frame, cv2.MORPH_CLOSE, kernel, iterations=close_iterations)\n",
    "    \n",
    "    return closed_frame\n",
    "\n",
    "def detect_objects(frame, min_area=500, max_area=1000):\n",
    "    # Find contours in the frame\n",
    "    contours, _ = cv2.findContours(frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area\n",
    "    objects = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if min_area <= area <= max_area:\n",
    "            objects.append(contour)\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def create_arena_mask(binary_frame, dilation_iterations=0):\n",
    "    # Create a mask for the arena\n",
    "    mask = np.zeros_like(binary_frame)\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    if dilation_iterations > 0:\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def check_contact(binary_frame):\n",
    "    # Perform connected component analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_frame)\n",
    "    \n",
    "    # Exclude the background label (0)\n",
    "    num_objects = num_labels - 1\n",
    "    \n",
    "    # If there is only one object, the fly and the ball are touching\n",
    "    if num_objects == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_contact_events(FLytrack, Balltrack, threshold=11, gap_between_events=4, event_min_length=2, fps=30):\n",
    "    \"\"\"\n",
    "    This function finds contact events where the fly's legs are touching the ball for a minimum amount of time.\n",
    "\n",
    "    Parameters:\n",
    "    FLytrack (DataFrame): DataFrame containing the fly's tracking data.\n",
    "    Balltrack (DataFrame): DataFrame containing the ball's tracking data.\n",
    "    threshold (int): The distance threshold (in pixels) for the fly's legs to be considered in contact with the ball.\n",
    "    gap_between_events (int): The minimum gap required between two events, expressed in seconds.\n",
    "    event_min_length (int): The minimum length of an event, expressed in seconds.\n",
    "    fps (int): Frames per second of the video.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of contact events, where each event is represented as [start_frame, end_frame, duration].\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the gap between events and the minimum event length from seconds to frames\n",
    "    gap_between_events = gap_between_events * fps\n",
    "    event_min_length = event_min_length * fps\n",
    "\n",
    "    # Compute the Euclidean distance for Lfront and Rfront\n",
    "    distances_Lfront = np.sqrt((FLytrack[\"x_Lfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Lfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "    distances_Rfront = np.sqrt((FLytrack[\"x_Rfront\"] - Balltrack[\"x_centre\"])**2 + (FLytrack[\"y_Rfront\"] - Balltrack[\"y_centre\"])**2)\n",
    "\n",
    "    # Find frames where either Lfront or Rfront is within the threshold distance\n",
    "    contact_frames = np.where((distances_Lfront < threshold) | (distances_Rfront < threshold))[0]\n",
    "\n",
    "    # If no contact frames are found, return an empty list\n",
    "    if len(contact_frames) == 0:\n",
    "        return []\n",
    "\n",
    "    # Find the distance between consecutive contact frames\n",
    "    distance_betw_frames = np.diff(contact_frames)\n",
    "\n",
    "    # Find the points where the distance between frames is greater than the gap between events\n",
    "    split_points = np.where(distance_betw_frames > gap_between_events)[0]\n",
    "\n",
    "    # Add the first and last points to the split points\n",
    "    split_points = np.insert(split_points, 0, -1)\n",
    "    split_points = np.append(split_points, len(contact_frames) - 1)\n",
    "\n",
    "    # Initialize the list of contact events\n",
    "    contact_events = []\n",
    "\n",
    "    # Iterate over the split points to find events\n",
    "    for f in range(0, len(split_points) - 1):\n",
    "        # Define the start and end of the region of interest (ROI)\n",
    "        start_roi = contact_frames[split_points[f] + 1]\n",
    "        end_roi = contact_frames[split_points[f + 1]]\n",
    "\n",
    "        # Calculate the duration of the event\n",
    "        duration = end_roi - start_roi\n",
    "\n",
    "        # If the duration of the event is greater than the minimum length, add the event to the list\n",
    "        if duration > event_min_length:\n",
    "            contact_events.append([start_roi, end_roi, duration])\n",
    "\n",
    "    return contact_events\n",
    "\n",
    "output_dir = \"/mnt/upramdya_data/MD/Other_Videos/ContactDetection/ConnectedComponents\"\n",
    "\n",
    "# Detect proximity events\n",
    "threshold = 50\n",
    "events = find_contact_events(FLytrack, Balltrack, threshold=threshold, gap_between_events=4, event_min_length=2, fps=29)\n",
    "\n",
    "# Process each event\n",
    "for event in events:\n",
    "    start_frame = event[0]\n",
    "    end_frame = event[1]\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        exit()\n",
    "\n",
    "    # Set the frame position to the start frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # Initialize the video writer\n",
    "    output_file = f\"{output_dir}/processed_event_{start_frame}_{end_frame}.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = 29\n",
    "\n",
    "    # Get the frame size\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Process the frames for the current event\n",
    "    for frame_count in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Ensure the frame is grayscale\n",
    "        if len(frame.shape) == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Get the fly and ball coordinates\n",
    "        fly_x = FLytrack.loc[frame_count, \"x_Thorax\"]\n",
    "        fly_y = FLytrack.loc[frame_count, \"y_Thorax\"]\n",
    "        ball_x = Balltrack.loc[frame_count, \"x_centre\"]\n",
    "        ball_y = Balltrack.loc[frame_count, \"y_centre\"]\n",
    "        \n",
    "        # Get the center of the frame\n",
    "        center_x = frame.shape[1] // 2\n",
    "\n",
    "        # Define the crop box\n",
    "        crop_x1 = max(0, int(center_x - 15))\n",
    "        crop_y1 = max(0, int(ball_y - 50))\n",
    "        crop_x2 = min(frame.shape[1], int(center_x + 15))\n",
    "        crop_y2 = min(frame.shape[0], int(fly_y + 50))\n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "\n",
    "        # Check if the cropped frame is empty\n",
    "        if cropped_frame.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Apply binary thresholding to the cropped frame\n",
    "        _, binary_frame = cv2.threshold(cropped_frame, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Invert the binary frame\n",
    "        binary_frame = cv2.bitwise_not(binary_frame)\n",
    "\n",
    "        # Apply asymmetric morphological operations to reduce noise and fill holes\n",
    "        processed_frame = apply_asymmetric_morphological_operations(binary_frame, kernel_size=1, open_iterations=1, close_iterations=10)\n",
    "\n",
    "        # Check if the fly and the ball are touching\n",
    "        contact = check_contact(processed_frame)\n",
    "\n",
    "        # Draw a green or red circle on the top of the frame based on the contact\n",
    "        \n",
    "        frame_with_contact = frame.copy()\n",
    "        if contact:\n",
    "            cv2.circle(frame_with_contact, (center_x, int((crop_y1 + crop_y2) / 2)), 10, (0, 255, 0), -1)\n",
    "        else:\n",
    "            cv2.circle(frame_with_contact, (center_x, int((crop_y1 + crop_y2) / 2)), 10, (0, 0, 255), -1)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame_with_contact)\n",
    "\n",
    "    # Release the video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "print(\"Video processing complete. Output saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
