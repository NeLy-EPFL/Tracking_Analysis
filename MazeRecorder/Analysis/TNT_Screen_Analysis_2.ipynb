{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_behavior\n",
    "\n",
    "from utils_behavior import Ballpushing_utils\n",
    "from utils_behavior import Utils\n",
    "from utils_behavior import Processing\n",
    "from utils_behavior import HoloviewsTemplates\n",
    "\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the path to either save or load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Utils.get_labserver() / \"Experimental_data/MultiMazeRecorder/Datasets/240306_TNT_Fine_Experiments.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the list of experiments\n",
    "\n",
    "Use the cells below to run the code from the beginning. Useful if something looks wrong in the already pre-saved dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data path\n",
    "Datapath = Utils.get_data_path()\n",
    "\n",
    "# Get all folders with \"TNT_Fine\" in the name\n",
    "\n",
    "Folders = [\n",
    "    f for f in os.listdir(Datapath) if \"TNT_Fine\" in f and \"Tracked\" in f and os.path.isdir(Datapath / f)\n",
    "]\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Experiment objects from each folder\n",
    "\n",
    "Experiments = [Ballpushing_utils.Experiment(Datapath / f) for f in Folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ballpushing_utils.save_object(Experiments, savepath.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-saved data from lab server\n",
    "\n",
    "To quickly reload already built Experiments, use cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the experiments from the saved file\n",
    "Experiments = utils_behavior.Ballpushing_utils.load_object(savepath.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the dataset from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Ballpushing_utils.Dataset(Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.generate_dataset(\"summary\")\n",
    "\n",
    "# Drop the flies whose genotype is either \"M6\", M7, PR or CS\n",
    "data.data=data.data[~data.data[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"CS\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set save folder\n",
    "\n",
    "This also needs to be updated if you want to generate a new set of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Utils.get_labserver() / \"Experimental_data/MultiMazeRecorder/Plots/240418_summaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"NumberEvents\",\n",
    "    \"FinalEvent\",\n",
    "    \"FinalTime\",\n",
    "    \"SignificantEvents\",\n",
    "    \"SignificantFirst\",\n",
    "    \"SignificantFirstTime\",\n",
    "    \"Pushes\",\n",
    "    \"Pulls\",\n",
    "    \"PullingRatio\",\n",
    "    \"InteractionProportion\",\n",
    "    \"AhaMoment\",\n",
    "    \"AhaMomentIndex\",\n",
    "    \"InsightEffect\",\n",
    "    \"TimeToFinish\",\n",
    "    \"SignificantRatio\",\n",
    "]\n",
    "\n",
    "# Loop over the metrics\n",
    "for metric in metrics:\n",
    "    # Generate the jitter boxplot for the current metric\n",
    "    HoloviewsTemplates.jitter_boxplot(\n",
    "        data.data,\n",
    "        metric,\n",
    "        show=True,\n",
    "        save=True,\n",
    "        metadata=data.metadata,\n",
    "        bs_controls=True,\n",
    "        sort_by=\"median\",\n",
    "        hline_method=\"boxplot\",\n",
    "        readme=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, one might only want to save one metric; here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resave one of the metrics\n",
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    data.data,\n",
    "    \"PullingRatio\",\n",
    "    show=False,\n",
    "    save=True,\n",
    "    metadata=data.metadata,\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "In this chapter we try some statistics. Data has too many outliers to allow for a parametric test. We'll use non parametric tests. We'll also do PCA to see if any pattern is immediately obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = (\n",
    "    Utils.get_labserver() / \"Experimental_data/MultiMazeRecorder/Datasets/Stats_TNT_Fine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"NumberEvents\",\n",
    "    \"FinalEvent\",\n",
    "    \"FinalTime\",\n",
    "    \"SignificantEvents\",\n",
    "    \"SignificantFirst\",\n",
    "    \"SignificantFirstTime\",\n",
    "    \"Pushes\",\n",
    "    \"Pulls\",\n",
    "    \"PullingRatio\",\n",
    "    \"InteractionProportion\",\n",
    "    \"AhaMoment\",\n",
    "    \"AhaMomentIndex\",\n",
    "    \"InsightEffect\",\n",
    "    \"TimeToFinish\",\n",
    "    \"SignificantRatio\",\n",
    "]\n",
    "\n",
    "Significant_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "\n",
    "    # Ensure the data only contains numeric values\n",
    "    if not pd.api.types.is_numeric_dtype(data.data[metric]):\n",
    "        print(f\"non-numeric metric: {metric}\")\n",
    "        data.data[metric] = pd.to_numeric(data.data[metric], errors=\"coerce\")\n",
    "\n",
    "    data_clean = data.data.dropna(subset=[metric])\n",
    "\n",
    "    # Perform the Kruskal-Wallis H-test\n",
    "    groups = [group[metric].values for name, group in data_clean.groupby(\"label\")]\n",
    "    H, p_kruskal = stats.kruskal(*groups)\n",
    "\n",
    "    # Perform multiple comparisons\n",
    "    p_values = []\n",
    "    labels = []\n",
    "    control_group = data_clean[data_clean[\"Genotype\"] == \"TNTxM7\"][metric].values\n",
    "\n",
    "    for name, group in data_clean[data_clean[\"Genotype\"] != \"TNTxM7\"].groupby(\"label\"):\n",
    "        test_group = group[metric].values\n",
    "        _, p = stats.mannwhitneyu(control_group, test_group, alternative=\"two-sided\")\n",
    "        p_values.append(p)\n",
    "        labels.append(name)\n",
    "\n",
    "    # Apply Bonferroni correction\n",
    "    reject, p_values_corrected, _, _ = multipletests(p_values, method=\"bonferroni\")\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    results = pd.DataFrame(\n",
    "        {\n",
    "            \"label\": labels,\n",
    "            \"p_value\": p_values,\n",
    "            \"p_value_corrected\": p_values_corrected,\n",
    "            \"reject\": reject,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    significant_results = results[results[\"reject\"]]\n",
    "\n",
    "    # If significant_result has values, print a message and save\n",
    "    if significant_results.shape[0] > 0:\n",
    "        print(f\"Significant results for {metric}\")\n",
    "        print(significant_results)\n",
    "        significant_results['metric'] = metric\n",
    "        Significant_results.append(significant_results)\n",
    "    else:\n",
    "        print(f\"No significant results for {metric}\")\n",
    "    # Save the table as csv with the metric name\n",
    "    significant_results.to_csv(savepath / f\"{metric}_stats_TNTPR.csv\", index=False)\n",
    "\n",
    "# Concatenate all significant results and save to a single CSV\n",
    "if Significant_results:\n",
    "    Significant_results_df = pd.concat(Significant_results)\n",
    "    Significant_results_df.to_csv(savepath / \"all_significant_results_TNTPR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on the data\n",
    "\n",
    "Here I'll try to do PCA on the data to see if I can get something interesting by reducing the dimensionality of the data, including all the summary metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the brain region table\n",
    "\n",
    "brain_regions_path = Utils.get_labserver() / \"Experimental_data/Region_map_240312.csv\"\n",
    "\n",
    "registry = pd.read_csv(brain_regions_path)\n",
    "\n",
    "registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Simplified Nickname column in mydata using the registry table to match Nickname and Simplified Nickname\n",
    "mydata = data.data\n",
    "\n",
    "mydata = mydata.merge(registry, left_on=\"Genotype\", right_on=\"Genotype\", how=\"left\")\n",
    "\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the \"Genotype_y\" column to \"Genotype\"\n",
    "mydata.rename(columns={\"Nickname_y\": \"Nickname\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting the data\n",
    "\n",
    "Some genotypes are removed from the analysis because PCA is sensitive to big variations. In particular, some like G74 and G75 are obviously unheathy flies from the videos whereas PR and CS that weren't crossed with TNT are less sensitive to starvation and show much lower activity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to remove some of the genotypes. Let's start with the M6 and M7 and PR genotypes, remove these.\n",
    "\n",
    "subset = mydata[~mydata[\"Genotype\"].isin([\"M6\", \"M7\", \"PR\", \"TNTxG74\", \"TNTxG75\", \"TNTxZ1633\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some metrics are not relevant for the analysis; also, some, like Genotype, are more labels than metrics. Here we only keep the metrics that can explain variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to only include the label and metrics of interest\n",
    "subset = subset[\n",
    "    [\n",
    "        \"NumberEvents\",\n",
    "        \"FinalEvent\",\n",
    "        \"FinalTime\",\n",
    "        \"SignificantEvents\",\n",
    "        \"SignificantFirst\",\n",
    "        \"SignificantFirstTime\",\n",
    "        \"PullingRatio\",\n",
    "        \"InteractionProportion\",\n",
    "        \"AhaMoment\",\n",
    "        \"AhaMomentIndex\",\n",
    "        \"InsightEffect\",\n",
    "        \"TimeToFinish\",\n",
    "        \"SignificantRatio\",\n",
    "        \"label\",\n",
    "        \"Brain region\",\n",
    "        \"fly\",\n",
    "        \"Genotype\",\n",
    "        \"Nickname\",\n",
    "        \"Simplified Nickname\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the features from the labels and brain region\n",
    "features = subset.drop(\n",
    "    [\"label\", \"Brain region\", \"fly\", \"Genotype\", \"Nickname\", \"Simplified Nickname\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Remove NaNs\n",
    "nan_indices = features.dropna().index\n",
    "features = features.loc[nan_indices].reset_index(drop=True)\n",
    "\n",
    "features_normalized = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # Adjust n_components as needed\n",
    "principalComponents = pca.fit_transform(features_normalized)\n",
    "\n",
    "# Convert the principal components for each sample to a DataFrame\n",
    "PCA_components = pd.DataFrame(principalComponents, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "# Add your labels and brain region to this DataFrame\n",
    "PCA_components[\"label\"] = subset.loc[nan_indices, \"label\"].values\n",
    "PCA_components[\"Brain region\"] = subset.loc[nan_indices, \"Brain region\"].values\n",
    "PCA_components[\"fly\"] = subset.loc[nan_indices, \"fly\"].values\n",
    "PCA_components[\"Genotype\"] = subset.loc[nan_indices, \"Genotype\"].values\n",
    "PCA_components[\"Nickname\"] = subset.loc[nan_indices, \"Nickname\"].values\n",
    "PCA_components[\"Simplified Nickname\"] = subset.loc[nan_indices, \"Simplified Nickname\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we only kept 2 factors to get a 2D representation. We can also do a 3 (or more) version like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3)\n",
    "\n",
    "principalComponents3 = pca3.fit_transform(features_normalized)\n",
    "\n",
    "\n",
    "#Convert the principal components for each sample to a DataFrame\n",
    "PCA_components3 = pd.DataFrame(principalComponents3, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "\n",
    "# Add your labels and brain region to this DataFrame\n",
    "PCA_components3[\"label\"] = subset.loc[nan_indices, \"label\"].values\n",
    "PCA_components3[\"Brain region\"] = subset.loc[nan_indices, \"Brain region\"].values\n",
    "PCA_components3[\"fly\"] = subset.loc[nan_indices, \"fly\"].values\n",
    "PCA_components3[\"Genotype\"] = subset.loc[nan_indices, \"Genotype\"].values\n",
    "PCA_components3[\"Nickname\"] = subset.loc[nan_indices, \"Nickname\"].values\n",
    "PCA_components3[\"Simplified Nickname\"] = subset.loc[nan_indices, \"Simplified Nickname\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the composition of the principal components\n",
    "PCs_compo3 = pd.DataFrame(pca3.components_, columns=features.columns, index=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(f\"Explained variance of PC1, PC2 and PC3 : {pca3.explained_variance_ratio_}\")\n",
    "\n",
    "PCs_compo3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's check how much variance each of the 10 first PCs can explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca10 = PCA(n_components=10)\n",
    "\n",
    "principalComponents10 = pca10.fit_transform(features_normalized)\n",
    "\n",
    "# Convert the principal components for each sample to a DataFrame\n",
    "PCA_components10 = pd.DataFrame(principalComponents10, columns=[f\"PC{i}\" for i in range(1, 11)])\n",
    "\n",
    "# Add your labels and brain region to this DataFrame\n",
    "PCA_components10[\"label\"] = subset.loc[nan_indices, \"label\"].values\n",
    "PCA_components10[\"Brain region\"] = subset.loc[nan_indices, \"Brain region\"].values\n",
    "PCA_components10[\"fly\"] = subset.loc[nan_indices, \"fly\"].values\n",
    "PCA_components10[\"Genotype\"] = subset.loc[nan_indices, \"Genotype\"].values\n",
    "PCA_components10[\"Nickname\"] = subset.loc[nan_indices, \"Nickname\"].values\n",
    "PCA_components10[\"Simplified Nickname\"] = subset.loc[nan_indices, \"Simplified Nickname\"].values\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(f\"Explained variance of the first 10 PCs : {pca10.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the composition of the principal components and highlight in green the values below -0.3 and in red the values above 0.3\n",
    "PCs_compo10 = pd.DataFrame(pca10.components_, columns=features.columns, index=[f\"PC{i}\" for i in range(1, 11)])\n",
    "\n",
    "PCs_compo10.style.applymap(lambda x: \"color: green\" if x < -0.3 else \"color: red\" if x > 0.3 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the composition of the principal components\n",
    "PCs_compo = pd.DataFrame(pca.components_, columns=features.columns, index=[\"PC1\", \"PC2\"])\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(f\"Explained variance of PC1 and PC2 : {pca.explained_variance_ratio_}\")\n",
    "\n",
    "PCs_compo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the composition of the principal components and the explained variance ratio\n",
    "PCs_compo.to_csv(savepath/\"PCs_composition.csv\")\n",
    "pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC1\", \"PC2\"], columns=[\"Explained variance\"]).to_csv(savepath/\"PCA_Explained_variance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data unique Genotype values\n",
    "\n",
    "unique_genotypes = subset[\"Genotype\"].unique()\n",
    "\n",
    "# Check if there is one called \"TNTxZ2018\"\n",
    "\n",
    "\"TNTxZ2018\" in unique_genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the label associated with Genotype \"TNTxZ2018\"\n",
    "TNTxZ2018_label = mydata[mydata[\"Genotype\"] == \"TNTxZ2018\"][\"label\"].values[0]\n",
    "\n",
    "TNTxZ2018_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "\n",
    "# Separate the \"TNTxZ2018\" data from the rest of the data\n",
    "TNTxZ2018_data = PCA_components[PCA_components[\"label\"] == TNTxZ2018_label]\n",
    "other_data = PCA_components[PCA_components[\"label\"] != TNTxZ2018_label]\n",
    "\n",
    "# Initialize an empty Layout\n",
    "plots = hv.Layout()\n",
    "\n",
    "# Generate one plot per Brain region\n",
    "for brain_region in PCA_components[\"Brain region\"].unique():\n",
    "    df_brain_region = other_data[other_data[\"Brain region\"] == brain_region]\n",
    "\n",
    "    # Create separate scatter plots for the \"TNTxZ2018\" genotype and the other genotypes\n",
    "    plot1 = df_brain_region.hvplot.scatter(\n",
    "        x=\"PC1\", y=\"PC2\", by=\"label\", hover_cols=[\"fly\"], cmap=\"nipy_spectral\"\n",
    "    )\n",
    "    plot2 = TNTxZ2018_data.hvplot.scatter(\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        by=\"label\",\n",
    "        hover_cols=[\"fly\"],\n",
    "        color=\"black\",\n",
    "        marker=\"x\",\n",
    "        size=100,\n",
    "    )\n",
    "\n",
    "    # Combine the plots\n",
    "    final_plot = (plot1 * plot2).opts(width=1000, height = 750)\n",
    "\n",
    "    # Add the plot to the Layout\n",
    "    plots += final_plot.relabel(f\"PCA - Brain Region: {brain_region}\")\n",
    "\n",
    "# Save the Layout\n",
    "hvplot.save(plots.cols(1), savepath/\"240306_PCA_plots.html\")\n",
    "# Display the Layout\n",
    "#hvplot.show(plots.cols(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the PCs separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column called \"Efficiency\" that is the inverted values of PC1 (typically, -2 will be 2)\n",
    "\n",
    "PCA_components[\"Efficiency\"] = -PCA_components[\"PC1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PC1 and PC2 as jitterboxplots\n",
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    PCA_components,\n",
    "    \"Efficiency\",\n",
    "    folder=\"240426_TNT_New\",\n",
    "    kdims=\"label\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    metadata=[],\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    "    readme=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.help(hv.BoxWhisker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with PC2\n",
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    PCA_components,\n",
    "    \"PC2\",\n",
    "    show=True,\n",
    "    save=True,\n",
    "    metadata=[],\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    "    readme=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Find flies with particular pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Perform the Kruskal-Wallis H-test\n",
    "groups = [group[\"PC1\"].values for name, group in PCA_components.groupby(\"Genotype\")]\n",
    "H, p_kruskal = stats.kruskal(*groups)\n",
    "\n",
    "# Perform multiple comparisons\n",
    "p_values = []\n",
    "labels = []\n",
    "genotypes = []\n",
    "brain_regions = []\n",
    "control_group = PCA_components[PCA_components[\"Genotype\"] == \"TNTxM6\"][\"PC1\"].values\n",
    "\n",
    "for name, group in PCA_components[PCA_components[\"Genotype\"] != \"TNTxM6\"].groupby(\n",
    "    \"label\"\n",
    "):\n",
    "    test_group = group[\"PC1\"].values\n",
    "    _, p = stats.mannwhitneyu(control_group, test_group, alternative=\"two-sided\")\n",
    "    p_values.append(p)\n",
    "    labels.append(name)\n",
    "    genotypes.append(\n",
    "        group[\"Genotype\"].iloc[0]\n",
    "    )  # assuming each group has a single genotype\n",
    "    brain_regions.append(\n",
    "        group[\"Brain region\"].iloc[0]\n",
    "    )  # assuming each group has a single brain region\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "reject, p_values_corrected, _, _ = multipletests(p_values, method=\"bonferroni\")\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"label\": labels,\n",
    "        \"Genotype\": genotypes,\n",
    "        \"Brain region\": brain_regions,\n",
    "        \"p_value\": p_values,\n",
    "        \"p_value_corrected\": p_values_corrected,\n",
    "        \"reject\": reject,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"reject\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"p_value\"] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(savepath / \"PC1_p_values_TNTEmptySplit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the p_values that are smaller than 0.05\n",
    "significant_results = results[results[\"reject\"]]\n",
    "\n",
    "significant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group[\"PC1\"].values for name, group in PCA_components.groupby(\"label\")]\n",
    "\n",
    "Effect_Sizes = []\n",
    "# control_group = PCA_components[PCA_components[\"Genotype\"] == \"TNTxZ2035\"][\"PC1\"].values\n",
    "\n",
    "control_genotypes = [\n",
    "    \"TNTxZ2035\",\n",
    "    \"TNTxZ2018\",\n",
    "    \"TNTxM7\",\n",
    "]  # Replace with your list of genotypes\n",
    "control_group = PCA_components[PCA_components[\"Genotype\"].isin(control_genotypes)][\n",
    "    \"PC1\"\n",
    "].values\n",
    "\n",
    "ctrl_bci = Processing.draw_bs_ci(control_group)\n",
    "\n",
    "# for name, group in PCA_components[PCA_components[\"Genotype\"] != \"TNTxZ2035\"].groupby(\n",
    "#     \"label\"\n",
    "# ):\n",
    "for name, group in PCA_components[\n",
    "    ~PCA_components[\"Genotype\"].isin(control_genotypes)\n",
    "].groupby(\"label\"):\n",
    "    bci = Processing.draw_bs_ci(group[\"PC1\"].values)\n",
    "\n",
    "    effect_size = (bci[0] - ctrl_bci[1], bci[1] - ctrl_bci[0])\n",
    "\n",
    "    # Get the 'Brain region' of the group\n",
    "    brain_region = group[\"Brain region\"].iloc[0]\n",
    "\n",
    "    result = {\"Brain region\": brain_region, \"label\": name, \"effect_size\": effect_size, \"bs_ci\": bci}\n",
    "\n",
    "    Effect_Sizes.append(result)\n",
    "\n",
    "results = pd.DataFrame(Effect_Sizes)\n",
    "\n",
    "# filter the results to only get those for which effect_size[0] and effect_size[1] are either both postive or negative\n",
    "significant_results = results[results[\"effect_size\"].apply(lambda x: x[0]*x[1] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = pd.DataFrame([{\"Brain region\": \"Control\", \"label\": \"Control\", \"effect_size\": None, \"bs_ci\": ctrl_bci}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsCi_dataset = pd.concat([ctrl, significant_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsCi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the middle point of each interval\n",
    "BsCi_dataset[[\"bs_ci_lower\", \"bs_ci_upper\"]] = pd.DataFrame(\n",
    "    BsCi_dataset[\"bs_ci\"].tolist(), index=BsCi_dataset.index\n",
    ")\n",
    "\n",
    "BsCi_dataset[\"lower\"] = abs(BsCi_dataset[\"bs_ci_lower\"])\n",
    "BsCi_dataset[\"upper\"] = abs(BsCi_dataset[\"bs_ci_upper\"])\n",
    "\n",
    "BsCi_dataset['middle'] = (BsCi_dataset['bs_ci_lower'] + BsCi_dataset['bs_ci_upper']) / 2\n",
    "\n",
    "# Compute the lengths of the error bars\n",
    "BsCi_dataset[\"lower_length\"] = BsCi_dataset[\"middle\"] - BsCi_dataset[\"bs_ci_lower\"]\n",
    "BsCi_dataset[\"upper_length\"] = BsCi_dataset[\"bs_ci_upper\"] - BsCi_dataset[\"middle\"]\n",
    "\n",
    "# Sort the DataFrame by 'Brain region' and 'middle'\n",
    "BsCi_dataset_sorted = BsCi_dataset.sort_values([\"Brain region\", \"middle\"])\n",
    "\n",
    "Ctrl = BsCi_dataset_sorted[BsCi_dataset_sorted[\"label\"] == \"Control\"]\n",
    "# Create an Area plot for the confidence interval\n",
    "hv_hline = hv.HSpan(Ctrl[\"bs_ci_lower\"][0], Ctrl[\"bs_ci_upper\"][0]).opts(\n",
    "    fill_alpha=0.2, color=\"red\"\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plot = hv.ErrorBars(\n",
    "    BsCi_dataset_sorted,\n",
    "    kdims=[\"label\"],\n",
    "    vdims=[\"middle\", \"lower_length\", \"upper_length\", \"Brain region\"],\n",
    ").opts(invert_axes=True, color='Brain region', line_width =2)\n",
    "\n",
    "plot = plot*hv_hline\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "hv.extension(\"bokeh\")\n",
    "plot.opts(width=600, height=1000, xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(plot, savepath/\"PC1_bs_ci_TNT__PooledControls.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(Effect_Sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsCi_dataset.to_csv(savepath / \"PC1_bs_ci_TNTPR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsCi_dataset[\"Brain region\"] =\"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'bs_ci' column into two columns 'bs_ci_lower' and 'bs_ci_upper'\n",
    "BsCi_dataset[[\"bs_ci_lower\", \"bs_ci_upper\"]] = pd.DataFrame(\n",
    "    BsCi_dataset[\"bs_ci\"].tolist(), index=BsCi_dataset.index\n",
    ")\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "plot = hv.ErrorBars(\n",
    "    BsCi_dataset, kdims=[\"label\"], vdims=[\"PC1\", \"bs_ci_lower\", \"bs_ci_upper\"]\n",
    ").opts()\n",
    "\n",
    "# Display the plot\n",
    "# hv.extension(\"bokeh\")\n",
    "plot.opts(width=600, height=1000, xrotation=90, invert_axes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BsCi_dataset['bs_ci_lower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the PCA to another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data path\n",
    "Datapath = Utils.get_data_path()\n",
    "\n",
    "# Get all folders with \"TNT_Fine\" in the name\n",
    "\n",
    "Folders = []\n",
    "for folder in Datapath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"feedingstate\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Ballpushing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230704_FeedingState_1_PM_Videos_Tracked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all directories containing at least one .mp4 file\n",
    "mp4_directories = [\n",
    "    dir for dir in directory.glob(\"**/*\") if any(dir.glob(\"*.mp4\"))\n",
    "]\n",
    "\n",
    "# Find all .mp4 files that are named the same as their parent directory\n",
    "mp4_files = [\n",
    "    mp4_file\n",
    "    for dir in mp4_directories\n",
    "    if (\n",
    "        (mp4_file := dir / f\"{dir.name}.mp4\").exists()\n",
    "        or (\n",
    "            mp4_file := dir / f\"{dir.parent.name}_corridor_{dir.name[-1]}.mp4\"\n",
    "        ).exists()\n",
    "    )\n",
    "]\n",
    "\n",
    "mp4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments = [Ballpushing_utils.Experiment(Datapath / f) for f in Folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp1 = Experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestExp = Ballpushing_utils.Experiment(Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230704_FeedingState_1_PM_Videos_Tracked\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly = Ballpushing_utils.Fly(Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230704_FeedingState_1_PM_Videos_Tracked/arena4/corridor4/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp1.flies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Utils.get_labserver() / \"Experimental_data/MultiMazeRecorder/Datasets/240422_FeedingState_Experiments.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ballpushing_utils.save_object(Experiments, savepath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments = Ballpushing_utils.load_object(savepath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedingStateData = Ballpushing_utils.Dataset(Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FeedingStateData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedingStateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedingStateData.generate_dataset(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_data = FeedingStateData.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get how many rows of Light values I have grouped by unique Light values\n",
    "\n",
    "FeedingStateData.data.groupby(\"Light\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedingStateData.data[\"Condition\"] = (\n",
    "    FeedingStateData.data[\"Light\"].astype(str)\n",
    "    + \"_\"\n",
    "    + FeedingStateData.data[\"FeedingState\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    FeedingStateData.data,\n",
    "    vdim=\"NumberEvents\",\n",
    "    kdims=\"Condition\",\n",
    "    show=True,\n",
    "    save=True,\n",
    "    metadata=FeedingStateData.metadata,\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    "    readme=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"NumberEvents\",\n",
    "    \"FinalEvent\",\n",
    "    \"FinalTime\",\n",
    "    \"SignificantEvents\",\n",
    "    \"SignificantFirst\",\n",
    "    \"SignificantFirstTime\",\n",
    "    \"Pushes\",\n",
    "    \"Pulls\",\n",
    "    \"PullingRatio\",\n",
    "    \"InteractionProportion\",\n",
    "    \"AhaMoment\",\n",
    "    \"AhaMomentIndex\",\n",
    "    \"InsightEffect\",\n",
    "    \"TimeToFinish\",\n",
    "    \"SignificantRatio\",\n",
    "]\n",
    "\n",
    "# Loop over the metrics\n",
    "for metric in metrics:\n",
    "    # Generate the jitter boxplot for the current metric\n",
    "    HoloviewsTemplates.jitter_boxplot(\n",
    "        FeedingStateData.data,\n",
    "        vdim=metric,\n",
    "        folder = \"240422_FeedingState_Light_summaries/byFeedingState\",\n",
    "        kdims=\"FeedingState\",\n",
    "        show=True,\n",
    "        save=True,\n",
    "        metadata=FeedingStateData.metadata,\n",
    "        bs_controls=True,\n",
    "        sort_by=\"median\",\n",
    "        hline_method=\"boxplot\",\n",
    "        readme=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Bootstrapped confidence intervals of InsightEffect grouped by Light\n",
    "\n",
    "grouped = FeedingStateData.data.groupby(\"Light\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lighton = FeedingStateData.data[FeedingStateData.data[\"Light\"]==\"on\"]\n",
    "# Remove Nans\n",
    "Lighton = Lighton.dropna(subset=[\"InsightEffect\"])\n",
    "LightOff = FeedingStateData.data[FeedingStateData.data[\"Light\"] == \"off\"]\n",
    "LightOff = LightOff.dropna(subset=[\"InsightEffect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_bc = Processing.draw_bs_ci(Lighton['InsightEffect'])\n",
    "\n",
    "on_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_bc = Processing.draw_bs_ci(LightOff[\"InsightEffect\"])\n",
    "\n",
    "off_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EffectSize = (on_bc[0]/off_bc[1],on_bc[1] / off_bc[0])\n",
    "\n",
    "EffectSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "for name, group in grouped:\n",
    "    data = group[\"InsightEffect\"].values\n",
    "    ci = Processing.draw_bs_ci(data)\n",
    "    results[name] = ci\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to only include the label and metrics of interest\n",
    "data_fs = FeedingStateData.data\n",
    "subset_fs = data_fs[\n",
    "    [\n",
    "        \"NumberEvents\",\n",
    "        \"FinalEvent\",\n",
    "        \"FinalTime\",\n",
    "        \"SignificantEvents\",\n",
    "        \"SignificantFirst\",\n",
    "        \"SignificantFirstTime\",\n",
    "        \"PullingRatio\",\n",
    "        \"InteractionProportion\",\n",
    "        \"AhaMoment\",\n",
    "        \"AhaMomentIndex\",\n",
    "        \"InsightEffect\",\n",
    "        \"TimeToFinish\",\n",
    "        \"SignificantRatio\",\n",
    "        \"label\",\n",
    "        \"fly\",\n",
    "        \"Light\",\n",
    "        \"FeedingState\",\n",
    "        \"Period\",\n",
    "        \"Orientation\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fs[\"new_label\"] = subset_fs[\"label\"]\n",
    "\n",
    "subset_fs[\"new_fly\"] = subset_fs[\"fly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the features from the labels and brain region\n",
    "new_features = subset_fs.drop(\n",
    "    [\"label\", \"fly\", \"new_label\", \"new_fly\", \"Light\", \"FeedingState\", \"Period\", \"Orientation\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Remove NaNs\n",
    "nan_indices = new_features.dropna().index\n",
    "new_features = new_features.loc[nan_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that 'new_features' is your new dataset\n",
    "# Make sure to preprocess 'new_features' in the same way as your original dataset\n",
    "\n",
    "\n",
    "# Normalize the new features\n",
    "new_features_normalized = scaler.transform(new_features)  # Use the same scaler fitted on the original dataset\n",
    "\n",
    "# Apply PCA\n",
    "new_principalComponents = pca.transform(new_features_normalized)  # Use the same pca fitted on the original dataset\n",
    "\n",
    "# Convert the principal components for each sample to a DataFrame\n",
    "new_PCA_components = pd.DataFrame(new_principalComponents, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "# Add your labels and brain region to this DataFrame\n",
    "# Make sure 'new_subset' has the same structure as your original 'subset'\n",
    "new_PCA_components[\"new_label\"] = subset_fs.loc[nan_indices, \"new_label\"].values\n",
    "new_PCA_components[\"new_fly\"] = subset_fs.loc[nan_indices, \"new_fly\"].values\n",
    "new_PCA_components[\"Light\"] = subset_fs.loc[nan_indices, \"Light\"].values\n",
    "new_PCA_components[\"FeedingState\"] = subset_fs.loc[nan_indices, \"FeedingState\"].values\n",
    "new_PCA_components[\"Period\"] = subset_fs.loc[nan_indices, \"Period\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PCA_components[\"Orientation\"] = subset_fs.loc[nan_indices, \"Orientation\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PCA_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PCA_components[\"Brain region\"] = \"None\"\n",
    "\n",
    "new_PCA_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PCA_components[\"Condition\"] = (\n",
    "    new_PCA_components[\"Light\"].astype(str)\n",
    "    + \"_\"\n",
    "    + new_PCA_components[\"FeedingState\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHange \"new_fly\" column name to \"fly\"\n",
    "\n",
    "new_PCA_components.rename(columns={\"new_fly\": \"fly\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    new_PCA_components,\n",
    "    folder=\"240422_FeedingState_Light_summaries\",\n",
    "    vdim=\"PC1\",\n",
    "    kdims=\"Condition\",\n",
    "    show=True,\n",
    "    save=True,\n",
    "    metadata=[],\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    "    readme=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate scatter plots for the \"TNTxZ2018\" genotype and the other genotypes\n",
    "PCplot = new_PCA_components.hvplot.scatter(\n",
    "    x=\"PC1\", y=\"PC2\", by=\"FeedingState\", hover_cols=[\"fly\"], cmap=\"nipy_spectral\"\n",
    ").opts(width=1000, height = 750)\n",
    "\n",
    "PCplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    Utils.get_labserver()\n",
    "    / \"Experimental_data\"\n",
    "    / \"MultiMazeRecorder\"\n",
    "    / \"Plots\"\n",
    "    / \"240422_FeedingState_Light_summaries\"\n",
    "    / \"byFeedingState\"\n",
    "    / \"PCA_Fullplot.html\"\n",
    ")\n",
    "\n",
    "hv.save(PCplot, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball types experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data path\n",
    "Datapath = Utils.get_data_path()\n",
    "\n",
    "# Get all folders with \"TNT_Fine\" in the name\n",
    "\n",
    "Folders = []\n",
    "for folder in Datapath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"balltype\" in minfolder and \"tracked\" in minfolder:\n",
    "        Folders.append(folder)\n",
    "        \n",
    "        \n",
    "print(Folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallExps = [Ballpushing_utils.Experiment(Datapath/f) for f in Folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BallData = Ballpushing_utils.Dataset(BallExps)\n",
    "BallData.generate_dataset(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(HoloviewsTemplates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"NumberEvents\",\n",
    "    \"FinalEvent\",\n",
    "    \"FinalTime\",\n",
    "    \"SignificantEvents\",\n",
    "    \"SignificantFirst\",\n",
    "    \"SignificantFirstTime\",\n",
    "    \"Pushes\",\n",
    "    \"Pulls\",\n",
    "    \"PullingRatio\",\n",
    "    \"InteractionProportion\",\n",
    "    \"AhaMoment\",\n",
    "    \"AhaMomentIndex\",\n",
    "    \"InsightEffect\",\n",
    "    \"TimeToFinish\",\n",
    "    \"SignificantRatio\",\n",
    "]\n",
    "\n",
    "# Loop over the metrics\n",
    "for metric in metrics:\n",
    "    # Generate the jitter boxplot for the current metric\n",
    "    HoloviewsTemplates.jitter_boxplot(\n",
    "        BallData.data,\n",
    "        vdim=metric,\n",
    "        kdims=\"BallType\",\n",
    "        show=True,\n",
    "        save=True,\n",
    "        metadata=BallData.metadata,\n",
    "        bs_controls=True,\n",
    "        sort_by=\"median\",\n",
    "        hline_method=\"boxplot\",\n",
    "        readme=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HoloviewsTemplates.jitter_boxplot(\n",
    "    BallData.data,\n",
    "    vdim=\"InsightEffect\",\n",
    "    kdims=\"BallType\",\n",
    "    show=True,\n",
    "    save=True,\n",
    "    metadata=BallData.metadata,\n",
    "    bs_controls=True,\n",
    "    sort_by=\"median\",\n",
    "    hline_method=\"boxplot\",\n",
    "    readme=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full plot from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = PCA_components\n",
    "\n",
    "pooled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Simplified Nickname\" that have the word \"MBON\" two times in the same string\n",
    "MBONs = pooled[pooled[\"Simplified Nickname\"].str.contains(\"MBON\")][\"Simplified Nickname\"].unique()\n",
    "\n",
    "MBONs[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import FuncTickFormatter\n",
    "\n",
    "# Define the long labels\n",
    "long_labels = [\"MBON-16-GaL4   MBON-17-Gal4 \", \"MBON-08-GaL4  MBON-09-GaL4 \"]\n",
    "\n",
    "# Replace the second space in each label with a newline character\n",
    "new_labels = [label.replace(\" \", \" \\n\", 1) for label in long_labels]\n",
    "\n",
    "# In pooled, replace the long labels with the new labels\n",
    "pooled[\"Simplified Nickname\"].replace(long_labels, new_labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the value to the old long labels\n",
    "pooled[\"Simplified Nickname\"].replace(new_labels, long_labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the new labels are in the \"Simplified Nickname\" column\n",
    "pooled[pooled[\"Simplified Nickname\"].isin(new_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting data by brain region and Nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median for each 'Brain region' and 'Nickname'\n",
    "median_values = pooled.groupby([\"Brain region\", \"Simplified Nickname\"])[\"PC2\"].median()\n",
    "\n",
    "# Sort 'Brain region' by its median\n",
    "region_order = median_values.groupby(\"Brain region\").median().sort_values().index\n",
    "\n",
    "# Within each 'Brain region', sort 'Nickname' by its median\n",
    "nickname_order_within_region = median_values.groupby(\"Brain region\").apply(\n",
    "    lambda x: x.sort_values().index.get_level_values(\"Simplified Nickname\")\n",
    ")\n",
    "\n",
    "# Create a new category type for 'Brain region' with the calculated order\n",
    "pooled[\"Brain region\"] = pd.Categorical(\n",
    "    pooled[\"Brain region\"], categories=region_order, ordered=True\n",
    ")\n",
    "\n",
    "# Create a list to hold the correct order of 'Nickname' across all 'Brain regions'\n",
    "correct_order_global = []\n",
    "\n",
    "# For each 'Brain region', add the 'Nickname' order to the global list\n",
    "for region in region_order:\n",
    "    correct_order_global.extend(nickname_order_within_region[region])\n",
    "\n",
    "# Convert 'Nickname' to a categorical type with the global order\n",
    "pooled[\"Simplified Nickname\"] = pd.Categorical(\n",
    "    pooled[\"Simplified Nickname\"], categories=correct_order_global, ordered=True\n",
    ")\n",
    "\n",
    "# Now you can sort\n",
    "pooled.sort_values(by=[\"Brain region\", \"Simplified Nickname\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and represent the control area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 25% and 75% quantiles for the control group\n",
    "control_data = pooled[pooled[\"Genotype\"] == \"TNTxZ2018\"]\n",
    "hline_values = (\n",
    "    control_data[\"PC2\"].quantile(0.25),\n",
    "    control_data[\"PC2\"].quantile(0.75),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the limits for the y axis\n",
    "y_min = pooled[\"PC2\"].min()\n",
    "# For y_max, use the 95th percentile of the data\n",
    "y_max = pooled[\"PC2\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "\n",
    "# Get the metadata for the tooltips\n",
    "tooltips = [\n",
    "    (\"Fly\", \"@fly\"),\n",
    "    (\"PC2\".capitalize(), \"@PC2\"),\n",
    "]\n",
    "\n",
    "\n",
    "hover = HoverTool(tooltips=tooltips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "pooled_opts = {\n",
    "    \"boxwhisker\": {\n",
    "        #\"box_fill_color\": None,\n",
    "        # \"box_line_color\": \"black\",\n",
    "        \"outlier_fill_color\": None,\n",
    "        \"outlier_line_color\": None,\n",
    "        \"framewise\": True,\n",
    "    },\n",
    "    \"scatter\": {\n",
    "        \"jitter\": 0.15,\n",
    "        \"color\": \"black\",\n",
    "        \"alpha\": 0.8,\n",
    "        \"size\": 2,\n",
    "        #\"cmap\": \"Category10\",\n",
    "        \"framewise\": True,\n",
    "    },\n",
    "    \"plot\": {\n",
    "        \"width\": 1100,\n",
    "        \"height\": 1423,\n",
    "        \"show_legend\": False,\n",
    "        \"xlabel\": \"\",\n",
    "        \"invert_axes\": True,\n",
    "        \"show_grid\": True,\n",
    "        \"fontscale\": 1,\n",
    "        \"title\": \"\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect ratio computation\n",
    "\n",
    "# For 1100 width I have 1423 height. What about if I have 1500 width?\n",
    "# 1500 * 1423 / 1100 = 1935\n",
    "\n",
    "# For 1800 width?\n",
    "# 1800 * 1423 / 1100 = 2323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.themes import Theme\n",
    "\n",
    "# Create a custom theme\n",
    "theme = Theme(\n",
    "    json={\n",
    "        \"attrs\": {\n",
    "            \"Title\": {\"text_font\": \"Arial\"},\n",
    "            \"AxisLabel\": {\"text_font\": \"Arial\"},\n",
    "            \"Legend\": {\"text_font\": \"Arial\"},\n",
    "            \"TickLabel\": {\"text_font\": \"Arial\"},\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Apply the theme\n",
    "hv.renderer(\"bokeh\").theme = theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_regions = pooled[\"Brain region\"].unique()\n",
    "\n",
    "plot_options = pooled_opts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = hv.Overlay(\n",
    "    [\n",
    "        hv.BoxWhisker(\n",
    "            pooled[pooled[\"Brain region\"] == region],\n",
    "            kdims=\"Simplified Nickname\",\n",
    "            vdims=\"PC2\",\n",
    "        ).opts(**plot_options[\"boxwhisker\"], box_color=color)\n",
    "        for region, color in zip(brain_regions, hv.Cycle(\"Category10\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the overlaid boxplots\n",
    "# boxplot.opts(show_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot = hv.Scatter(\n",
    "    data=pooled,\n",
    "    vdims=[\"PC2\"]\n",
    "    + [\"fly\"]\n",
    "    + [\"Brain region\"]\n",
    "    + [\"Simplified Nickname\"]\n",
    "    + [\"Genotype\"]\n",
    "    + [\"label\"]\n",
    "    + [\"PC2\"],\n",
    "    kdims=[\"Simplified Nickname\"],\n",
    ").opts(**plot_options[\"scatter\"], tools=[hover], ylim=(y_min, y_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the control area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_hline = hv.HSpan(hline_values[0], hline_values[1]).opts(fill_alpha=0.2, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of simplified labels\n",
    "unique_labels = pooled[\"Simplified Nickname\"].unique()\n",
    "unique_labels\n",
    "\n",
    "# Find the \"Simplified Nickname\" that is nan and find the associated \"Nickname\"\n",
    "nan_simplified_nickname = pooled[pooled[\"Simplified Nickname\"].isna()][\"Nickname\"].unique()\n",
    "\n",
    "nan_simplified_nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitterboxplot = (\n",
    "    (hv_hline * boxplot * scatterplot)\n",
    "    .opts(ylabel=\"PC2\", **plot_options[\"plot\"])\n",
    "    .opts(show_grid=False, fontsize={\"yticks\": 10})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitterboxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot\n",
    "hv.save(jitterboxplot, savepath/\"240315_PCA2_jitterboxplot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "\n",
    "from bokeh.io import export_svgs\n",
    "\n",
    "# Create a custom theme\n",
    "theme = Theme(\n",
    "    json={\n",
    "        \"attrs\": {\n",
    "            \"Title\": {\"text_font\": \"Arial\"},\n",
    "            \"AxisLabel\": {\"text_font\": \"Arial\"},\n",
    "            \"Legend\": {\"text_font\": \"Arial\"},\n",
    "            \"TickLabel\": {\"text_font\": \"Arial\"},\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Apply the theme\n",
    "hv.renderer(\"bokeh\").theme = theme\n",
    "\n",
    "\n",
    "def export_svg(obj, filename):\n",
    "    plot_state = hv.renderer(\"bokeh\").get_plot(obj).state\n",
    "    plot_state.output_backend = \"svg\"\n",
    "    export_svgs(plot_state, filename=filename)\n",
    "\n",
    "\n",
    "export_svg(jitterboxplot, savepath / \"240306_PCA_jitterboxplot.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 96  # adjust this to match your intended DPI\n",
    "width_in = 1100 / dpi\n",
    "height_in = 1423 / dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the same plotting with matplotlib backend\n",
    "\n",
    "pooled_opts_matplotlib = {\n",
    "    \"boxwhisker\": {\n",
    "        \"showfliers\": False,  # equivalent to setting outlier fill and line color to None\n",
    "        \"notch\": False,  # equivalent to framewise\n",
    "        # \"patch_artist\":True,\n",
    "    },\n",
    "    \"scatter\": {\n",
    "        # \"jitter\": 0.15,\n",
    "        \"color\": \"black\",\n",
    "        \"alpha\": 0.8,\n",
    "        \"s\": 4,  # equivalent to size\n",
    "    },\n",
    "    \"plot\": {\n",
    "        \"fig_size\": 2000,  # equivalent to width and height (note: this is in inches)\n",
    "        \"show_legend\": False,\n",
    "        \"xlabel\": \"\",\n",
    "        \"invert_axes\": True,\n",
    "        \"show_grid\": True,\n",
    "        \"fontsize\": {\n",
    "            \"title\": 16,\n",
    "            \"labels\": 14,\n",
    "            \"xticks\": 12,\n",
    "            \"yticks\": 12,\n",
    "        },  # equivalent to fontscale\n",
    "        \"title\": \"\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remake the jitterboxplot with the matplotlib backend\n",
    "\n",
    "hv.extension(\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a color cycle\n",
    "color_cycler = cycler(color=plt.cm.tab10.colors)\n",
    "\n",
    "# Convert the color cycle to a list of colors\n",
    "color_list = [c[\"color\"] for c in color_cycler]\n",
    "\n",
    "# Now you can use color_list in your plot\n",
    "boxplot = hv.Overlay(\n",
    "    [\n",
    "        hv.BoxWhisker(\n",
    "            pooled[pooled[\"Brain region\"] == region], kdims=\"Nickname\", vdims=\"PC1\"\n",
    "        ).opts(**pooled_opts_matplotlib[\"boxwhisker\"], boxprops=dict(color=\"black\", facecolor = color))\n",
    "        for region, color in zip(brain_regions, color_list)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = hv.BoxWhisker(pooled, kdims=\"Nickname\", vdims=\"PC1\", by=\"Brain region\").opts(\n",
    "    **pooled_opts_matplotlib[\"boxwhisker\"], cmap=\"category10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot = hv.Scatter(\n",
    "    data=pooled,\n",
    "    vdims=[\"PC1\"],\n",
    "    kdims=[\"Nickname\"],\n",
    ").opts(**pooled_opts_matplotlib[\"scatter\"], ylim=(y_min, y_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the control area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_hline = hv.HSpan(hline_values[0], hline_values[1]).opts(alpha=0.2, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitterboxplot = (hv_hline * boxplot * scatterplot).opts(\n",
    "    ylabel=\"PC1\", **pooled_opts_matplotlib[\"plot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitterboxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a matplotlib png\n",
    "hv.save(jitterboxplot, savepath/\"240306_PCA_jitterboxplot_matplotlib.png\", fmt=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
