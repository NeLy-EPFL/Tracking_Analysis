{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from utils_behavior import Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Umap = pd.read_feather(\n",
    "    \"/mnt/upramdya_data/MD/BallPushing_Learning/Datasets/250326_StdContacts_Ctrl_300frames_Data/UMAP/250313_pooled_standardized_contacts_Allfeatures.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create if not exist output directory\n",
    "\n",
    "output_dir = Path(\"/mnt/upramdya_data/MD/BallPushing_Learning/Plots/UMAP/250327_StdContacts_Ctrl_300frames_Data\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of UMAP1 vs UMAP2\n",
    "\n",
    "sns.scatterplot(data=Umap, x=\"UMAP1\", y=\"UMAP2\", size=0.01, alpha = 0.1)\n",
    "\n",
    "# save the plot\n",
    "\n",
    "plt.savefig(f\"{output_dir}/UMAP_Main.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with kde\n",
    "\n",
    "sns.kdeplot(data=Umap, x=\"UMAP1\", y=\"UMAP2\", fill=True)\n",
    "\n",
    "# save the plot\n",
    "\n",
    "plt.savefig(f\"{output_dir}/UMAP_Main_kde.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to keep only events that have a trial number\n",
    "\n",
    "Umap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Umap[\"trial\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep events that are in the first 4 trials in a subset\n",
    "\n",
    "Umap_subset = Umap[Umap[\"trial\"] < 5]\n",
    "\n",
    "Umap_subset = Umap_subset[Umap_subset[\"trial\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all\n",
    "\n",
    "Umap_subset = Umap[Umap[\"trial\"] > 0]\n",
    "\n",
    "Umap_subset = Umap_subset[Umap_subset[\"trial\"] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=Umap_subset, x=\"UMAP1\", y=\"UMAP2\", size=0.01, alpha = 0.1, hue=\"trial\", palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid with two columns, one for each event_type\n",
    "g = sns.FacetGrid(Umap_subset, col=\"trial\", hue=\"trial\", sharex=True, sharey=True, height=6, aspect=1.2, col_wrap=3, palette=\"viridis\")\n",
    "\n",
    "# Map the kdeplot to the FacetGrid\n",
    "g.map(sns.kdeplot, \"UMAP1\", \"UMAP2\", fill=True, alpha=0.5)\n",
    "\n",
    "# Add titles and adjust layout\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.add_legend()\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle(\"Density Plots of UMAP by trial number\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{output_dir}/UMAP_trials_density_full.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute contact number per trial\n",
    "\n",
    "Umap[\"trial\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify clusters based on KMeans\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(Umap_subset[[\"UMAP1\", \"UMAP2\"]])\n",
    "\n",
    "Umap_subset[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=Umap_subset, x=\"UMAP1\", y=\"UMAP2\", alpha = 0.1, hue=\"cluster\", palette=\"tab20\")\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "#plt.savefig(f\"{output_dir}/UMAP_Clusters_full.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster proportions over time by event type\n",
    "cluster_proportions = (\n",
    "    Umap_subset\n",
    "    .groupby(['trial', 'cluster'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Calculate totals for proportions\n",
    "totals = (\n",
    "    cluster_proportions\n",
    "    .groupby(['trial'])['count']\n",
    "    .sum()\n",
    "    .reset_index(name='total')\n",
    ")\n",
    "\n",
    "# Merge and calculate proportions\n",
    "cluster_proportions = cluster_proportions.merge(totals, on=['trial'])\n",
    "cluster_proportions['proportion'] = cluster_proportions['count'] / cluster_proportions['total']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot a line for each cluster\n",
    "for cluster in sorted(Umap_subset[\"cluster\"].unique()):\n",
    "    cluster_data = cluster_proportions[cluster_proportions[\"cluster\"] == cluster]\n",
    "    if not cluster_data.empty:\n",
    "        plt.plot(\n",
    "            cluster_data[\"trial\"],\n",
    "            cluster_data[\"proportion\"],\n",
    "            marker=\"o\",\n",
    "            linewidth=2,\n",
    "            label=f\"Cluster {cluster}\",\n",
    "        )\n",
    "\n",
    "plt.title(\"Cluster Evolution Over trials\", fontsize=14)\n",
    "plt.xlabel(\"trial\", fontsize=12)\n",
    "plt.ylabel(\"Proportion of Events\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{output_dir}/cluster_evolution_line_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only flies that have atleast 2 trials\n",
    "\n",
    "Data_2_trials = Umap_subset.groupby(\"fly\").filter(\n",
    "    lambda x: x[\"trial\"].nunique() >= 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique clusters from your dataset\n",
    "clusters = sorted(Data_2_trials[\"cluster\"].unique())\n",
    "\n",
    "# Count occurrences for each cluster and trial combination\n",
    "counts = Data_2_trials.groupby([\"cluster\", \"trial\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Calculate total events for each trial\n",
    "totals = Data_2_trials.groupby([\"trial\"]).size().reset_index(name=\"total\")\n",
    "\n",
    "# Merge totals with counts to calculate proportions\n",
    "counts = counts.merge(totals, on=['trial'], how='left')\n",
    "counts['proportion'] = counts['count'] / counts['total'] * 100  # Convert to percentage\n",
    "\n",
    "# Create the figure and axes grid - one subplot per cluster\n",
    "fig, axes = plt.subplots(len(clusters), 1, \n",
    "                         figsize=(6, 3 * len(clusters)),\n",
    "                         sharex=True, sharey=True)  # Share both axes\n",
    "\n",
    "# Ensure axes is always an array\n",
    "if len(clusters) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "# Get all unique trials\n",
    "all_trials = sorted(Data_2_trials[\"trial\"].unique())\n",
    "\n",
    "# Plot each cluster\n",
    "for i, cluster in enumerate(clusters):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get data for this cluster\n",
    "    cluster_data = counts[counts['cluster'] == cluster]\n",
    "    \n",
    "    # Sort by trial for proper plotting\n",
    "    cluster_data = cluster_data.sort_values('trial')\n",
    "    \n",
    "    # Plot if there's data\n",
    "    if len(cluster_data) > 0:\n",
    "        # Use line plot with markers to show evolution, using the proportion\n",
    "        ax.plot(cluster_data['trial'], cluster_data['proportion'], \n",
    "                marker='o', markersize=8, \n",
    "                linestyle='-', linewidth=2.5, \n",
    "                color='blue', label=f\"Cluster {cluster}\")\n",
    "        \n",
    "        # Option: Add text labels showing the raw counts for context\n",
    "        for idx, row in cluster_data.iterrows():\n",
    "            ax.annotate(f\"{int(row['count'])}\", \n",
    "                        (row['trial'], row['proportion']),\n",
    "                        textcoords=\"offset points\", \n",
    "                        xytext=(0, 5), \n",
    "                        ha='center',\n",
    "                        fontsize=8)\n",
    "    \n",
    "    # Set labels and title for subplot\n",
    "    ax.set_title(f\"Cluster {cluster}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "    if i == len(clusters) - 1:\n",
    "        ax.set_xlabel(\"Trial\", fontsize=12)\n",
    "        \n",
    "    # Add grid for readability\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Set y-axis limits to 0-30%\n",
    "    ax.set_ylim(0, 35)  \n",
    "    \n",
    "    # Set x-axis to include all trials\n",
    "    ax.set_xticks(all_trials)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle('Proportion of Clusters Across Trials (% of Total Events)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get all unique clusters from your dataset\n",
    "clusters = sorted(Data_2_trials[\"cluster\"].unique())\n",
    "\n",
    "# Count occurrences for each cluster and trial combination\n",
    "counts = Data_2_trials.groupby([\"cluster\", \"trial\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Calculate total events for each trial\n",
    "totals = Data_2_trials.groupby([\"trial\"]).size().reset_index(name=\"total\")\n",
    "\n",
    "# Merge totals with counts to calculate proportions\n",
    "counts = counts.merge(totals, on=[\"trial\"], how=\"left\")\n",
    "counts[\"proportion\"] = counts[\"count\"] / counts[\"total\"] * 100  # Convert to percentage\n",
    "\n",
    "# Define the number of columns for the grid\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(clusters) / n_cols))\n",
    "\n",
    "# Create the figure and axes grid\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows,\n",
    "    n_cols,\n",
    "    figsize=(6, 3 * n_rows),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get all unique trials\n",
    "all_trials = sorted(Data_2_trials[\"trial\"].unique())\n",
    "\n",
    "# Plot each cluster\n",
    "for i, cluster in enumerate(clusters):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Get data for this cluster\n",
    "    cluster_data = counts[counts[\"cluster\"] == cluster]\n",
    "\n",
    "    # Sort by trial for proper plotting\n",
    "    cluster_data = cluster_data.sort_values(\"trial\")\n",
    "\n",
    "    # Plot if there's data\n",
    "    if len(cluster_data) > 0:\n",
    "        # Use line plot with markers to show evolution, using the proportion\n",
    "        ax.plot(\n",
    "            cluster_data[\"trial\"],\n",
    "            cluster_data[\"proportion\"],\n",
    "            marker=\"o\",\n",
    "            markersize=8,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2.5,\n",
    "            color=\"blue\",\n",
    "            label=f\"Cluster {cluster}\",\n",
    "        )\n",
    "\n",
    "        # Option: Add text labels showing the raw counts for context\n",
    "        for idx, row in cluster_data.iterrows():\n",
    "            ax.annotate(\n",
    "                f\"{int(row['count'])}\",\n",
    "                (row[\"trial\"], row[\"proportion\"]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0, 5),\n",
    "                ha=\"center\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    # Set labels and title for subplot\n",
    "    ax.set_title(f\"Cluster {cluster}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=12)\n",
    "\n",
    "    # Add grid for readability\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Set y-axis limits to 0-35%\n",
    "    ax.set_ylim(0, 35)\n",
    "\n",
    "    # Set x-axis to include all trials\n",
    "    ax.set_xticks(all_trials)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(clusters), len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.90)\n",
    "fig.suptitle(\"Proportion of Clusters Across Trials (% of Total Events)\", fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source data\n",
    "\n",
    "interaction_data = pd.read_feather(\n",
    "    \"/mnt/upramdya_data/MD/BallPushing_Learning/Datasets/250326_StdContacts_Ctrl_300frames_Data/standardized_contacts/250326_pooled_standardized_contacts.feather\"\n",
    ")\n",
    "interaction_data.head()\n",
    "interaction_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a unique identifier as combination of fly, event_type and event_id\n",
    "\n",
    "Umap_subset[\"unique_id\"] = Umap_subset[\"fly\"].astype(str) + \"_\" + Umap[\"event_id\"].astype(str)\n",
    "\n",
    "interaction_data[\"unique_id\"] = interaction_data[\"fly\"].astype(str) + \"_\" + interaction_data[\"event_id\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Looping over all clusters\n",
    "# Configuration parameters\n",
    "MAX_CELL_WIDTH = 96   # Maximum width for grid cells\n",
    "MAX_CELL_HEIGHT = 516  # Maximum height for grid cells\n",
    "MAX_OUTPUT_WIDTH = 3840\n",
    "MAX_OUTPUT_HEIGHT = 2160\n",
    "FPS = 5\n",
    "CODEC = \"mp4v\"\n",
    "OUTPUT_DIR = output_dir\n",
    "\n",
    "def resize_with_padding(frame, target_w, target_h):\n",
    "    \"\"\"Resize frame while maintaining aspect ratio with padding\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = min(target_w/w, target_h/h)\n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    \n",
    "    resized = cv2.resize(frame, (new_w, new_h))\n",
    "    pad_w = target_w - new_w\n",
    "    pad_h = target_h - new_h\n",
    "    \n",
    "    # Add equal padding on both sides\n",
    "    top = pad_h // 2\n",
    "    bottom = pad_h - top\n",
    "    left = pad_w // 2\n",
    "    right = pad_w - left\n",
    "    \n",
    "    return cv2.copyMakeBorder(resized, top, bottom, left, right, \n",
    "                            cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "\n",
    "def process_cluster(cluster_id, Umap, interaction_data):\n",
    "    cluster_data = Umap[Umap[\"cluster\"] == cluster_id]\n",
    "    cluster_interactions = interaction_data[interaction_data[\"unique_id\"].isin(cluster_data[\"unique_id\"])]\n",
    "    \n",
    "    # Calculate frame ranges for each unique_id\n",
    "    frame_ranges = (cluster_interactions\n",
    "                    .groupby('unique_id')['frame']\n",
    "                    .agg(frame_start=('min'), frame_end=('max'))\n",
    "                    .reset_index())\n",
    "\n",
    "    # Merge with path information\n",
    "    event_metadata = (cluster_interactions[['unique_id', 'flypath']]\n",
    "                      .drop_duplicates()\n",
    "                      .merge(frame_ranges, on='unique_id'))\n",
    "\n",
    "    # Calculate grid layout based on max output dimensions\n",
    "    cols = MAX_OUTPUT_WIDTH // MAX_CELL_HEIGHT  # Note the swapped dimensions\n",
    "    rows = MAX_OUTPUT_HEIGHT // MAX_CELL_WIDTH  # Note the swapped dimensions\n",
    "    max_events = cols * rows\n",
    "\n",
    "    # Sample events if needed\n",
    "    if len(event_metadata) > max_events:\n",
    "        event_metadata = event_metadata.sample(max_events, random_state=42)\n",
    "\n",
    "    # Initialize frame storage and video metadata\n",
    "    frames_dict = {}\n",
    "    max_duration = 0\n",
    "    valid_events = 0\n",
    "\n",
    "    # Process videos in optimized groups\n",
    "    for flypath, group in event_metadata.groupby('flypath'):\n",
    "        video_files = list(Path(flypath).glob(\"*.mp4\"))\n",
    "        video_file = next((vf for vf in video_files if \"_preprocessed\" not in vf.stem), None)\n",
    "        \n",
    "        if not video_file:\n",
    "            print(f\"Skipping {flypath} - no suitable MP4 found\")\n",
    "            continue\n",
    "\n",
    "        cap = cv2.VideoCapture(str(video_file))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Couldn't open {video_file}\")\n",
    "            continue\n",
    "\n",
    "        # Process all events from this video\n",
    "        for _, event in group.iterrows():\n",
    "            try:\n",
    "                start = int(event['frame_start'])\n",
    "                end = int(event['frame_end'])\n",
    "                if start > end:\n",
    "                    print(f\"Invalid frames for {event['unique_id']}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Read event frames with boundary checks\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "                frames = []\n",
    "                for _ in range(end - start + 1):\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    # Rotate frame 90° clockwise\n",
    "                    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    # Convert color space and resize with padding\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame = resize_with_padding(frame, MAX_CELL_HEIGHT, MAX_CELL_WIDTH)  # Note the swapped dimensions\n",
    "                    frames.append(frame)\n",
    "                \n",
    "                if frames:\n",
    "                    frames_dict[event['unique_id']] = frames\n",
    "                    max_duration = max(max_duration, len(frames))\n",
    "                    valid_events += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {event['unique_id']}: {str(e)}\")\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "    # Early exit if no valid events\n",
    "    if valid_events == 0:\n",
    "        raise ValueError(f\"No processable events found for cluster {cluster_id}\")\n",
    "\n",
    "    # Pad all clips to max duration with black frames\n",
    "    for uid in frames_dict:\n",
    "        frames = frames_dict[uid]\n",
    "        if len(frames) < max_duration:\n",
    "            padding = [np.zeros((MAX_CELL_WIDTH, MAX_CELL_HEIGHT, 3), dtype=np.uint8)] * (max_duration - len(frames))  # Note the swapped dimensions\n",
    "            frames_dict[uid] = frames + padding\n",
    "\n",
    "    # Final output dimensions\n",
    "    output_size = (cols * MAX_CELL_HEIGHT, rows * MAX_CELL_WIDTH)  # Note the swapped dimensions\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*CODEC)\n",
    "    output_path = Path(OUTPUT_DIR) / f\"cluster_{cluster_id}_video.mp4\"\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, FPS, output_size)\n",
    "\n",
    "    # Generate grid frames\n",
    "    for frame_idx in range(max_duration):\n",
    "        grid = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "        \n",
    "        for idx, (uid, frames) in enumerate(frames_dict.items()):\n",
    "            if frame_idx >= len(frames):\n",
    "                continue\n",
    "                \n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            # Calculate position\n",
    "            x = col * MAX_CELL_HEIGHT  # Note the swapped dimensions\n",
    "            y = row * MAX_CELL_WIDTH  # Note the swapped dimensions\n",
    "            \n",
    "            # Place frame in grid cell\n",
    "            grid[y:y+MAX_CELL_WIDTH, x:x+MAX_CELL_HEIGHT] = frames[frame_idx]  # Note the swapped dimensions\n",
    "\n",
    "        out.write(cv2.cvtColor(grid, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Successfully created grid video for cluster {cluster_id} at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster(cluster_id, Umap, interaction_data, best_disp=False):\n",
    "    cluster_data = Umap[Umap[\"cluster\"] == cluster_id]\n",
    "    cluster_interactions = interaction_data[interaction_data[\"unique_id\"].isin(cluster_data[\"unique_id\"])]\n",
    "    \n",
    "    # Calculate frame ranges for each unique_id\n",
    "    frame_ranges = (cluster_interactions\n",
    "                    .groupby('unique_id')['frame']\n",
    "                    .agg(frame_start=('min'), frame_end=('max'))\n",
    "                    .reset_index())\n",
    "\n",
    "    # Merge with path information\n",
    "    event_metadata = (cluster_interactions[['unique_id', 'flypath']]\n",
    "                      .drop_duplicates()\n",
    "                      .merge(frame_ranges, on='unique_id'))\n",
    "\n",
    "    # Add raw_displacement from Umap to event_metadata\n",
    "    event_metadata = event_metadata.merge(\n",
    "        Umap[['unique_id', 'raw_displacement']],\n",
    "        on='unique_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Calculate grid layout based on max output dimensions\n",
    "    cols = MAX_OUTPUT_WIDTH // MAX_CELL_HEIGHT  # Note the swapped dimensions\n",
    "    rows = MAX_OUTPUT_HEIGHT // MAX_CELL_WIDTH  # Note the swapped dimensions\n",
    "    max_events = cols * rows\n",
    "\n",
    "    # Select events based on the best_disp argument\n",
    "    if len(event_metadata) > max_events:\n",
    "        if best_disp:\n",
    "            # Sort by raw_displacement in descending order and pick the top events\n",
    "            event_metadata = event_metadata.sort_values(by='raw_displacement', ascending=False).head(max_events)\n",
    "        else:\n",
    "            # Randomly sample events\n",
    "            event_metadata = event_metadata.sample(max_events, random_state=42)\n",
    "\n",
    "    # Initialize frame storage and video metadata\n",
    "    frames_dict = {}\n",
    "    max_duration = 0\n",
    "    valid_events = 0\n",
    "\n",
    "    # Process videos in optimized groups\n",
    "    for flypath, group in event_metadata.groupby('flypath'):\n",
    "        video_files = list(Path(flypath).glob(\"*.mp4\"))\n",
    "        video_file = next((vf for vf in video_files if \"_preprocessed\" not in vf.stem), None)\n",
    "        \n",
    "        if not video_file:\n",
    "            print(f\"Skipping {flypath} - no suitable MP4 found\")\n",
    "            continue\n",
    "\n",
    "        cap = cv2.VideoCapture(str(video_file))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Couldn't open {video_file}\")\n",
    "            continue\n",
    "\n",
    "        # Process all events from this video\n",
    "        for _, event in group.iterrows():\n",
    "            try:\n",
    "                start = int(event['frame_start'])\n",
    "                end = int(event['frame_end'])\n",
    "                if start > end:\n",
    "                    print(f\"Invalid frames for {event['unique_id']}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Read event frames with boundary checks\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "                frames = []\n",
    "                for _ in range(end - start + 1):\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    # Rotate frame 90° clockwise\n",
    "                    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    # Convert color space and resize with padding\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame = resize_with_padding(frame, MAX_CELL_HEIGHT, MAX_CELL_WIDTH)  # Note the swapped dimensions\n",
    "                    frames.append(frame)\n",
    "                \n",
    "                if frames:\n",
    "                    frames_dict[event['unique_id']] = frames\n",
    "                    max_duration = max(max_duration, len(frames))\n",
    "                    valid_events += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {event['unique_id']}: {str(e)}\")\n",
    "        \n",
    "        cap.release()\n",
    "\n",
    "    # Early exit if no valid events\n",
    "    if valid_events == 0:\n",
    "        raise ValueError(f\"No processable events found for cluster {cluster_id}\")\n",
    "\n",
    "    # Pad all clips to max duration with black frames\n",
    "    for uid in frames_dict:\n",
    "        frames = frames_dict[uid]\n",
    "        if len(frames) < max_duration:\n",
    "            padding = [np.zeros((MAX_CELL_WIDTH, MAX_CELL_HEIGHT, 3), dtype=np.uint8)] * (max_duration - len(frames))  # Note the swapped dimensions\n",
    "            frames_dict[uid] = frames + padding\n",
    "\n",
    "    # Final output dimensions\n",
    "    output_size = (cols * MAX_CELL_HEIGHT, rows * MAX_CELL_WIDTH)  # Note the swapped dimensions\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*CODEC)\n",
    "    if best_disp:\n",
    "        output_path = Path(OUTPUT_DIR) / f\"cluster_{cluster_id}_video_best_disp.mp4\"\n",
    "    else:\n",
    "        output_path = Path(OUTPUT_DIR) / f\"cluster_{cluster_id}_video.mp4\"\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, FPS, output_size)\n",
    "\n",
    "    # Generate grid frames\n",
    "    for frame_idx in range(max_duration):\n",
    "        grid = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "        \n",
    "        for idx, (uid, frames) in enumerate(frames_dict.items()):\n",
    "            if frame_idx >= len(frames):\n",
    "                continue\n",
    "                \n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            # Calculate position\n",
    "            x = col * MAX_CELL_HEIGHT  # Note the swapped dimensions\n",
    "            y = row * MAX_CELL_WIDTH  # Note the swapped dimensions\n",
    "            \n",
    "            # Place frame in grid cell\n",
    "            grid[y:y+MAX_CELL_WIDTH, x:x+MAX_CELL_HEIGHT] = frames[frame_idx]  # Note the swapped dimensions\n",
    "\n",
    "        out.write(cv2.cvtColor(grid, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Successfully created grid video for cluster {cluster_id} at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get unique clusters\n",
    "unique_clusters = Umap_subset[\"cluster\"].unique()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "#Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each cluster\n",
    "for cluster_id in unique_clusters:\n",
    "    try:\n",
    "        process_cluster(cluster_id, Umap_subset, interaction_data, best_disp=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cluster {cluster_id}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the ball efficiency per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rank the clusters by the median efficiency of interactions\n",
    "\n",
    "Subset_positive = Umap_subset[Umap_subset[\"raw_displacement\"] > 0]\n",
    "\n",
    "# Rank the clusters by median efficiency\n",
    "\n",
    "cluster_ranking = Subset_positive.groupby(\"cluster\")[\"raw_displacement\"].median().sort_values(ascending=False)\n",
    "\n",
    "# Get the order of the clusters\n",
    "\n",
    "cluster_order = cluster_ranking.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log version\n",
    "\n",
    "Umap_subset[\"log_displacement\"] = np.log1p(Umap_subset[\"raw_displacement\"])\n",
    "\n",
    "# Make a boxplot of the log_displacement by cluster\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.boxplot(data=Umap_subset, x=\"cluster\", y=\"log_displacement\", color=\"skyblue\")\n",
    "\n",
    "plt.title(\"Efficiency of Interactions by Cluster\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Cluster Number\", fontsize=14)\n",
    "\n",
    "plt.ylabel(\"Log(1 + Raw Displacement)\", fontsize=14)\n",
    "\n",
    "plt.xticks(range(len(cluster_order)), cluster_order, fontsize=12)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute bootstrapped confidence intervals for average efficiency of interactions per cluster\n",
    "\n",
    "clusters_bs_ci = {}\n",
    "\n",
    "for cluster in Umap_subset[\"cluster\"].unique():\n",
    "    cluster_data = Umap_subset[Umap_subset[\"cluster\"] == cluster]\n",
    "    \n",
    "    bs_ci = Processing.draw_bs_ci(cluster_data[\"raw_displacement\"], np.mean)\n",
    "    \n",
    "    clusters_bs_ci[cluster] = bs_ci\n",
    "    \n",
    "    print(f\"Cluster {cluster}: {bs_ci}\")\n",
    "    \n",
    "# Rank the clusters by the average efficiency of interactions\n",
    "\n",
    "cluster_ranking = {cluster: np.mean(ci) for cluster, ci in clusters_bs_ci.items()}\n",
    "\n",
    "cluster_order = [cluster for cluster, _ in sorted(cluster_ranking.items(), key=lambda x: x[1], reverse=True)]\n",
    "    \n",
    "    \n",
    "# Let's plot the average efficiency of interactions per cluster with bootstrapped confidence intervals\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the bootstrapped confidence intervals\n",
    "for cluster in cluster_order:\n",
    "    low, high = clusters_bs_ci[cluster]\n",
    "    mean_value = Umap_subset[Umap_subset[\"cluster\"] == cluster][\"raw_displacement\"].mean()\n",
    "    plt.errorbar(cluster_order.index(cluster), mean_value, yerr=[[mean_value - low], [high - mean_value]], fmt='o', color='black', capsize=5)\n",
    "\n",
    "plt.title(\"Average Efficiency of Interactions by Cluster\", fontsize=16)\n",
    "plt.xlabel(\"Cluster Number\", fontsize=14)\n",
    "plt.ylabel(\"Raw Displacement\", fontsize=14)\n",
    "plt.xticks(range(len(cluster_order)), cluster_order, fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{output_dir}/average_efficiency_interactions_by_cluster_subset.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average efficiency (raw_displacement) for each time bin\n",
    "efficiency_over_time = Umap_subset.groupby('trial')['raw_displacement'].agg(['mean', 'count', 'std']).reset_index()\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "efficiency_over_time['ci'] = 1.96 * efficiency_over_time['std'] / np.sqrt(efficiency_over_time['count'])\n",
    "\n",
    "# Plot average efficiency over time with confidence intervals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(efficiency_over_time['trial'], \n",
    "             efficiency_over_time['mean'], \n",
    "             yerr=efficiency_over_time['ci'], \n",
    "             fmt='o-', \n",
    "             capsize=5, \n",
    "             linewidth=2, \n",
    "             markersize=8)\n",
    "\n",
    "# Change x axis to be from 1 to 4 without decimals\n",
    "\n",
    "plt.xticks(range(1, 5))\n",
    "\n",
    "plt.title('Average Efficiency Over Time', fontsize=16)\n",
    "plt.xlabel('Trial', fontsize=14)\n",
    "plt.ylabel('Raw Displacement (Efficiency)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/average_efficiency_over_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify efficient vs. inefficient clusters (using median as cutoff)\n",
    "median_efficiency = np.median(list(cluster_ranking.values()))\n",
    "\n",
    "threshold = median_efficiency\n",
    "\n",
    "efficient_clusters = [c for c, v in cluster_ranking.items() if v >= threshold]\n",
    "inefficient_clusters = [c for c, v in cluster_ranking.items() if v < threshold]\n",
    "\n",
    "print(f\"Efficient clusters: {efficient_clusters}\")\n",
    "print(f\"Inefficient clusters: {inefficient_clusters}\")\n",
    "\n",
    "# Calculate the proportion of efficient and inefficient clusters over time\n",
    "efficiency_dist = []\n",
    "\n",
    "for time_bin in sorted(Umap_subset['trial'].unique()):\n",
    "    bin_data = Umap_subset[Umap_subset['trial'] == time_bin]\n",
    "    total_count = len(bin_data)\n",
    "    \n",
    "    if total_count > 0:\n",
    "        efficient_count = len(bin_data[bin_data['cluster'].isin(efficient_clusters)])\n",
    "        inefficient_count = len(bin_data[bin_data['cluster'].isin(inefficient_clusters)])\n",
    "        \n",
    "        efficiency_dist.append({\n",
    "            'trial': time_bin,\n",
    "            'efficient_prop': efficient_count / total_count * 100,\n",
    "            'inefficient_prop': inefficient_count / total_count * 100,\n",
    "            'efficient_count': efficient_count,\n",
    "            'inefficient_count': inefficient_count,\n",
    "            'total_count': total_count\n",
    "        })\n",
    "\n",
    "efficiency_dist_df = pd.DataFrame(efficiency_dist)\n",
    "\n",
    "# Plot the proportion of efficient vs. inefficient clusters over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(efficiency_dist_df['trial'], efficiency_dist_df['efficient_prop'], \n",
    "         'o-', color='green', linewidth=2, markersize=8, label='Efficient Clusters')\n",
    "plt.plot(efficiency_dist_df['trial'], efficiency_dist_df['inefficient_prop'], \n",
    "         'o-', color='red', linewidth=2, markersize=8, label='Inefficient Clusters')\n",
    "\n",
    "# Add counts as annotations\n",
    "for i, row in efficiency_dist_df.iterrows():\n",
    "    plt.annotate(f\"{int(row['efficient_count'])}\", \n",
    "               (row['trial'], row['efficient_prop']),\n",
    "               textcoords=\"offset points\", \n",
    "               xytext=(0,10), \n",
    "               ha='center',\n",
    "               color='green',\n",
    "               fontsize=9)\n",
    "    plt.annotate(f\"{int(row['inefficient_count'])}\", \n",
    "               (row['trial'], row['inefficient_prop']),\n",
    "               textcoords=\"offset points\", \n",
    "               xytext=(0,10), \n",
    "               ha='center',\n",
    "               color='red',\n",
    "               fontsize=9)\n",
    "\n",
    "plt.title('Proportion of Efficient vs. Inefficient Clusters Over Time', fontsize=16)\n",
    "plt.xlabel('Time Bin', fontsize=14)\n",
    "plt.ylabel('Percentage (%)', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/efficiency_proportion_over_time.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density based clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Extract t-SNE components\n",
    "x = Umap_subset['UMAP1']\n",
    "y = Umap_subset['UMAP2']\n",
    "\n",
    "# Compute the KDE\n",
    "kde = gaussian_kde([x, y], bw_method=0.05)\n",
    "\n",
    "# Evaluate the KDE on a grid\n",
    "xmin, xmax = x.min(), x.max()\n",
    "ymin, ymax = y.min(), y.max()\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "kde_values = kde(positions).reshape(xx.shape)\n",
    "# Plot the KDE and extract contour levels\n",
    "plt.figure(figsize=(10, 8))\n",
    "contour = plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\")\n",
    "plt.colorbar(label=\"Density\")\n",
    "plt.title(\"KDE Contour Plot\")\n",
    "plt.xlabel(\"UMAP1\")\n",
    "plt.ylabel(\"UMAP2\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the top 5 density levels (darkest shades)\n",
    "top_levels = contour.levels[-15:]  # Adjust number of levels if needed\n",
    "threshold = top_levels[0]  # Use the lowest value of the top 5 levels as threshold\n",
    "# Plot the area of contour levels above the threshold\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, kde_values, levels=top_levels, cmap=\"Blues\")\n",
    "\n",
    "plt.colorbar(label=\"Density\")\n",
    "\n",
    "plt.title(\"KDE Contour Plot (Top 10 Levels)\")\n",
    "\n",
    "plt.xlabel(\"UMAP1\")\n",
    "plt.ylabel(\"UMAP2\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the TSNE data with contour around the top 5 density levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=Umap_subset, x='UMAP1', y='UMAP2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=top_levels, colors='r')\n",
    "\n",
    "# plt.xlabel('t-SNE1')\n",
    "\n",
    "# plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Umap Plot of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Redo but get only the lowest contour level among the selected levels\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(data=Umap_subset, x='UMAP1', y='UMAP2', alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "# plt.xlabel('t-SNE1')\n",
    "\n",
    "# plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Umap of Behavior Map with Density Contour')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a list of the distinct areas of the contour plot\n",
    "\n",
    "contour_areas = []\n",
    "\n",
    "for i in range(len(top_levels) - 1):\n",
    "    \n",
    "    # Get the area of the contour between the current and next levels\n",
    "    area = np.sum(kde_values * (kde_values >= top_levels[i]) * (kde_values < top_levels[i + 1]))\n",
    "    \n",
    "    contour_areas.append(area)\n",
    "    \n",
    "# Display the areas of the contour plot\n",
    "\n",
    "contour_areas\n",
    "\n",
    "# Find the indices of the points that are within the contour area\n",
    "\n",
    "points_in_contour = np.where(kde_values >= threshold)\n",
    "\n",
    "# Extract the x and y coordinates of the points within the contour area\n",
    "\n",
    "x_in_contour = xx[points_in_contour]\n",
    "\n",
    "y_in_contour = yy[points_in_contour]\n",
    "\n",
    "# Plot the points within the contour area\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(x_in_contour, y_in_contour, alpha=0.5)\n",
    "\n",
    "plt.contour(xx, yy, kde_values, levels=[threshold], colors='r')\n",
    "\n",
    "# plt.xlabel('t-SNE1')\n",
    "\n",
    "# plt.ylabel('t-SNE2')\n",
    "\n",
    "plt.title('Points within the Density Contour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "\n",
    "# Create a \"cluster_db\" column initialized to -1 (indicating no cluster)\n",
    "Umap_subset['cluster_db'] = -1\n",
    "\n",
    "# Generate the contour object\n",
    "contour_obj = plt.contour(xx, yy, kde_values, levels=top_levels, colors='r')\n",
    "\n",
    "# Loop through each contour level and its associated paths\n",
    "cluster_id = 0\n",
    "for collection in contour_obj.collections:\n",
    "    for path in collection.get_paths():\n",
    "        # Create a Path object for the current contour\n",
    "        contour_path = Path(path.vertices)\n",
    "        \n",
    "        # Check which points in the dataset fall within this contour\n",
    "        points = np.vstack((Umap_subset['UMAP1'], Umap_subset['UMAP2'])).T\n",
    "        inside = contour_path.contains_points(points)\n",
    "        \n",
    "        # Assign the current cluster ID to points within the contour\n",
    "        Umap_subset.loc[inside, 'cluster_db'] = cluster_id\n",
    "    \n",
    "    # Increment the cluster ID for the next contour\n",
    "    cluster_id += 1\n",
    "\n",
    "# Display the updated dataset\n",
    "print(Umap_subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Create a binary mask for high-density areas\n",
    "high_density_mask = kde_values >= threshold\n",
    "\n",
    "# Label connected components in the binary mask\n",
    "labeled_array, num_features = label(high_density_mask)\n",
    "\n",
    "# Add a \"cluster_db\" column to the dataset, initialized to -1 (indicating no cluster)\n",
    "Umap_subset['cluster_db'] = -1\n",
    "\n",
    "# Assign cluster labels to points based on the labeled high-density areas\n",
    "for i in range(1, num_features + 1):\n",
    "    area_mask = labeled_array == i\n",
    "    x_in_area = xx[area_mask]\n",
    "    y_in_area = yy[area_mask]\n",
    "    \n",
    "    # Find points from the original dataset that fall within this area\n",
    "    points_in_area = Umap_subset[\n",
    "        (Umap_subset['UMAP1'] >= x_in_area.min()) &\n",
    "        (Umap_subset['UMAP1'] <= x_in_area.max()) &\n",
    "        (Umap_subset['UMAP2'] >= y_in_area.min()) &\n",
    "        (Umap_subset['UMAP2'] <= y_in_area.max())\n",
    "    ]\n",
    "    \n",
    "    # Assign the cluster ID to these points\n",
    "    Umap_subset.loc[points_in_area.index, 'cluster_db'] = i\n",
    "\n",
    "# Plot each distinct area with a different color\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.contourf(xx, yy, kde_values, levels=20, cmap=\"Blues\", alpha=0.3)\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, num_features))\n",
    "for i in range(1, num_features + 1):\n",
    "    cluster_points = Umap_subset[Umap_subset['cluster_db'] == i]\n",
    "    plt.scatter(cluster_points['UMAP1'], cluster_points['UMAP2'], \n",
    "                color=colors[i - 1], label=f'Cluster {i}', alpha=0.6)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title('Distinct High-Density Areas in UMAP Plot')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print information about each cluster\n",
    "for i in range(1, num_features + 1):\n",
    "    cluster_points = Umap_subset[Umap_subset['cluster_db'] == i]\n",
    "    print(f\"Cluster {i}: {len(cluster_points)} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster proportions over time by event type\n",
    "cluster_proportions = (\n",
    "    Umap_subset\n",
    "    .groupby(['trial', 'cluster_db'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Calculate totals for proportions\n",
    "totals = (\n",
    "    cluster_proportions\n",
    "    .groupby(['trial'])['count']\n",
    "    .sum()\n",
    "    .reset_index(name='total')\n",
    ")\n",
    "\n",
    "# Merge and calculate proportions\n",
    "cluster_proportions = cluster_proportions.merge(totals, on=['trial'])\n",
    "cluster_proportions['proportion'] = cluster_proportions['count'] / cluster_proportions['total']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot a line for each cluster\n",
    "for cluster in sorted(Umap_subset[\"cluster_db\"].unique()):\n",
    "    cluster_data = cluster_proportions[cluster_proportions[\"cluster_db\"] == cluster]\n",
    "    if not cluster_data.empty:\n",
    "        plt.plot(\n",
    "            cluster_data[\"trial\"],\n",
    "            cluster_data[\"proportion\"],\n",
    "            marker=\"o\",\n",
    "            linewidth=2,\n",
    "            label=f\"Cluster {cluster}\",\n",
    "        )\n",
    "\n",
    "plt.title(\"Cluster Evolution Over Time\", fontsize=14)\n",
    "plt.xlabel(\"Normalized Time Bin (Event Progress)\", fontsize=12)\n",
    "plt.ylabel(\"Proportion of Events\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title=\"Cluster\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{output_dir}/cluster_evolution_line_plots_db.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same with the DBSCAN\n",
    "\n",
    "# Get all unique clusters from your dataset\n",
    "clusters = sorted(Umap_subset['cluster_db'].unique())\n",
    "\n",
    "# Count occurrences for each cluster and trial combination\n",
    "counts = Umap_subset.groupby(['cluster_db', 'trial']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate total events for each trial\n",
    "totals = Umap_subset.groupby(['trial']).size().reset_index(name='total')\n",
    "\n",
    "# Merge totals with counts to calculate proportions\n",
    "counts = counts.merge(totals, on=['trial'], how='left')\n",
    "counts['proportion'] = counts['count'] / counts['total'] * 100  # Convert to percentage\n",
    "\n",
    "# Create the figure and axes grid - one subplot per cluster\n",
    "fig, axes = plt.subplots(len(clusters), 1, \n",
    "                         figsize=(12, 3 * len(clusters)),\n",
    "                         sharex=True, sharey=True)  # Share both axes\n",
    "\n",
    "# Ensure axes is always an array\n",
    "if len(clusters) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "# Get all unique trials\n",
    "all_trials = sorted(Umap_subset['trial'].unique())\n",
    "\n",
    "# Plot each cluster\n",
    "for i, cluster in enumerate(clusters):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get data for this cluster\n",
    "    cluster_data = counts[counts['cluster_db'] == cluster]\n",
    "    \n",
    "    # Sort by trial for proper plotting\n",
    "    cluster_data = cluster_data.sort_values('trial')\n",
    "    \n",
    "    # Plot if there's data\n",
    "    if len(cluster_data) > 0:\n",
    "        # Use line plot with markers to show evolution, using the proportion\n",
    "        ax.plot(cluster_data['trial'], cluster_data['proportion'], \n",
    "                marker='o', markersize=8, \n",
    "                linestyle='-', linewidth=2.5, \n",
    "                color='blue', label=f\"Cluster {cluster}\")\n",
    "        \n",
    "        # Option: Add text labels showing the raw counts for context\n",
    "        for idx, row in cluster_data.iterrows():\n",
    "            ax.annotate(f\"{int(row['count'])}\", \n",
    "                        (row['trial'], row['proportion']),\n",
    "                        textcoords=\"offset points\", \n",
    "                        xytext=(0, 5), \n",
    "                        ha='center',\n",
    "                        fontsize=8)\n",
    "    \n",
    "    # Set labels and title for subplot\n",
    "    ax.set_title(f\"Cluster {cluster}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "    if i == len(clusters) - 1:\n",
    "        ax.set_xlabel(\"Trial\", fontsize=12)\n",
    "        \n",
    "    # Add grid for readability\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Set y-axis limits to 0-30%\n",
    "    ax.set_ylim(0, 30)  \n",
    "    \n",
    "    # Set x-axis to include all trials\n",
    "    ax.set_xticks(all_trials)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "fig.suptitle('Proportion of Clusters Across Trials (% of Total Events)', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
