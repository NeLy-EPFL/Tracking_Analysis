{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_behavior\n",
    "\n",
    "from utils_behavior import Ballpushing_utils\n",
    "from utils_behavior import Utils\n",
    "from utils_behavior import Processing\n",
    "from utils_behavior import HoloviewsTemplates\n",
    "\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import pwlf\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the data\n",
    "\n",
    "Datapath = Utils.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already existing dataset: \n",
    "\n",
    "Subset = feather.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Learning/240809_BallposData.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find folders with \"Learning or learning\" in the name as a list\n",
    "\n",
    "folders = [f for f in Datapath.glob(\"*Learning*\")]\n",
    "\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the experiments\n",
    "\n",
    "Exps = [Ballpushing_utils.Experiment(f) for f in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Ballpushing_utils.Dataset(Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.generate_dataset(success_cutoff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns\n",
    "  \n",
    "Data.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of the data keeping only yball, yball_smooth,\n",
    "\n",
    "Subset = Data.data[[\"Frame\",\"time\", \"yball\", \"yball_smooth\", \"yball_relative\", \"fly\", \"Peak\", \"Date\"]]\n",
    "\n",
    "# Save this subset to a feather file\n",
    "\n",
    "#feather.write_feather(Subset, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Learning/240809_BallposData.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the first fly and store it to use it for the next steps\n",
    "\n",
    "fly = Subset[\"fly\"].iloc[0]\n",
    "\n",
    "TestData = Subset[Subset[\"fly\"] == fly]\n",
    "\n",
    "# Now take one fly and plot the yball_relative\n",
    "\n",
    "#Subset[Subset[\"fly\"] == fly].hvplot(x=\"time\", y=\"yball_relative\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the derivative of the yball_relative\n",
    "\n",
    "Subset[\"yball_relative_derivative\"] = Subset[\"yball_relative\"].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the derivative\n",
    "\n",
    "Subset[Subset[\"fly\"] == fly].hvplot(x=\"time\", y=\"yball_relative_derivative\", kind=\"scatter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Negative peak detection on the derivative\n",
    "\n",
    "Peaks = find_peaks(-TestData[\"yball_relative_derivative\"], height=0.23, distance=500)\n",
    "\n",
    "#Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the \"time\" and \"Frame\" columns from the dataset\n",
    "frame_to_time_mapping = dict(zip(TestData[\"Frame\"], TestData[\"time\"]))\n",
    "\n",
    "# Convert Peaks data to lists\n",
    "x_peaks = Peaks[0].tolist()\n",
    "y_peaks = Peaks[1][\"peak_heights\"].tolist()\n",
    "\n",
    "# Map frame indices to time values\n",
    "x_peaks_time = [frame_to_time_mapping[frame] for frame in x_peaks]\n",
    "\n",
    "# Plot the derivative and the peaks\n",
    "scatter_plot = TestData.hvplot(x=\"time\", y=\"yball_relative_derivative\", kind=\"scatter\")\n",
    "peaks_plot = hv.Scatter(\n",
    "    (x_peaks_time, y_peaks), kdims=[\"time\"], vdims=[\"peak_heights\"], label=\"Peaks\"\n",
    ")\n",
    "\n",
    "# Combine the plots\n",
    "combined_plot = scatter_plot * peaks_plot\n",
    "#combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Group by individual flies\n",
    "grouped = Subset.groupby(\"fly\")\n",
    "\n",
    "\n",
    "# Function to process each group\n",
    "def process_group(group):\n",
    "    # Find peaks in the derivative\n",
    "    peaks, _ = find_peaks(\n",
    "        -group[\"yball_relative_derivative\"], height=0.3, distance=500\n",
    "    )\n",
    "\n",
    "    # Debug: Print the peaks detected for each fly\n",
    "    print(f\"Fly: {group['fly'].iloc[0]}, Peaks: {peaks}\")\n",
    "\n",
    "    # Initialize the \"Trial\" column\n",
    "    group[\"Trial\"] = 0\n",
    "\n",
    "    # Assign trial numbers based on peak positions\n",
    "    trial_number = 1\n",
    "    previous_peak = 0\n",
    "    for peak in peaks:\n",
    "        group.iloc[previous_peak : peak + 1, group.columns.get_loc(\"Trial\")] = (\n",
    "            trial_number\n",
    "        )\n",
    "        trial_number += 1\n",
    "        previous_peak = peak + 1\n",
    "\n",
    "    # Assign the last trial number to the remaining rows\n",
    "    group.iloc[previous_peak:, group.columns.get_loc(\"Trial\")] = trial_number\n",
    "\n",
    "    # Debug: Print the trial numbers assigned for each fly\n",
    "    print(group[[\"fly\", \"Frame\", \"Trial\"]].head(10))\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "# Apply the function to each group and combine the results\n",
    "Trials = grouped.apply(process_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique trials there are grouped by fly\n",
    "Trials.groupby(\"fly\")[\"Trial\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can drop any fly that has less than 2 trials\n",
    "\n",
    "Filtered = Trials.groupby(\"fly\").filter(lambda x: x[\"Trial\"].nunique() > 1)\n",
    "\n",
    "Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered.groupby(\"fly\")[\"Trial\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Trial and time, then compute the mean of yball_relative\n",
    "averaged_data = (\n",
    "    Filtered.groupby([\"Trial\", \"time\"])[\"yball_relative\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Plot the averaged yball_relative values\n",
    "# averaged_data.hvplot(\n",
    "#     x=\"time\", y=\"yball_relative\", by=\"Trial\", kind=\"line\", legend=\"top_left\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among the flies that have more than 1 trial, we need to drop the Frames that belong to a plateau, meaning the frames where the yball_relative is above a certain threshold\n",
    "\n",
    "\n",
    "# Function to clean each trial\n",
    "def clean_trial(group):\n",
    "    # Drop the first 500 frames\n",
    "    group = group.iloc[500:]\n",
    "\n",
    "    # Find the index where yball_relative reaches its max value for the first time\n",
    "    max_index = group[\"yball_relative\"].idxmax()\n",
    "\n",
    "    # Trim the trial data to end at this maximum value\n",
    "    group = group.loc[:max_index]\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "# Apply the function to each group and combine the results\n",
    "cleaned_data = (\n",
    "    Filtered.groupby([\"fly\", \"Trial\"]).apply(clean_trial).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display the cleaned dataset\n",
    "#cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute trial duration\n",
    "def compute_trial_duration(group):\n",
    "    duration = group[\"time\"].max() - group[\"time\"].min()\n",
    "    return pd.Series({\"duration\": duration})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_duration).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jitterbox = HoloviewsTemplates.jitter_boxplot(trial_durations, kdims = \"Trial\", metric=\"duration\", plot_options=HoloviewsTemplates.hv_slides).opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jitterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a PNG and a SVG file\n",
    "hv.save(\n",
    "    Jitterbox,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to save as svg\n",
    "\n",
    "from bokeh.io.export import export_svgs\n",
    "\n",
    "\n",
    "def export_svg(obj, filename):\n",
    "    plot_state = hv.renderer(\"bokeh\").get_plot(obj).state\n",
    "    plot_state.output_backend = \"svg\"\n",
    "    export_svgs(plot_state, filename=filename)\n",
    "\n",
    "\n",
    "export_svg(\n",
    "    Jitterbox,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration.svg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "# Create the jitterboxplot\n",
    "jitterbox = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "# Create a line plot to track each \"fly\" across trial numbers\n",
    "line_plot = (\n",
    "    hv.Curve(trial_durations, kdims=[\"Trial\"], vdims=[\"duration\", \"fly\"])\n",
    "    .groupby(\"fly\")\n",
    "    .opts(color=\"gray\", line_width=1, alpha=0.5)\n",
    "    .overlay()\n",
    ")\n",
    "\n",
    "# Overlay the line plot on top of the jitterboxplot\n",
    "combined_plot = (jitterbox * line_plot).opts(width = 1500,\n",
    "                                             height = 1000,\n",
    "                                             fontscale = 2.5,\n",
    "                                             show_grid = True,\n",
    "                                             )\n",
    "\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as png\n",
    "\n",
    "hv.save(combined_plot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration_Lines.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get how many individual flies we have for each trial number\n",
    "\n",
    "trial_durations.groupby(\"Trial\")[\"fly\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Function to calculate improvement\n",
    "def calculate_improvement(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"improved\"] = df[\"duration\"].diff().lt(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each group of 'fly'\n",
    "trial_durations = trial_durations.groupby(\"fly\").apply(calculate_improvement)\n",
    "\n",
    "# Calculate the proportion of flies that improved in each trial\n",
    "improvement_proportions = trial_durations.groupby(\"Trial\")[\"improved\"].mean()\n",
    "\n",
    "# Print the results\n",
    "print(improvement_proportions)\n",
    "\n",
    "# Plot the results\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "improvement_plot = (\n",
    "    hv.Curve(improvement_proportions)\n",
    "    .opts(\n",
    "        xlabel=\"Trial Number\",\n",
    "        ylabel=\"Proportion of Flies Improved\",\n",
    "        title=\"Proportion of Flies that Improved in Each Trial\",\n",
    "    )\n",
    "    .options(**HoloviewsTemplates.hv_slides[\"plot\"])\n",
    "    .opts(invert_axes=False, show_legend=True)\n",
    ")\n",
    "\n",
    "improvement_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include the trials where at least 5 flies participated\n",
    "improvement_proportions_filtered = improvement_proportions[\n",
    "    trial_durations.groupby(\"Trial\")[\"fly\"].nunique() >= 5\n",
    "]\n",
    "\n",
    "# Plot the filtered results\n",
    "improvement_plot_filtered = (\n",
    "    hv.Curve(improvement_proportions_filtered)\n",
    "    .opts(\n",
    "        xlabel=\"Trial Number\",\n",
    "        ylabel=\"Proportion of Flies Improved\",\n",
    "        title=\"Proportion of Flies that Improved in Each Trial\",\n",
    "    )\n",
    "    .options(**HoloviewsTemplates.hv_slides[\"plot\"])\n",
    "    .opts(invert_axes=False, show_legend=True)\n",
    ")\n",
    "\n",
    "improvement_plot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(\n",
    "    improvement_plot_filtered,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240819_Improvement.png\",\n",
    ")\n",
    "\n",
    "hv.save(\n",
    "    improvement_plot_filtered,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240819_Improvement.html\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate duration ratio and invert it\n",
    "def calculate_duration_ratio(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"duration_ratio\"] = df[\"duration\"].shift(1) / df[\"duration\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each group of 'fly'\n",
    "trial_durations = trial_durations.groupby(\"fly\").apply(calculate_duration_ratio)\n",
    "\n",
    "# Calculate the average inverted duration ratio for each trial\n",
    "average_inverted_ratio = trial_durations.groupby(\"Trial\")[\"duration_ratio\"].mean()\n",
    "\n",
    "# Print the results\n",
    "print(average_inverted_ratio)\n",
    "\n",
    "# Plot the results\n",
    "improvement_magnitude_plot = hv.Curve(average_inverted_ratio).opts(\n",
    "    xlabel=\"Trial Number\",\n",
    "    ylabel=\"Average Inverted Duration Ratio\",\n",
    "    title=\"Average Inverted Duration Ratio in Each Trial\",\n",
    ").options(**HoloviewsTemplates.hv_slides[\"plot\"]).opts(invert_axes=False, show_legend=True)\n",
    "\n",
    "improvement_magnitude_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the 10 first trials\n",
    "filtered_trial_durations = trial_durations[trial_durations[\"Trial\"] <= 10]\n",
    "\n",
    "# Calculate the average duration for each trial\n",
    "average_duration = filtered_trial_durations.groupby(\"Trial\")[\"duration\"].mean()\n",
    "\n",
    "# Compute the bootstrapped confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Initialize an empty DataFrame to store the bootstrap samples\n",
    "bootstrap_samples = pd.DataFrame()\n",
    "\n",
    "# Perform bootstrapping\n",
    "for trial in range(1, 11):\n",
    "    # Get the duration values for the current trial\n",
    "    trial_values = filtered_trial_durations[filtered_trial_durations[\"Trial\"] == trial][\n",
    "        \"duration\"\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty list to store the bootstrap samples\n",
    "    samples = []\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    for _ in range(n_samples):\n",
    "        # Sample with replacement from the trial values\n",
    "        sample = np.random.choice(trial_values, len(trial_values), replace=True)\n",
    "\n",
    "        # Compute the mean of the sample and store it\n",
    "        samples.append(sample.mean())\n",
    "\n",
    "    # Store the bootstrap samples in the DataFrame\n",
    "    bootstrap_samples[trial] = samples\n",
    "\n",
    "# Compute the 95% confidence intervals\n",
    "confidence_intervals = bootstrap_samples.quantile([0.025, 0.975], axis=0).T\n",
    "\n",
    "# Plot the average duration and confidence intervals\n",
    "average_duration_plot = (\n",
    "    hv.Curve(average_duration)\n",
    "    .opts(\n",
    "        xlabel=\"Trial Number\",\n",
    "        ylabel=\"Average Duration (s)\",\n",
    "        title=\"Average Duration in Each Trial\",\n",
    "        xticks=list(\n",
    "            range(1, len(trial_durations[\"Trial\"].unique()) + 1)\n",
    "        ),  # Explicitly set x-ticks to include all trial numbers,\n",
    "    )\n",
    "    .options(**HoloviewsTemplates.hv_slides[\"plot\"])\n",
    "    .opts(invert_axes=False, show_legend=False)\n",
    ")\n",
    "\n",
    "confidence_interval_plot = hv.Area(\n",
    "    (\n",
    "        confidence_intervals.index,\n",
    "        confidence_intervals[0.025],\n",
    "        confidence_intervals[0.975],\n",
    "    ),\n",
    "    vdims=[\"lower\", \"upper\"],\n",
    "    label=\"95% Confidence Interval\",\n",
    ").opts(color=\"blue\", alpha=0.2, xticks=list(range(1, len(trial_durations[\"Trial\"].unique()) + 1))).opts(show_legend=False)\n",
    "\n",
    "CombinedPlot = (average_duration_plot * confidence_interval_plot).opts(xlabel=\"Trial Number\", ylabel=\"Average Duration (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(CombinedPlot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240819_AverageDuration.png\")\n",
    "hv.save(CombinedPlot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240819_AverageDuration.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the whole dataset\n",
    "\n",
    "\n",
    "# Calculate the average duration for each trial\n",
    "average_duration = trial_durations.groupby(\"Trial\")[\"duration\"].mean()\n",
    "\n",
    "# Compute the bootstrapped confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Initialize an empty DataFrame to store the bootstrap samples\n",
    "bootstrap_samples = pd.DataFrame()\n",
    "\n",
    "# Perform bootstrapping\n",
    "for trial in range(1, len(trial_durations[\"Trial\"].unique())):\n",
    "    # Get the duration values for the current trial\n",
    "    trial_values = trial_durations[trial_durations[\"Trial\"] == trial][\n",
    "        \"duration\"\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty list to store the bootstrap samples\n",
    "    samples = []\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    for _ in range(n_samples):\n",
    "        # Sample with replacement from the trial values\n",
    "        sample = np.random.choice(trial_values, len(trial_values), replace=True)\n",
    "\n",
    "        # Compute the mean of the sample and store it\n",
    "        samples.append(sample.mean())\n",
    "\n",
    "    # Store the bootstrap samples in the DataFrame\n",
    "    bootstrap_samples[trial] = samples\n",
    "\n",
    "# Compute the 95% confidence intervals\n",
    "confidence_intervals = bootstrap_samples.quantile([0.025, 0.975], axis=0).T\n",
    "\n",
    "# Plot the average duration and confidence intervals\n",
    "average_duration_plot = (\n",
    "    hv.Curve(average_duration)\n",
    "    .opts(\n",
    "        xlabel=\"Trial Number\",\n",
    "        ylabel=\"Average Duration\",\n",
    "        title=\"Average Duration in Each Trial\",\n",
    "    )\n",
    "    .options(**HoloviewsTemplates.hv_slides[\"plot\"])\n",
    "    .opts(invert_axes=False, show_legend=False)\n",
    ")\n",
    "\n",
    "confidence_interval_plot = hv.Area(\n",
    "    (\n",
    "        confidence_intervals.index,\n",
    "        confidence_intervals[0.025],\n",
    "        confidence_intervals[0.975],\n",
    "    ),\n",
    "    vdims=[\"lower\", \"upper\"],\n",
    "    label=\"95% Confidence Interval\",\n",
    ").opts(color=\"blue\", alpha=0.3)\n",
    "\n",
    "average_duration_plot * confidence_interval_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Function to calculate improvement and worsening\n",
    "def calculate_improvement_worsening(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"improved\"] = df[\"duration\"].diff().lt(0)\n",
    "    df[\"worsened\"] = df[\"duration\"].diff().gt(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each group of 'fly'\n",
    "trial_durations = trial_durations.groupby(\"fly\").apply(calculate_improvement_worsening)\n",
    "\n",
    "# Calculate the proportion of flies that improved and worsened in each trial\n",
    "improvement_proportions = trial_durations.groupby(\"Trial\")[\"improved\"].mean()\n",
    "worsening_proportions = trial_durations.groupby(\"Trial\")[\"worsened\"].mean()\n",
    "\n",
    "# Calculate the difference between improvement and worsening proportions\n",
    "difference_proportions = improvement_proportions - worsening_proportions\n",
    "\n",
    "# Print the results\n",
    "print(difference_proportions)\n",
    "\n",
    "# Plot the results\n",
    "\n",
    "difference_plot = hv.Curve(difference_proportions).opts(\n",
    "    xlabel=\"Trial Number\",\n",
    "    ylabel=\"Proportion Difference (Improved - Worsened)\",\n",
    "    title=\"Difference in Proportion of Flies Improved vs Worsened in Each Trial\",\n",
    ").options(**HoloviewsTemplates.hv_slides[\"plot\"]).opts(invert_axes=False, show_legend=True)\n",
    "\n",
    "difference_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Function to calculate improvement, worsening, and change in duration\n",
    "def calculate_changes(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"improved\"] = df[\"duration\"].diff().lt(0)\n",
    "    df[\"worsened\"] = df[\"duration\"].diff().gt(0)\n",
    "    df[\"change\"] = df[\"duration\"].diff()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each group of 'fly'\n",
    "trial_durations = trial_durations.groupby(\"fly\").apply(calculate_changes)\n",
    "\n",
    "# Calculate the proportion of flies that improved and worsened in each trial\n",
    "improvement_proportions = trial_durations.groupby(\"Trial\")[\"improved\"].mean()\n",
    "worsening_proportions = trial_durations.groupby(\"Trial\")[\"worsened\"].mean()\n",
    "\n",
    "# Calculate the difference between improvement and worsening proportions\n",
    "difference_proportions = improvement_proportions - worsening_proportions\n",
    "\n",
    "# Calculate the average change in duration for each trial\n",
    "average_change = trial_durations.groupby(\"Trial\")[\"change\"].mean()\n",
    "\n",
    "# Combine the proportion difference with the average change\n",
    "combined_metric = pd.DataFrame(\n",
    "    {\"Proportion Difference\": difference_proportions, \"Average Change\": average_change}\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(combined_metric)\n",
    "\n",
    "# Plot the results\n",
    "proportion_plot = hv.Curve(\n",
    "    combined_metric[\"Proportion Difference\"], label=\"Proportion Difference\"\n",
    ").opts(\n",
    "    xlabel=\"Trial Number\",\n",
    "    ylabel=\"Proportion Difference (Improved - Worsened)\",\n",
    "    width=800,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "change_plot = hv.Curve(combined_metric[\"Average Change\"], label=\"Average Change\").opts(\n",
    "    xlabel=\"Trial Number\",\n",
    "    ylabel=\"Average Change in Duration\",\n",
    "    width=800,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "combined_plot = proportion_plot * change_plot.opts(ylabel=\"Combined Metric\")\n",
    "\n",
    "# Save the plot as png\n",
    "# hv.save(\n",
    "#     combined_plot,\n",
    "#     \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_Combined_Metric.png\",\n",
    "# )\n",
    "\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as png\n",
    "\n",
    "hv.save(improvement_plot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_Improvement.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flies for which \"Peak\" is NaN, give them the value \"morning\"\n",
    "Filtered[\"Peak\"] = Filtered[\"Peak\"].fillna(\"morning\")\n",
    "cleaned_data[\"Peak\"] = cleaned_data[\"Peak\"].fillna(\"morning\")\n",
    "\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "cleaned_data[\"Trial\"] = pd.Categorical(cleaned_data[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations_peak = (\n",
    "    cleaned_data.groupby([\"Peak\",\"fly\", \"Trial\"]).apply(compute_trial_duration).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "Jitterbox_peak = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations_peak,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    "    groupby=\"Peak\",\n",
    "    render=\"grouped\"\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "Jitterbox_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as html\n",
    "\n",
    "hv.save(Jitterbox_peak, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration_Peak.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the improvement but grouped by Peak\n",
    "\n",
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations_peak[\"Trial\"] = pd.Categorical(\n",
    "    trial_durations_peak[\"Trial\"], ordered=True\n",
    ")\n",
    "\n",
    "\n",
    "# Function to calculate improvement\n",
    "def calculate_improvement(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"improved\"] = df[\"duration\"].diff().lt(0)\n",
    "    return df\n",
    "\n",
    "# Apply the function to each group of 'fly' and 'Peak'\n",
    "trial_durations_peak = trial_durations_peak.groupby([\"fly\", \"Peak\"]).apply(\n",
    "    calculate_improvement\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the proportion of flies that improved in each trial for each Peak\n",
    "improvement_proportions = (\n",
    "    trial_durations_peak.groupby([\"Peak\", \"Trial\"])[\"improved\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(improvement_proportions)\n",
    "\n",
    "# Plot the results\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "# Create a separate plot for each Peak\n",
    "plots = []\n",
    "for peak in improvement_proportions[\"Peak\"].unique():\n",
    "    peak_data = improvement_proportions[improvement_proportions[\"Peak\"] == peak]\n",
    "    plot = hv.Curve(peak_data, kdims=\"Trial\", vdims=\"improved\").opts(\n",
    "        xlabel=\"Trial Number\",\n",
    "        ylabel=\"Proportion of Flies Improved\",\n",
    "        title=f\"Proportion of Flies that Improved in Each Trial for Peak {peak}\",\n",
    "        width=800,\n",
    "        height=400,\n",
    "    )\n",
    "    plots.append(plot)\n",
    "\n",
    "# Combine all plots into a single layout\n",
    "improvement_plot = hv.Layout(plots).cols(1)\n",
    "\n",
    "improvement_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Trial back to integers\n",
    "cleaned_data[\"Trial\"] = cleaned_data[\"Trial\"].astype(int)\n",
    "\n",
    "# Function to compute the end time of each trial\n",
    "def compute_trial_end_time(group):\n",
    "    end_time = group[\"time\"].max()\n",
    "    return pd.Series({\"end_time\": end_time})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the end times\n",
    "trial_end_times = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_end_time).reset_index()\n",
    ")\n",
    "\n",
    "# Sort by end_time\n",
    "trial_end_times = trial_end_times.sort_values(by=\"end_time\")\n",
    "\n",
    "# Compute the cumulative count of solved trials\n",
    "trial_end_times[\"cumulative_solved_trials\"] = (\n",
    "    trial_end_times[\"end_time\"].rank(method=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "# Plot the cumulative count of solved trials over time\n",
    "cumulcurve = trial_end_times.hvplot.step(\n",
    "    x=\"end_time\",\n",
    "    y=\"cumulative_solved_trials\",\n",
    "    title=\"Cumulative Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Cumulative Solved Trials\",\n",
    ").opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as a PNG\n",
    "\n",
    "hv.save(cumulcurve, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_CumulativeSolvedTrials.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts  # Import opts from holoviews\n",
    "\n",
    "\n",
    "# Define logistic function\n",
    "def logistic(x, L, k, x0):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "# Filter data to include only relevant subset\n",
    "GroupData_morning = trial_end_times\n",
    "\n",
    "# Calculate the number of unique 'flies' in the dataset\n",
    "num_replicates = GroupData_morning[\"fly\"].nunique()\n",
    "\n",
    "# Initial guesses for L, k, x0\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    1,\n",
    "    np.median(GroupData_morning[\"end_time\"]),\n",
    "]\n",
    "\n",
    "# Fit logistic function to data\n",
    "params, _ = curve_fit(\n",
    "    logistic,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=10000,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L, k, x0\n",
    "L, k, x0 = params\n",
    "\n",
    "# Create a new DataFrame for the logistic fit curve\n",
    "logistic_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the logistic fit curve\n",
    "logistic_fit[\"cumulative_solved_trials\"] = logistic(logistic_fit[\"end_time\"], L, k, x0)\n",
    "\n",
    "# Calculate R-squared for logistic fit curve\n",
    "y_pred_logistic = logistic(GroupData_morning[\"end_time\"], L, k, x0)\n",
    "r_squared_logistic = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_logistic\n",
    ")\n",
    "\n",
    "# Calculate linear fit for the first half of the data\n",
    "first_half = GroupData_morning.iloc[: len(GroupData_morning) // 2]\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    first_half[\"end_time\"], first_half[\"cumulative_solved_trials\"]\n",
    ")\n",
    "\n",
    "# Create a new DataFrame for the linear fit line\n",
    "linear_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the linear fit line\n",
    "linear_fit[\"cumulative_solved_trials\"] = slope * linear_fit[\"end_time\"] + intercept\n",
    "\n",
    "# Calculate R-squared for linear fit curve\n",
    "y_pred_linear = slope * GroupData_morning[\"end_time\"] + intercept\n",
    "r_squared_linear = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_linear\n",
    ")\n",
    "\n",
    "# Calculate center x value and min and maximum xy value\n",
    "center_x = (\n",
    "    GroupData_morning[\"end_time\"].max() - GroupData_morning[\"end_time\"].min()\n",
    ") / 2\n",
    "max_y = max(\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    max(logistic_fit[\"cumulative_solved_trials\"]),\n",
    ")\n",
    "\n",
    "max_x = GroupData_morning[\"end_time\"].max()\n",
    "min_y = GroupData_morning[\"cumulative_solved_trials\"].min()\n",
    "\n",
    "# Create your plot using GroupData_morning and add the fits and annotations\n",
    "cumulcurve_pool = (\n",
    "    hv.Curve(\n",
    "        data=GroupData_morning,\n",
    "        kdims=[\"end_time\"],\n",
    "        vdims=[\"cumulative_solved_trials\"],\n",
    "    )\n",
    "    .opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )\n",
    "    * hv.Curve(\n",
    "        data=logistic_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"green\")\n",
    "    * hv.Curve(\n",
    "        data=linear_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"red\")\n",
    "    # Uncomment the following lines to add text annotations\n",
    "    * hv.Text(center_x, max_y - 7, f\"Logistic fit R-squared: {r_squared_logistic:.2f}\").opts(text_color=\"green\")\n",
    "    * hv.Text(center_x, max_y, f\"Linear fit R-squared: {r_squared_linear:.2f}\").opts(text_color=\"red\")\n",
    "    * hv.Text(max_x - 100, min_y * num_replicates, f\"N = {num_replicates}\")\n",
    ").opts(\n",
    "    opts.Area(\n",
    "        show_legend=False,\n",
    "        show_frame=False,\n",
    "        fill_color=\"blue\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "cumulcurve_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "# Define double sigmoid function\n",
    "def double_sigmoid(x, L1, k1, x01, L2, k2, x02):\n",
    "    return (L1 / (1 + np.exp(-k1 * (x - x01)))) + (L2 / (1 + np.exp(-k2 * (x - x02))))\n",
    "\n",
    "\n",
    "# Improved initial guesses for L1, k1, x01, L2, k2, x02\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) / 2,\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) * 1.5,\n",
    "]\n",
    "\n",
    "# Increase maxfev\n",
    "maxfev_value = 10000\n",
    "\n",
    "# Fit double sigmoid function to data\n",
    "params, _ = curve_fit(\n",
    "    double_sigmoid,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=maxfev_value,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L1, k1, x01, L2, k2, x02\n",
    "L1, k1, x01, L2, k2, x02 = params\n",
    "\n",
    "# Calculate fitted values\n",
    "fitted_values = double_sigmoid(GroupData_morning[\"end_time\"], L1, k1, x01, L2, k2, x02)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = GroupData_morning[\"cumulative_solved_trials\"] - fitted_values\n",
    "\n",
    "# Calculate SS_res and SS_tot\n",
    "SS_res = np.sum(residuals**2)\n",
    "SS_tot = np.sum(\n",
    "    (\n",
    "        GroupData_morning[\"cumulative_solved_trials\"]\n",
    "        - np.mean(GroupData_morning[\"cumulative_solved_trials\"])\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = 1 - (SS_res / SS_tot)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Create a new DataFrame for the double sigmoid fit curve\n",
    "double_sigmoid_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the double sigmoid fit curve\n",
    "double_sigmoid_fit[\"cumulative_solved_trials\"] = double_sigmoid(\n",
    "    double_sigmoid_fit[\"end_time\"], L1, k1, x01, L2, k2, x02\n",
    ")\n",
    "\n",
    "# Plot the original data and the double sigmoid fit curve\n",
    "cumulcurve_pool = hv.Curve(\n",
    "    data=GroupData_morning,\n",
    "    kdims=[\"end_time\"],\n",
    "    vdims=[\"cumulative_solved_trials\"],\n",
    ").opts(\n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    alpha=1,\n",
    "    line_width=2,\n",
    "    xlabel=\"Time(s)\",\n",
    "    ylabel=\"Cumulative Solved Trials\",\n",
    "    show_grid=True,\n",
    "    fontscale=3,\n",
    "    title=\"Cumulative Solved Trials Over Time\",\n",
    ") * hv.Curve(\n",
    "    data=double_sigmoid_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    ").opts(\n",
    "    color=\"green\"\n",
    ")\n",
    "\n",
    "#cumulcurve_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double sigmoid + Linear fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to include only relevant subset\n",
    "GroupData_morning = trial_end_times\n",
    "\n",
    "# Define double sigmoid function\n",
    "def double_sigmoid(x, L1, k1, x01, L2, k2, x02):\n",
    "    return (L1 / (1 + np.exp(-k1 * (x - x01)))) + (L2 / (1 + np.exp(-k2 * (x - x02))))\n",
    "\n",
    "\n",
    "# Improved initial guesses for L1, k1, x01, L2, k2, x02\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) / 2,\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) * 1.5,\n",
    "]\n",
    "\n",
    "# Increase maxfev\n",
    "maxfev_value = 10000\n",
    "\n",
    "# Fit double sigmoid function to data\n",
    "params, _ = curve_fit(\n",
    "    double_sigmoid,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=maxfev_value,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L1, k1, x01, L2, k2, x02\n",
    "L1, k1, x01, L2, k2, x02 = params\n",
    "\n",
    "# Calculate fitted values\n",
    "fitted_values = double_sigmoid(GroupData_morning[\"end_time\"], L1, k1, x01, L2, k2, x02)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = GroupData_morning[\"cumulative_solved_trials\"] - fitted_values\n",
    "\n",
    "# Calculate SS_res and SS_tot\n",
    "SS_res = np.sum(residuals**2)\n",
    "SS_tot = np.sum(\n",
    "    (\n",
    "        GroupData_morning[\"cumulative_solved_trials\"]\n",
    "        - np.mean(GroupData_morning[\"cumulative_solved_trials\"])\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = 1 - (SS_res / SS_tot)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Create a new DataFrame for the double sigmoid fit curve\n",
    "double_sigmoid_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the double sigmoid fit curve\n",
    "double_sigmoid_fit[\"cumulative_solved_trials\"] = double_sigmoid(\n",
    "    double_sigmoid_fit[\"end_time\"], L1, k1, x01, L2, k2, x02\n",
    ")\n",
    "\n",
    "# Fit a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(\n",
    "    GroupData_morning[[\"end_time\"]], GroupData_morning[\"cumulative_solved_trials\"]\n",
    ")\n",
    "\n",
    "# Calculate fitted values for the linear model\n",
    "linear_fitted_values = linear_model.predict(GroupData_morning[[\"end_time\"]])\n",
    "\n",
    "# Calculate R-squared for the linear model\n",
    "linear_r2 = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], linear_fitted_values\n",
    ")\n",
    "print(f\"Linear R-squared: {linear_r2}\")\n",
    "\n",
    "# Create a new DataFrame for the linear fit curve\n",
    "linear_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": GroupData_morning[\"end_time\"],\n",
    "        \"cumulative_solved_trials\": linear_fitted_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot the original data, the double sigmoid fit curve, and the linear fit curve\n",
    "cumulcurve_pool = (\n",
    "    hv.Curve(\n",
    "        data=GroupData_morning,\n",
    "        kdims=[\"end_time\"],\n",
    "        vdims=[\"cumulative_solved_trials\"],\n",
    "    ).opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )\n",
    "    * hv.Curve(\n",
    "        data=double_sigmoid_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    )\n",
    "    .opts(\n",
    "        color=\"green\",\n",
    "    )\n",
    "    .relabel(f\"Double Sigmoid Fit (R²={r_squared:.2f})\")\n",
    "    * hv.Curve(data=linear_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"])\n",
    "    .opts(\n",
    "        color=\"red\",\n",
    "        line_dash=\"dashed\",\n",
    "    )\n",
    "    .relabel(f\"Linear Fit (R²={linear_r2:.2f})\")\n",
    ")\n",
    "\n",
    "cumulcurve_pool = cumulcurve_pool.options(**HoloviewsTemplates.hv_slides[\"plot\"]).opts(\n",
    "    invert_axes=False, show_legend=True)\n",
    "\n",
    "hv.save(\n",
    "    cumulcurve_pool,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_CumulativeSolvedTrials_sigmoid_linear.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as PNG\n",
    "\n",
    "hv.save(cumulcurve_pool, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_CumulativeSolvedTrials.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts  # Import opts from holoviews\n",
    "\n",
    "\n",
    "# Define logistic (sigmoid) function\n",
    "def sigmoid(x, L, k, x0):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "# Filter data to include only relevant subset\n",
    "GroupData_morning = trial_end_times\n",
    "\n",
    "# Calculate the number of unique 'flies' in the dataset\n",
    "num_replicates = GroupData_morning[\"fly\"].nunique()\n",
    "\n",
    "# Initial guesses for L, k, x0\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    1,\n",
    "    np.median(GroupData_morning[\"end_time\"]),\n",
    "]\n",
    "\n",
    "# Fit sigmoid function to data\n",
    "params, _ = curve_fit(\n",
    "    sigmoid,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=5000,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L, k, x0\n",
    "L, k, x0 = params\n",
    "\n",
    "# Create a new DataFrame for the sigmoid fit curve\n",
    "sigmoid_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the sigmoid fit curve\n",
    "sigmoid_fit[\"cumulative_solved_trials\"] = sigmoid(sigmoid_fit[\"end_time\"], L, k, x0)\n",
    "\n",
    "# Calculate R-squared for sigmoid fit curve\n",
    "y_pred_sigmoid = sigmoid(GroupData_morning[\"end_time\"], L, k, x0)\n",
    "r_squared_sigmoid = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_sigmoid\n",
    ")\n",
    "\n",
    "# Calculate linear fit for the first half of the data\n",
    "first_half = GroupData_morning.iloc[: len(GroupData_morning) // 2]\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    first_half[\"end_time\"], first_half[\"cumulative_solved_trials\"]\n",
    ")\n",
    "\n",
    "# Create a new DataFrame for the linear fit line\n",
    "linear_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the linear fit line\n",
    "linear_fit[\"cumulative_solved_trials\"] = slope * linear_fit[\"end_time\"] + intercept\n",
    "\n",
    "# Calculate R-squared for linear fit curve\n",
    "y_pred_linear = slope * GroupData_morning[\"end_time\"] + intercept\n",
    "r_squared_linear = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_linear\n",
    ")\n",
    "\n",
    "# Calculate center x value and min and maximum xy value\n",
    "center_x = (\n",
    "    GroupData_morning[\"end_time\"].max() - GroupData_morning[\"end_time\"].min()\n",
    ") / 2\n",
    "max_y = max(\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    max(sigmoid_fit[\"cumulative_solved_trials\"]),\n",
    ")\n",
    "\n",
    "max_x = GroupData_morning[\"end_time\"].max()\n",
    "min_y = GroupData_morning[\"cumulative_solved_trials\"].min()\n",
    "\n",
    "# Create your plot using GroupData_morning and add the fits and annotations\n",
    "cumulcurve_pool = (\n",
    "    hv.Curve(\n",
    "        data=GroupData_morning,\n",
    "        kdims=[\"end_time\"],\n",
    "        vdims=[\"cumulative_solved_trials\"],\n",
    "    )\n",
    "    .opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )\n",
    "    * hv.Curve(\n",
    "        data=sigmoid_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"blue\")\n",
    "    * hv.Curve(\n",
    "        data=linear_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"red\")\n",
    "    # Uncomment the following lines to add text annotations\n",
    "    * hv.Text(center_x, max_y - 10, f\"Sigmoid fit R-squared: {r_squared_sigmoid:.2f}\").opts(text_color=\"blue\")\n",
    "    * hv.Text(center_x, max_y, f\"Linear fit R-squared: {r_squared_linear:.2f}\").opts(text_color=\"red\")\n",
    "    * hv.Text(max_x - 100, min_y * num_replicates, f\"N = {num_replicates}\")\n",
    ").opts(\n",
    "    opts.Area(\n",
    "        show_legend=False,\n",
    "        show_frame=False,\n",
    "        fill_color=\"blue\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "cumulcurve_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered[\"solved_trials\"] = Filtered[\"Trial\"] - 1\n",
    "\n",
    "# On clean data, get the average \"solved_trial\" grouped by time\n",
    "\n",
    "average_solved = Filtered.groupby(\"time\")[\"solved_trials\"].mean()\n",
    "\n",
    "# Plot the average \"solved_trials\" over time\n",
    "average_solved.hvplot(\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    height=400,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "# Convert Trial back to integers\n",
    "cleaned_data[\"Trial\"] = cleaned_data[\"Trial\"].astype(int)\n",
    "\n",
    "\n",
    "# Function to compute the end time of each trial\n",
    "def compute_trial_end_time(group):\n",
    "    end_time = group[\"time\"].max()\n",
    "    return pd.Series({\"end_time\": end_time})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the end times\n",
    "trial_end_times = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_end_time).reset_index()\n",
    ")\n",
    "\n",
    "# Sort by end_time\n",
    "trial_end_times = trial_end_times.sort_values(by=\"end_time\")\n",
    "\n",
    "# Compute the cumulative count of solved trials\n",
    "trial_end_times[\"cumulative_solved_trials\"] = (\n",
    "    trial_end_times[\"end_time\"].rank(method=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "# Compute the average number of trials solved over time\n",
    "average_solved_trials = (\n",
    "    trial_end_times.groupby(\"end_time\")[\"cumulative_solved_trials\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Plot the average number of trials solved over time\n",
    "average_plot = average_solved_trials.hvplot.line(\n",
    "    x=\"end_time\",\n",
    "    y=\"cumulative_solved_trials\",\n",
    "    title=\"Average Number of Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Number of Solved Trials\",\n",
    ").opts(\n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    alpha=1,\n",
    "    line_width=2,\n",
    "    xlabel=\"Time(s)\",\n",
    "    ylabel=\"Average Number of Solved Trials\",\n",
    "    show_grid=True,\n",
    "    fontscale=3,\n",
    "    title=\"Average Number of Solved Trials Over Time\",\n",
    ")\n",
    "\n",
    "average_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "\n",
    "# Convert Trial back to integers\n",
    "cleaned_data[\"Trial\"] = cleaned_data[\"Trial\"].astype(int)\n",
    "\n",
    "\n",
    "# Function to compute the end time of each trial\n",
    "def compute_trial_end_time(group):\n",
    "    end_time = group[\"time\"].max()\n",
    "    return pd.Series({\"end_time\": end_time})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the end times\n",
    "trial_end_times = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_end_time).reset_index()\n",
    ")\n",
    "\n",
    "# Sort by end_time\n",
    "trial_end_times = trial_end_times.sort_values(by=\"end_time\")\n",
    "\n",
    "# Compute the cumulative count of solved trials\n",
    "trial_end_times[\"cumulative_solved_trials\"] = (\n",
    "    trial_end_times[\"end_time\"].rank(method=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "# Compute the average number of trials solved over time\n",
    "average_solved_trials = (\n",
    "    trial_end_times.groupby(\"end_time\")[\"cumulative_solved_trials\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Compute the standard deviation of the cumulative solved trials at each time point\n",
    "std_solved_trials = (\n",
    "    trial_end_times.groupby(\"end_time\")[\"cumulative_solved_trials\"].std().reset_index()\n",
    ")\n",
    "\n",
    "# Merge the mean and standard deviation data\n",
    "average_solved_trials = average_solved_trials.merge(\n",
    "    std_solved_trials, on=\"end_time\", suffixes=(\"_mean\", \"_std\")\n",
    ")\n",
    "\n",
    "# Compute the 95% confidence intervals\n",
    "z_score = 1.96  # for 95% confidence interval\n",
    "average_solved_trials[\"upper_bound\"] = average_solved_trials[\n",
    "    \"cumulative_solved_trials_mean\"\n",
    "] + z_score * (average_solved_trials[\"cumulative_solved_trials_std\"] / np.sqrt(80))\n",
    "average_solved_trials[\"lower_bound\"] = average_solved_trials[\n",
    "    \"cumulative_solved_trials_mean\"\n",
    "] - z_score * (average_solved_trials[\"cumulative_solved_trials_std\"] / np.sqrt(80))\n",
    "\n",
    "# Plot the average number of trials solved over time with confidence intervals\n",
    "average_plot = average_solved_trials.hvplot.line(\n",
    "    x=\"end_time\",\n",
    "    y=\"cumulative_solved_trials_mean\",\n",
    "    title=\"Average Number of Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Number of Solved Trials\",\n",
    "    color=\"blue\",\n",
    "    label=\"Mean\",\n",
    ").opts(\n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    alpha=1,\n",
    "    line_width=2,\n",
    "    xlabel=\"Time(s)\",\n",
    "    ylabel=\"Average Number of Solved Trials\",\n",
    "    show_grid=True,\n",
    "    fontscale=3,\n",
    "    title=\"Average Number of Solved Trials Over Time\",\n",
    ")\n",
    "\n",
    "confidence_plot = average_solved_trials.hvplot.area(\n",
    "    x=\"end_time\",\n",
    "    y=\"upper_bound\",\n",
    "    y2=\"lower_bound\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.3,\n",
    "    label=\"95% CI\",\n",
    ")\n",
    "\n",
    "average_plot * confidence_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average trials solved per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a column \"solved_trials\" that is equal to \"Trial\" - 1\n",
    "\n",
    "Filtered[\"solved_trials\"] = Filtered[\"Trial\"] - 1\n",
    "\n",
    "# Group by time and fly, then compute the mean of \"solved_trials\"\n",
    "\n",
    "average_solved = Filtered.groupby([\"time\"])[\"solved_trials\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the curve of the average \"solved_trials\" over time\n",
    "\n",
    "avgplot = average_solved.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"solved_trials\",\n",
    "    kind=\"line\",\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    height=400,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Save the plot\n",
    "\n",
    "hv.save(avgplot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_AverageSolvedTrials.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"solved_trials\"] = cleaned_data[\"Trial\"] - 1\n",
    "\n",
    "# Group by time and fly, then compute the mean of \"solved_trials\"\n",
    "\n",
    "clean_average_solved = cleaned_data.groupby([\"time\"])[\"solved_trials\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_avgplot = clean_average_solved.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"solved_trials\",\n",
    "    kind=\"line\",\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    height=400,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "hv.save(clean_avgplot, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with 'time' and 'solved_trials' columns\n",
    "# Group by 'time' and calculate mean and SEM\n",
    "grouped = cleaned_data.groupby(\"time\")[\"solved_trials\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "# Keep only times between 0 and 7100\n",
    "\n",
    "grouped = grouped[(grouped[\"time\"] >= 0) & (grouped[\"time\"] <= 7100)]\n",
    "\n",
    "# Calculate the confidence intervals (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "z_score = 1.96  # Z-score for 95% confidence\n",
    "grouped[\"ci_lower\"] = grouped[\"mean\"] - z_score * grouped[\"sem\"]\n",
    "grouped[\"ci_upper\"] = grouped[\"mean\"] + z_score * grouped[\"sem\"]\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped.rename(columns={\"mean\": \"solved_trials\"}, inplace=True)\n",
    "\n",
    "# Plot the data with confidence intervals\n",
    "clean_avgplot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"solved_trials\",\n",
    "    kind=\"line\",\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    height=400,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Create the area plot for the confidence intervals\n",
    "ci_area = hv.Area(\n",
    "    (grouped[\"time\"], grouped[\"ci_lower\"], grouped[\"ci_upper\"]),\n",
    "    vdims=[\"ci_lower\", \"ci_upper\"],\n",
    ").opts(alpha=0.3, color=\"blue\")\n",
    "\n",
    "# Overlay the confidence interval area plot with the line plot\n",
    "combined_plot = ci_area * clean_avgplot\n",
    "\n",
    "# Save the combined plot\n",
    "hv.save(\n",
    "    combined_plot,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'time' and calculate mean and SEM\n",
    "grouped = (\n",
    "    cleaned_data.groupby(\"time\")[\"solved_trials\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    ")\n",
    "\n",
    "# Keep only times between 0 and 7100\n",
    "grouped = grouped[(grouped[\"time\"] >= 0) & (grouped[\"time\"] <= 7100)]\n",
    "\n",
    "# Calculate the confidence intervals (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "z_score = 1.96  # Z-score for 95% confidence\n",
    "grouped[\"ci_lower\"] = grouped[\"mean\"] - z_score * grouped[\"sem\"]\n",
    "grouped[\"ci_upper\"] = grouped[\"mean\"] + z_score * grouped[\"sem\"]\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped.rename(columns={\"mean\": \"solved_trials\"}, inplace=True)\n",
    "\n",
    "# Fit a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(grouped[[\"time\"]], grouped[\"solved_trials\"])\n",
    "grouped[\"linear_fit\"] = linear_model.predict(grouped[[\"time\"]])\n",
    "linear_r2 = r2_score(grouped[\"solved_trials\"], grouped[\"linear_fit\"])\n",
    "\n",
    "\n",
    "# Define logistic function\n",
    "def logistic(x, L, x0, k):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "# Initial guesses for L, x0, k\n",
    "L_initial = max(grouped[\"solved_trials\"])\n",
    "x0_initial = np.median(grouped[\"time\"])\n",
    "k_initial = 1 / (max(grouped[\"time\"]) - min(grouped[\"time\"]))\n",
    "\n",
    "# Fit a logistic regression model\n",
    "popt, _ = curve_fit(\n",
    "    logistic,\n",
    "    grouped[\"time\"],\n",
    "    grouped[\"solved_trials\"],\n",
    "    p0=[L_initial, x0_initial, k_initial],\n",
    "    maxfev=5000,\n",
    ")\n",
    "grouped[\"logistic_fit\"] = logistic(grouped[\"time\"], *popt)\n",
    "logistic_r2 = r2_score(grouped[\"solved_trials\"], grouped[\"logistic_fit\"])\n",
    "\n",
    "# Plot the data with confidence intervals\n",
    "clean_avgplot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"solved_trials\",\n",
    "    kind=\"line\",\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    height=400,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Create the area plot for the confidence intervals\n",
    "ci_area = hv.Area(\n",
    "    (grouped[\"time\"], grouped[\"ci_lower\"], grouped[\"ci_upper\"]),\n",
    "    vdims=[\"ci_lower\", \"ci_upper\"],\n",
    ").opts(alpha=0.3, color=\"gray\")\n",
    "\n",
    "# Create the linear fit plot\n",
    "linear_fit_plot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"linear_fit\",\n",
    "    kind=\"line\",\n",
    "    color=\"red\",\n",
    "    line_dash=\"dashed\",\n",
    "    label=f\"Linear Fit (R²={linear_r2:.2f})\",\n",
    ")\n",
    "\n",
    "# Create the logistic fit plot\n",
    "logistic_fit_plot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"logistic_fit\",\n",
    "    kind=\"line\",\n",
    "    color=\"blue\",\n",
    "    line_dash=\"dotted\",\n",
    "    label=f\"Logistic Fit (R²={logistic_r2:.2f})\",\n",
    ")\n",
    "\n",
    "# Overlay the confidence interval area plot with the line plot and fits\n",
    "combined_plot = (ci_area * clean_avgplot * linear_fit_plot * logistic_fit_plot)\n",
    "\n",
    "# Save the combined plot\n",
    "hv.save(\n",
    "    combined_plot,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'time' and calculate mean and SEM\n",
    "grouped = (\n",
    "    cleaned_data.groupby(\"time\")[\"solved_trials\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    ")\n",
    "\n",
    "# Keep only times between 0 and 7100\n",
    "grouped = grouped[(grouped[\"time\"] >= 0) & (grouped[\"time\"] <= 7100)]\n",
    "\n",
    "# Calculate the confidence intervals (95% confidence level)\n",
    "confidence_level = 0.95\n",
    "z_score = 1.96  # Z-score for 95% confidence\n",
    "grouped[\"ci_lower\"] = grouped[\"mean\"] - z_score * grouped[\"sem\"]\n",
    "grouped[\"ci_upper\"] = grouped[\"mean\"] + z_score * grouped[\"sem\"]\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped.rename(columns={\"mean\": \"solved_trials\"}, inplace=True)\n",
    "\n",
    "# Fit a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(grouped[[\"time\"]], grouped[\"solved_trials\"])\n",
    "grouped[\"linear_fit\"] = linear_model.predict(grouped[[\"time\"]])\n",
    "linear_r2 = r2_score(grouped[\"solved_trials\"], grouped[\"linear_fit\"])\n",
    "\n",
    "# Fit a piecewise linear regression model\n",
    "piecewise_model = pwlf.PiecewiseLinFit(grouped[\"time\"], grouped[\"solved_trials\"])\n",
    "\n",
    "# Define the number of line segments\n",
    "num_segments = 4  # Adjust this number based on your data\n",
    "\n",
    "# Fit the model\n",
    "breaks = piecewise_model.fit(num_segments)\n",
    "\n",
    "# Predict the piecewise linear fit\n",
    "grouped[\"piecewise_fit\"] = piecewise_model.predict(grouped[\"time\"])\n",
    "piecewise_r2 = r2_score(grouped[\"solved_trials\"], grouped[\"piecewise_fit\"])\n",
    "\n",
    "# Plot the data with confidence intervals\n",
    "clean_avgplot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"solved_trials\",\n",
    "    kind=\"line\",\n",
    "    title=\"Average Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Average Solved Trials\",\n",
    "    line_width=3,\n",
    "    height=400,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Create the area plot for the confidence intervals\n",
    "ci_area = hv.Area(\n",
    "    (grouped[\"time\"], grouped[\"ci_lower\"], grouped[\"ci_upper\"]),\n",
    "    vdims=[\"ci_lower\", \"ci_upper\"],\n",
    ").opts(alpha=0.1, color=\"blue\")\n",
    "\n",
    "# Create the linear fit plot\n",
    "linear_fit_plot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"linear_fit\",\n",
    "    kind=\"line\",\n",
    "    line_width=3,\n",
    "    color=\"red\",\n",
    "    line_dash=\"dashed\",\n",
    "    label=f\"Linear Fit (R²={linear_r2:.2f})\",\n",
    ")\n",
    "\n",
    "# Create the piecewise linear fit plot\n",
    "piecewise_fit_plot = grouped.hvplot(\n",
    "    x=\"time\",\n",
    "    y=\"piecewise_fit\",\n",
    "    kind=\"line\",\n",
    "    line_width=3,\n",
    "    color=\"green\",\n",
    "    line_dash=\"dotdash\",\n",
    "    label=f\"Piecewise Linear Fit (R²={piecewise_r2:.2f})\",\n",
    ")\n",
    "\n",
    "# Overlay the confidence interval area plot with the line plot and fits\n",
    "combined_plot = ci_area * clean_avgplot * linear_fit_plot * piecewise_fit_plot\n",
    "\n",
    "# Save the combined plot\n",
    "hv.save(\n",
    "    combined_plot,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials_Linear.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_plot = combined_plot.options(**HoloviewsTemplates.hv_slides[\"plot\"]).opts(\n",
    "    invert_axes=False, show_legend=True\n",
    ")\n",
    "\n",
    "hv.save(\n",
    "    combined_plot,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials_Linear.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subplot = (clean_avgplot * ci_area).options(**HoloviewsTemplates.hv_slides[\"plot\"]).opts(\n",
    "    invert_axes=False, show_legend=True)\n",
    "\n",
    "hv.save(Subplot,\n",
    "        \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240815_CleanAverageSolvedTrials_Linear_Subplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
