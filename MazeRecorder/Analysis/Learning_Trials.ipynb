{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_behavior\n",
    "\n",
    "from utils_behavior import Ballpushing_utils\n",
    "from utils_behavior import Utils\n",
    "from utils_behavior import Processing\n",
    "from utils_behavior import HoloviewsTemplates\n",
    "\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the data\n",
    "\n",
    "Datapath = Utils.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already existing dataset: \n",
    "\n",
    "Subset = feather.read_feather(\"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Learning/240809_BallposData.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find folders with \"Learning or learning\" in the name as a list\n",
    "\n",
    "folders = [f for f in Datapath.glob(\"*Learning*\")]\n",
    "\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the experiments\n",
    "\n",
    "Exps = [Ballpushing_utils.Experiment(f) for f in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Ballpushing_utils.Dataset(Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.generate_dataset(success_cutoff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns\n",
    "  \n",
    "Data.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of the data keeping only yball, yball_smooth,\n",
    "\n",
    "Subset = Data.data[[\"Frame\",\"time\", \"yball\", \"yball_smooth\", \"yball_relative\", \"fly\", \"Peak\", \"Date\"]]\n",
    "\n",
    "# Save this subset to a feather file\n",
    "\n",
    "#feather.write_feather(Subset, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Datasets/Learning/240809_BallposData.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the first fly and store it to use it for the next steps\n",
    "\n",
    "fly = Subset[\"fly\"].iloc[0]\n",
    "\n",
    "TestData = Subset[Subset[\"fly\"] == fly]\n",
    "\n",
    "# Now take one fly and plot the yball_relative\n",
    "\n",
    "Subset[Subset[\"fly\"] == fly].hvplot(x=\"time\", y=\"yball_relative\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the derivative of the yball_relative\n",
    "\n",
    "Subset[\"yball_relative_derivative\"] = Subset[\"yball_relative\"].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the derivative\n",
    "\n",
    "Subset[Subset[\"fly\"] == fly].hvplot(x=\"time\", y=\"yball_relative_derivative\", kind=\"scatter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Negative peak detection on the derivative\n",
    "\n",
    "Peaks = find_peaks(-TestData[\"yball_relative_derivative\"], height=0.23, distance=500)\n",
    "\n",
    "Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the \"time\" and \"Frame\" columns from the dataset\n",
    "frame_to_time_mapping = dict(zip(TestData[\"Frame\"], TestData[\"time\"]))\n",
    "\n",
    "# Convert Peaks data to lists\n",
    "x_peaks = Peaks[0].tolist()\n",
    "y_peaks = Peaks[1][\"peak_heights\"].tolist()\n",
    "\n",
    "# Map frame indices to time values\n",
    "x_peaks_time = [frame_to_time_mapping[frame] for frame in x_peaks]\n",
    "\n",
    "# Plot the derivative and the peaks\n",
    "scatter_plot = TestData.hvplot(x=\"time\", y=\"yball_relative_derivative\", kind=\"scatter\")\n",
    "peaks_plot = hv.Scatter(\n",
    "    (x_peaks_time, y_peaks), kdims=[\"time\"], vdims=[\"peak_heights\"], label=\"Peaks\"\n",
    ")\n",
    "\n",
    "# Combine the plots\n",
    "combined_plot = scatter_plot * peaks_plot\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Group by individual flies\n",
    "grouped = Subset.groupby(\"fly\")\n",
    "\n",
    "\n",
    "# Function to process each group\n",
    "def process_group(group):\n",
    "    # Find peaks in the derivative\n",
    "    peaks, _ = find_peaks(\n",
    "        -group[\"yball_relative_derivative\"], height=0.3, distance=500\n",
    "    )\n",
    "\n",
    "    # Debug: Print the peaks detected for each fly\n",
    "    print(f\"Fly: {group['fly'].iloc[0]}, Peaks: {peaks}\")\n",
    "\n",
    "    # Initialize the \"Trial\" column\n",
    "    group[\"Trial\"] = 0\n",
    "\n",
    "    # Assign trial numbers based on peak positions\n",
    "    trial_number = 1\n",
    "    previous_peak = 0\n",
    "    for peak in peaks:\n",
    "        group.iloc[previous_peak : peak + 1, group.columns.get_loc(\"Trial\")] = (\n",
    "            trial_number\n",
    "        )\n",
    "        trial_number += 1\n",
    "        previous_peak = peak + 1\n",
    "\n",
    "    # Assign the last trial number to the remaining rows\n",
    "    group.iloc[previous_peak:, group.columns.get_loc(\"Trial\")] = trial_number\n",
    "\n",
    "    # Debug: Print the trial numbers assigned for each fly\n",
    "    print(group[[\"fly\", \"Frame\", \"Trial\"]].head(10))\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "# Apply the function to each group and combine the results\n",
    "Trials = grouped.apply(process_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique trials there are grouped by fly\n",
    "Trials.groupby(\"fly\")[\"Trial\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can drop any fly that has less than 2 trials\n",
    "\n",
    "Filtered = Trials.groupby(\"fly\").filter(lambda x: x[\"Trial\"].nunique() > 1)\n",
    "\n",
    "Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered.groupby(\"fly\")[\"Trial\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Trial and time, then compute the mean of yball_relative\n",
    "averaged_data = (\n",
    "    Filtered.groupby([\"Trial\", \"time\"])[\"yball_relative\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Plot the averaged yball_relative values\n",
    "averaged_data.hvplot(\n",
    "    x=\"time\", y=\"yball_relative\", by=\"Trial\", kind=\"line\", legend=\"top_left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among the flies that have more than 1 trial, we need to drop the Frames that belong to a plateau, meaning the frames where the yball_relative is above a certain threshold\n",
    "\n",
    "\n",
    "# Function to clean each trial\n",
    "def clean_trial(group):\n",
    "    # Drop the first 500 frames\n",
    "    group = group.iloc[500:]\n",
    "\n",
    "    # Find the index where yball_relative reaches its max value for the first time\n",
    "    max_index = group[\"yball_relative\"].idxmax()\n",
    "\n",
    "    # Trim the trial data to end at this maximum value\n",
    "    group = group.loc[:max_index]\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "# Apply the function to each group and combine the results\n",
    "cleaned_data = (\n",
    "    Filtered.groupby([\"fly\", \"Trial\"]).apply(clean_trial).reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display the cleaned dataset\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute trial duration\n",
    "def compute_trial_duration(group):\n",
    "    duration = group[\"time\"].max() - group[\"time\"].min()\n",
    "    return pd.Series({\"duration\": duration})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_duration).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jitterbox = HoloviewsTemplates.jitter_boxplot(trial_durations, kdims = \"Trial\", metric=\"duration\", plot_options=HoloviewsTemplates.hv_slides).opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jitterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a PNG and a SVG file\n",
    "hv.save(\n",
    "    Jitterbox,\n",
    "    \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "# Create the jitterboxplot\n",
    "jitterbox = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "# Create a line plot to track each \"fly\" across trial numbers\n",
    "line_plot = (\n",
    "    hv.Curve(trial_durations, kdims=[\"Trial\"], vdims=[\"duration\", \"fly\"])\n",
    "    .groupby(\"fly\")\n",
    "    .opts(color=\"gray\", line_width=1, alpha=0.5)\n",
    "    .overlay()\n",
    ")\n",
    "\n",
    "# Overlay the line plot on top of the jitterboxplot\n",
    "combined_plot = (jitterbox * line_plot).opts(width = 1500,\n",
    "                                             height = 1000,\n",
    "                                             )\n",
    "\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming trial_durations is your DataFrame\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "trial_durations[\"Trial\"] = pd.Categorical(trial_durations[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Function to calculate improvement\n",
    "def calculate_improvement(df):\n",
    "    df = df.sort_values(by=\"Trial\")\n",
    "    df[\"improved\"] = df[\"duration\"].diff().lt(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to each group of 'fly'\n",
    "trial_durations = trial_durations.groupby(\"fly\").apply(calculate_improvement)\n",
    "\n",
    "# Calculate the proportion of flies that improved in each trial\n",
    "improvement_proportions = trial_durations.groupby(\"Trial\")[\"improved\"].mean()\n",
    "\n",
    "# Print the results\n",
    "print(improvement_proportions)\n",
    "\n",
    "# Plot the results\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "improvement_plot = hv.Curve(improvement_proportions).opts(\n",
    "    xlabel=\"Trial Number\",\n",
    "    ylabel=\"Proportion of Flies Improved\",\n",
    "    title=\"Proportion of Flies that Improved in Each Trial\",\n",
    "    width=800,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "improvement_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot\n",
    "hv.save(improvement_plot, \"improvement_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to get only the \"morning\" data\n",
    "morning_data = cleaned_data[cleaned_data[\"Peak\"] == \"morning\"]\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations = (\n",
    "    morning_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_duration).reset_index()\n",
    ")\n",
    "\n",
    "# Redo the plot with the morning data\n",
    "\n",
    "# Create the jitterboxplot\n",
    "jitterbox = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "# Create a line plot to track each \"fly\" across trial numbers\n",
    "line_plot = (\n",
    "    hv.Curve(trial_durations, kdims=[\"Trial\"], vdims=[\"duration\", \"fly\"])\n",
    "    .groupby(\"fly\")\n",
    "    .overlay()\n",
    ")\n",
    "\n",
    "# Overlay the line plot on top of the jitterboxplot\n",
    "combined_plot = (jitterbox * line_plot).opts(width = 1500,\n",
    "                                             height = 1000,\n",
    "                                             )\n",
    "\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flies for which \"Peak\" is NaN, give them the value \"morning\"\n",
    "Filtered[\"Peak\"] = Filtered[\"Peak\"].fillna(\"morning\")\n",
    "cleaned_data[\"Peak\"] = cleaned_data[\"Peak\"].fillna(\"morning\")\n",
    "\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "cleaned_data[\"Trial\"] = pd.Categorical(cleaned_data[\"Trial\"], ordered=True)\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations_peak = (\n",
    "    cleaned_data.groupby([\"Peak\",\"fly\", \"Trial\"]).apply(compute_trial_duration).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "Jitterbox_peak = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations_peak,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    "    groupby=\"Peak\",\n",
    "    render=\"grouped\"\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "Jitterbox_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "\n",
    "# For flies for which \"Peak\" is NaN, give them the value \"morning\"\n",
    "Filtered[\"Peak\"] = Filtered[\"Peak\"].fillna(\"morning\")\n",
    "cleaned_data[\"Peak\"] = cleaned_data[\"Peak\"].fillna(\"morning\")\n",
    "\n",
    "# Ensure 'Trial' is treated as a categorical variable with ordered categories\n",
    "cleaned_data[\"Trial\"] = pd.Categorical(cleaned_data[\"Trial\"], ordered=True)\n",
    "\n",
    "# Apply the function to each group and compute the trial durations\n",
    "trial_durations_peak = (\n",
    "    cleaned_data.groupby([\"Peak\", \"fly\", \"Trial\"])\n",
    "    .apply(compute_trial_duration)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Create the jitterboxplot\n",
    "jitterbox_peak = HoloviewsTemplates.jitter_boxplot(\n",
    "    trial_durations_peak,\n",
    "    kdims=\"Trial\",\n",
    "    metric=\"duration\",\n",
    "    plot_options=HoloviewsTemplates.hv_slides,\n",
    "    groupby=\"Peak\",\n",
    "    render=\"grouped\",\n",
    ").opts(invert_axes=False, xlabel=\"Trial Number\", ylabel=\"Duration (s)\")\n",
    "\n",
    "# Create a line plot to track each \"fly\" across trial numbers\n",
    "line_plot_peak = (\n",
    "    hv.Curve(trial_durations_peak, kdims=[\"Trial\", \"Peak\"], vdims=[\"duration\", \"fly\"])\n",
    "    .groupby([\"Peak\", \"fly\"])\n",
    "    .overlay()\n",
    ")\n",
    "\n",
    "# Overlay the line plot on top of the jitterboxplot\n",
    "combined_plot_peak = (jitterbox_peak * line_plot_peak).opts(\n",
    "    width=1500,\n",
    "    height=1000,\n",
    ")\n",
    "\n",
    "combined_plot_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a PNG and a SVG file\n",
    "hv.save(Jitterbox, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io.export import export_svgs\n",
    "\n",
    "def export_svg(obj, filename):\n",
    "    plot_state = hv.renderer(\"bokeh\").get_plot(obj).state\n",
    "    plot_state.output_backend = \"svg\"\n",
    "    export_svgs(plot_state, filename=filename)\n",
    "\n",
    "\n",
    "export_svg(Jitterbox, \"/mnt/upramdya_data/MD/MultiMazeRecorder/Plots/Learning/240809_TrialDuration.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Trial back to integers\n",
    "cleaned_data[\"Trial\"] = cleaned_data[\"Trial\"].astype(int)\n",
    "\n",
    "# Function to compute the end time of each trial\n",
    "def compute_trial_end_time(group):\n",
    "    end_time = group[\"time\"].max()\n",
    "    return pd.Series({\"end_time\": end_time})\n",
    "\n",
    "\n",
    "# Apply the function to each group and compute the end times\n",
    "trial_end_times = (\n",
    "    cleaned_data.groupby([\"fly\", \"Trial\"]).apply(compute_trial_end_time).reset_index()\n",
    ")\n",
    "\n",
    "# Sort by end_time\n",
    "trial_end_times = trial_end_times.sort_values(by=\"end_time\")\n",
    "\n",
    "# Compute the cumulative count of solved trials\n",
    "trial_end_times[\"cumulative_solved_trials\"] = (\n",
    "    trial_end_times[\"end_time\"].rank(method=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "# Plot the cumulative count of solved trials over time\n",
    "trial_end_times.hvplot.step(\n",
    "    x=\"end_time\",\n",
    "    y=\"cumulative_solved_trials\",\n",
    "    title=\"Cumulative Solved Trials Over Time\",\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Cumulative Solved Trials\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts  # Import opts from holoviews\n",
    "\n",
    "\n",
    "# Define logistic function\n",
    "def logistic(x, L, k, x0):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "# Filter data to include only relevant subset\n",
    "GroupData_morning = trial_end_times\n",
    "\n",
    "# Calculate the number of unique 'flies' in the dataset\n",
    "num_replicates = GroupData_morning[\"fly\"].nunique()\n",
    "\n",
    "# Initial guesses for L, k, x0\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    1,\n",
    "    np.median(GroupData_morning[\"end_time\"]),\n",
    "]\n",
    "\n",
    "# Fit logistic function to data\n",
    "params, _ = curve_fit(\n",
    "    logistic,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=10000,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L, k, x0\n",
    "L, k, x0 = params\n",
    "\n",
    "# Create a new DataFrame for the logistic fit curve\n",
    "logistic_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the logistic fit curve\n",
    "logistic_fit[\"cumulative_solved_trials\"] = logistic(logistic_fit[\"end_time\"], L, k, x0)\n",
    "\n",
    "# Calculate R-squared for logistic fit curve\n",
    "y_pred_logistic = logistic(GroupData_morning[\"end_time\"], L, k, x0)\n",
    "r_squared_logistic = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_logistic\n",
    ")\n",
    "\n",
    "# Calculate linear fit for the first half of the data\n",
    "first_half = GroupData_morning.iloc[: len(GroupData_morning) // 2]\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    first_half[\"end_time\"], first_half[\"cumulative_solved_trials\"]\n",
    ")\n",
    "\n",
    "# Create a new DataFrame for the linear fit line\n",
    "linear_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the linear fit line\n",
    "linear_fit[\"cumulative_solved_trials\"] = slope * linear_fit[\"end_time\"] + intercept\n",
    "\n",
    "# Calculate R-squared for linear fit curve\n",
    "y_pred_linear = slope * GroupData_morning[\"end_time\"] + intercept\n",
    "r_squared_linear = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_linear\n",
    ")\n",
    "\n",
    "# Calculate center x value and min and maximum xy value\n",
    "center_x = (\n",
    "    GroupData_morning[\"end_time\"].max() - GroupData_morning[\"end_time\"].min()\n",
    ") / 2\n",
    "max_y = max(\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    max(logistic_fit[\"cumulative_solved_trials\"]),\n",
    ")\n",
    "\n",
    "max_x = GroupData_morning[\"end_time\"].max()\n",
    "min_y = GroupData_morning[\"cumulative_solved_trials\"].min()\n",
    "\n",
    "# Create your plot using GroupData_morning and add the fits and annotations\n",
    "cumulcurve_pool = (\n",
    "    hv.Curve(\n",
    "        data=GroupData_morning,\n",
    "        kdims=[\"end_time\"],\n",
    "        vdims=[\"cumulative_solved_trials\"],\n",
    "    )\n",
    "    .opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )\n",
    "    * hv.Curve(\n",
    "        data=logistic_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"green\")\n",
    "    * hv.Curve(\n",
    "        data=linear_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"red\")\n",
    "    # Uncomment the following lines to add text annotations\n",
    "    * hv.Text(center_x, max_y - 7, f\"Logistic fit R-squared: {r_squared_logistic:.2f}\").opts(text_color=\"green\")\n",
    "    * hv.Text(center_x, max_y, f\"Linear fit R-squared: {r_squared_linear:.2f}\").opts(text_color=\"red\")\n",
    "    * hv.Text(max_x - 100, min_y * num_replicates, f\"N = {num_replicates}\")\n",
    ").opts(\n",
    "    opts.Area(\n",
    "        show_legend=False,\n",
    "        show_frame=False,\n",
    "        fill_color=\"blue\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "cumulcurve_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "# Define double sigmoid function\n",
    "def double_sigmoid(x, L1, k1, x01, L2, k2, x02):\n",
    "    return (L1 / (1 + np.exp(-k1 * (x - x01)))) + (L2 / (1 + np.exp(-k2 * (x - x02))))\n",
    "\n",
    "\n",
    "# Improved initial guesses for L1, k1, x01, L2, k2, x02\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) / 2,\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]) / 2,\n",
    "    0.1,\n",
    "    np.median(GroupData_morning[\"end_time\"]) * 1.5,\n",
    "]\n",
    "\n",
    "# Increase maxfev\n",
    "maxfev_value = 10000\n",
    "\n",
    "# Fit double sigmoid function to data\n",
    "params, _ = curve_fit(\n",
    "    double_sigmoid,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=maxfev_value,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L1, k1, x01, L2, k2, x02\n",
    "L1, k1, x01, L2, k2, x02 = params\n",
    "\n",
    "# Calculate fitted values\n",
    "fitted_values = double_sigmoid(GroupData_morning[\"end_time\"], L1, k1, x01, L2, k2, x02)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = GroupData_morning[\"cumulative_solved_trials\"] - fitted_values\n",
    "\n",
    "# Calculate SS_res and SS_tot\n",
    "SS_res = np.sum(residuals**2)\n",
    "SS_tot = np.sum(\n",
    "    (\n",
    "        GroupData_morning[\"cumulative_solved_trials\"]\n",
    "        - np.mean(GroupData_morning[\"cumulative_solved_trials\"])\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = 1 - (SS_res / SS_tot)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Create a new DataFrame for the double sigmoid fit curve\n",
    "double_sigmoid_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the double sigmoid fit curve\n",
    "double_sigmoid_fit[\"cumulative_solved_trials\"] = double_sigmoid(\n",
    "    double_sigmoid_fit[\"end_time\"], L1, k1, x01, L2, k2, x02\n",
    ")\n",
    "\n",
    "# Plot the original data and the double sigmoid fit curve\n",
    "cumulcurve_pool = hv.Curve(\n",
    "    data=GroupData_morning,\n",
    "    kdims=[\"end_time\"],\n",
    "    vdims=[\"cumulative_solved_trials\"],\n",
    ").opts(\n",
    "    height=1000,\n",
    "    width=1200,\n",
    "    alpha=1,\n",
    "    line_width=2,\n",
    "    xlabel=\"Time(s)\",\n",
    "    ylabel=\"Cumulative Solved Trials\",\n",
    "    show_grid=True,\n",
    "    fontscale=3,\n",
    "    title=\"Cumulative Solved Trials Over Time\",\n",
    ") * hv.Curve(\n",
    "    data=double_sigmoid_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    ").opts(\n",
    "    color=\"green\"\n",
    ")\n",
    "\n",
    "cumulcurve_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from holoviews import opts  # Import opts from holoviews\n",
    "\n",
    "\n",
    "# Define logistic (sigmoid) function\n",
    "def sigmoid(x, L, k, x0):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "# Filter data to include only relevant subset\n",
    "GroupData_morning = trial_end_times\n",
    "\n",
    "# Calculate the number of unique 'flies' in the dataset\n",
    "num_replicates = GroupData_morning[\"fly\"].nunique()\n",
    "\n",
    "# Initial guesses for L, k, x0\n",
    "p0 = [\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    1,\n",
    "    np.median(GroupData_morning[\"end_time\"]),\n",
    "]\n",
    "\n",
    "# Fit sigmoid function to data\n",
    "params, _ = curve_fit(\n",
    "    sigmoid,\n",
    "    GroupData_morning[\"end_time\"],\n",
    "    GroupData_morning[\"cumulative_solved_trials\"],\n",
    "    p0,\n",
    "    maxfev=5000,\n",
    ")\n",
    "\n",
    "# params contains the fitted values for L, k, x0\n",
    "L, k, x0 = params\n",
    "\n",
    "# Create a new DataFrame for the sigmoid fit curve\n",
    "sigmoid_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the sigmoid fit curve\n",
    "sigmoid_fit[\"cumulative_solved_trials\"] = sigmoid(sigmoid_fit[\"end_time\"], L, k, x0)\n",
    "\n",
    "# Calculate R-squared for sigmoid fit curve\n",
    "y_pred_sigmoid = sigmoid(GroupData_morning[\"end_time\"], L, k, x0)\n",
    "r_squared_sigmoid = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_sigmoid\n",
    ")\n",
    "\n",
    "# Calculate linear fit for the first half of the data\n",
    "first_half = GroupData_morning.iloc[: len(GroupData_morning) // 2]\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    first_half[\"end_time\"], first_half[\"cumulative_solved_trials\"]\n",
    ")\n",
    "\n",
    "# Create a new DataFrame for the linear fit line\n",
    "linear_fit = pd.DataFrame(\n",
    "    {\n",
    "        \"end_time\": np.linspace(\n",
    "            GroupData_morning[\"end_time\"].min(),\n",
    "            GroupData_morning[\"end_time\"].max(),\n",
    "            100,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate y values for the linear fit line\n",
    "linear_fit[\"cumulative_solved_trials\"] = slope * linear_fit[\"end_time\"] + intercept\n",
    "\n",
    "# Calculate R-squared for linear fit curve\n",
    "y_pred_linear = slope * GroupData_morning[\"end_time\"] + intercept\n",
    "r_squared_linear = r2_score(\n",
    "    GroupData_morning[\"cumulative_solved_trials\"], y_pred_linear\n",
    ")\n",
    "\n",
    "# Calculate center x value and min and maximum xy value\n",
    "center_x = (\n",
    "    GroupData_morning[\"end_time\"].max() - GroupData_morning[\"end_time\"].min()\n",
    ") / 2\n",
    "max_y = max(\n",
    "    max(GroupData_morning[\"cumulative_solved_trials\"]),\n",
    "    max(sigmoid_fit[\"cumulative_solved_trials\"]),\n",
    ")\n",
    "\n",
    "max_x = GroupData_morning[\"end_time\"].max()\n",
    "min_y = GroupData_morning[\"cumulative_solved_trials\"].min()\n",
    "\n",
    "# Create your plot using GroupData_morning and add the fits and annotations\n",
    "cumulcurve_pool = (\n",
    "    hv.Curve(\n",
    "        data=GroupData_morning,\n",
    "        kdims=[\"end_time\"],\n",
    "        vdims=[\"cumulative_solved_trials\"],\n",
    "    )\n",
    "    .opts(\n",
    "        height=1000,\n",
    "        width=1200,\n",
    "        alpha=1,\n",
    "        line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Cumulative Solved Trials\",\n",
    "        show_grid=True,\n",
    "        fontscale=3,\n",
    "        title=\"Cumulative Solved Trials Over Time\",\n",
    "    )\n",
    "    * hv.Curve(\n",
    "        data=sigmoid_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"blue\")\n",
    "    * hv.Curve(\n",
    "        data=linear_fit, kdims=[\"end_time\"], vdims=[\"cumulative_solved_trials\"]\n",
    "    ).opts(color=\"red\")\n",
    "    # Uncomment the following lines to add text annotations\n",
    "    * hv.Text(center_x, max_y - 10, f\"Sigmoid fit R-squared: {r_squared_sigmoid:.2f}\").opts(text_color=\"blue\")\n",
    "    * hv.Text(center_x, max_y, f\"Linear fit R-squared: {r_squared_linear:.2f}\").opts(text_color=\"red\")\n",
    "    * hv.Text(max_x - 100, min_y * num_replicates, f\"N = {num_replicates}\")\n",
    ").opts(\n",
    "    opts.Area(\n",
    "        show_legend=False,\n",
    "        show_frame=False,\n",
    "        fill_color=\"blue\",\n",
    "        line_color=\"black\",\n",
    "        line_width=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "cumulcurve_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
