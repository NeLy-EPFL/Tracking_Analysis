{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This code allows balls tracking in fly pushing experiments.\n",
    "\n",
    "For now, proved successful in single corridor arenas with 1 fly and 1 ball, with different arena materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add path to utilities module\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Path definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VideoPath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/Optogenetics/Optobot/MultiMaze_15stepped_gated_bowtie/Starved_noWater/230209/111026_s0a0_p0-0/Arena5/Arena5.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mac path\n",
    "VideoPath = Path(\n",
    "    \"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/Optogenetics/Optobot/MultiMazeBiS_15_Steel_Wax/Female_Starved_noWater/221116/102044_s0a0_p6-0/Arena4/Arena4.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Quickly check first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "for i in range(1):\n",
    "    success, im_full = vidcap.read()\n",
    "\n",
    "im_full_gray = cv2.cvtColor(im_full, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# hv.Image(im_full_gray)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.imshow(\n",
    "    im_full_gray, cmap=\"gray\", vmin=0, vmax=255\n",
    ");  # semicolon removes print of matplotlib object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Optional : Fine tune tracking parameters for new videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate trimmed version of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the start and finish timestamps\n",
    "startpoint = \"00:10:20\"\n",
    "\n",
    "finishpoint = \"00:10:50\"\n",
    "TrimmedPath = VideoPath.with_stem(VideoPath.stem + \"_Trimmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(  # Ffmpeg +\n",
    "    \"ffmpeg -hide_banner -loglevel error -i \"\n",
    "    + VideoPath.as_posix()\n",
    "    + \" -ss \"\n",
    "    + startpoint\n",
    "    + \" -to \"\n",
    "    + finishpoint\n",
    "    + \" -c copy \"\n",
    "    + TrimmedPath.as_posix()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startpoint = \"00:35:00\"\n",
    "\n",
    "finishpoint = \"00:35:30\"\n",
    "TrimmedPath2 = VideoPath.with_stem(VideoPath.stem + \"_Trimmed2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(  # Ffmpeg +\n",
    "    \"ffmpeg -hide_banner -loglevel error -i \"\n",
    "    + VideoPath.as_posix()\n",
    "    + \" -ss \"\n",
    "    + startpoint\n",
    "    + \" -to \"\n",
    "    + finishpoint\n",
    "    + \" -c copy \"\n",
    "    + TrimmedPath2.as_posix()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Play with y cropping parameters to center ROI on corridor without chambers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "cropping_parameters = (195, 655)\n",
    "cropped = im_full_gray[cropping_parameters[0] : cropping_parameters[1], :]\n",
    "# Note that this is arbitrary but shouldn't move from one arena to the other.\n",
    "# 120:650 was chosen for previous videos, here 155:685 is better aligned with arenas\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.imshow(cropped, cmap=\"gray\", vmin=0, vmax=255);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save cropping parameters in a file for further use\n",
    "# if VideoPath.parent.joinpath(\"Cropping_params.npy\").exists() is True:\n",
    "#     choice = input(\"File already exists! Overwrite? [y/n]\")\n",
    "\n",
    "#     if choice == \"n\":\n",
    "#         print(\"File unchanged.\")\n",
    "\n",
    "#     elif choice == \"y\":\n",
    "#         np.save(\n",
    "#             VideoPath.parent.joinpath(\"Cropping_params.npy\").as_posix(),\n",
    "#             cropping_parameters,\n",
    "#         )\n",
    "#         print(\"File updated.\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"invalid input\")\n",
    "\n",
    "# else:\n",
    "#     np.save(\n",
    "#         VideoPath.parent.joinpath(\"Cropping_params.npy\").as_posix(), cropping_parameters\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksave(\n",
    "    path=VideoPath.parent.joinpath(\"Cropping_params.npy\"),\n",
    "    object=\"parameter\",\n",
    "    file=cropping_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load cropping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cropping_parameters in locals():\n",
    "    pass\n",
    "else:\n",
    "    cropping_parameters = np.load(\n",
    "        VideoPath.parent.joinpath(\"Cropping_params.npy\").as_posix()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check ball tracking on video sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vidcap = cv2.VideoCapture(TrimmedPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "ballpos = []\n",
    "\n",
    "\n",
    "# Hough circles parameters to tune\n",
    "param1 = 120\n",
    "param2 = 50\n",
    "minrad = 5\n",
    "maxrad = 20\n",
    "dp = 1.5\n",
    "mindist = 500\n",
    "\n",
    "# Counter for failed detections\n",
    "fails = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read()  # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "        cropped = im_full_gray[cropping_parameters[0] : cropping_parameters[1], :]\n",
    "\n",
    "        # filtered = cv2.medianBlur(cropped, 5)\n",
    "        filtered = cv2.GaussianBlur(cropped, (9, 9), 0)\n",
    "\n",
    "        # rows = filt.shape[0]\n",
    "        circles = cv2.HoughCircles(\n",
    "            filtered,\n",
    "            cv2.HOUGH_GRADIENT,\n",
    "            dp=dp,\n",
    "            minDist=mindist,\n",
    "            param1=param1,\n",
    "            param2=param2,\n",
    "            minRadius=minrad,\n",
    "            maxRadius=maxrad,\n",
    "        )\n",
    "\n",
    "        out = cv2.cvtColor(cropped, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "\n",
    "                ballpos.append(center)\n",
    "\n",
    "                # circle center\n",
    "                cv2.circle(out, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                cv2.circle(out, center, radius, (255, 0, 255), 3)\n",
    "        elif len(ballpos) > 0:\n",
    "            fails += 1\n",
    "            ballpos.append(ballpos[-1])\n",
    "            cv2.circle(out, ballpos[-1], 1, (0, 0, 255), 3)\n",
    "            cv2.circle(out, center, radius, (0, 0, 255), 3)\n",
    "\n",
    "        # if len(ballpos) > 1:\n",
    "        #     if np.absolute(ballpos[-1][1] - ballpos[-2][1]) > 25:\n",
    "        #         ballpos_corr.append(ballpos[-2])\n",
    "        #         cv2.circle(out, ballpos_corr[-1], 1, (0, 255, 0), 3)\n",
    "        #         cv2.circle(out, center, radius, (0, 255, 0), 3)\n",
    "        #     else:\n",
    "        #         ballpos_corr.append(ballpos[-1])\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(\n",
    "            img=out,\n",
    "            text=str(i) + \"/\" + str(TotFrame),\n",
    "            color=(255, 0, 0),\n",
    "            org=(0, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.3,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"detected circles\", out)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print(\n",
    "    \"Parameters test finished. Detection success: \"\n",
    "    + str(((TotFrame - fails) / TotFrame) * 100)\n",
    "    + \"%.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations : \n",
    "\n",
    "Higher canny edge parameter avoid detecting the magnet.\n",
    "\n",
    "Interesting : Radius of detected circle seems to be constant when ball is correctly detected. Let's check radius in circle instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check it with a different chunk of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vidcap = cv2.VideoCapture(TrimmedPath2.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "ballpos = []\n",
    "\n",
    "\n",
    "# Hough circles parameters to tune\n",
    "param1 = 120\n",
    "param2 = 50\n",
    "minrad = 5\n",
    "maxrad = 20\n",
    "dp = 1.5\n",
    "mindist = 500\n",
    "\n",
    "# Counter for failed detections\n",
    "fails = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read()  # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "        cropped = im_full_gray[cropping_parameters[0] : cropping_parameters[1], :]\n",
    "\n",
    "        # filtered = cv2.medianBlur(cropped, 5)\n",
    "        filtered = cv2.GaussianBlur(cropped, (9, 9), 0)\n",
    "\n",
    "        # rows = filt.shape[0]\n",
    "        circles = cv2.HoughCircles(\n",
    "            filtered,\n",
    "            cv2.HOUGH_GRADIENT,\n",
    "            dp=dp,\n",
    "            minDist=mindist,\n",
    "            param1=param1,\n",
    "            param2=param2,\n",
    "            minRadius=minrad,\n",
    "            maxRadius=maxrad,\n",
    "        )\n",
    "\n",
    "        out = cv2.cvtColor(cropped, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "\n",
    "                ballpos.append(center)\n",
    "\n",
    "                # circle center\n",
    "                cv2.circle(out, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                cv2.circle(out, center, radius, (255, 0, 255), 3)\n",
    "        elif len(ballpos) > 0:\n",
    "            fails += 1\n",
    "            ballpos.append(ballpos[-1])\n",
    "            cv2.circle(out, ballpos[-1], 1, (0, 0, 255), 3)\n",
    "            cv2.circle(out, center, radius, (0, 0, 255), 3)\n",
    "\n",
    "        # if len(ballpos) > 1:\n",
    "        #     if np.absolute(ballpos[-1][1] - ballpos[-2][1]) > 25:\n",
    "        #         ballpos_corr.append(ballpos[-2])\n",
    "        #         cv2.circle(out, ballpos_corr[-1], 1, (0, 255, 0), 3)\n",
    "        #         cv2.circle(out, center, radius, (0, 255, 0), 3)\n",
    "        #     else:\n",
    "        #         ballpos_corr.append(ballpos[-1])\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(\n",
    "            img=out,\n",
    "            text=str(i) + \"/\" + str(TotFrame),\n",
    "            color=(255, 0, 0),\n",
    "            org=(0, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.3,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"detected circles\", out)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print(\n",
    "    \"Parameters test finished. Detection success: \"\n",
    "    + str(((TotFrame - fails) / TotFrame) * 100)\n",
    "    + \"%.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing: detect false detection and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ballpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all second values of ballpos tuples\n",
    "ballpos_y = [i[1] for i in ballpos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.01  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "ysmooth = butter_lowpass_filter(ballpos_y, cutoff, order)\n",
    "\n",
    "plt.plot(ysmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ballpos_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save fine tuned Hough circles parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'param1' : param1,\n",
    "#     'param2' : param2,\n",
    "#     'minrad' : minrad,\n",
    "#     'maxrad' : maxrad,\n",
    "# }\n",
    "\n",
    "# if VideoPath.parent.joinpath('Tracking_params.npy').exists() is True:\n",
    "#     choice = input(\"File already exists! Overwrite? [y/n]\")\n",
    "\n",
    "#     if choice =='n':\n",
    "#         print('File unchanged.')\n",
    "\n",
    "#     elif choice =='y':\n",
    "#         np.save(VideoPath.parent.joinpath('Tracking_params.npy').as_posix(), params)\n",
    "#         print('File updated.')\n",
    "\n",
    "#     else: print('invalid input')\n",
    "\n",
    "# else:\n",
    "#     np.save(VideoPath.parent.joinpath('Tracking_params.npy').as_posix(), params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"param1\": param1,\n",
    "    \"param2\": param2,\n",
    "    \"minrad\": minrad,\n",
    "    \"maxrad\": maxrad,\n",
    "    \"dp\": dp,\n",
    "    \"mindist\": mindist,\n",
    "}\n",
    "\n",
    "checksave(\n",
    "    path=VideoPath.parent.joinpath(\"Tracking_params.npy\"),\n",
    "    object=\"parameter\",\n",
    "    file=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Track the ball in entire video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = np.load(\n",
    "    VideoPath.parent.joinpath(\"Tracking_params.npy\").as_posix(), allow_pickle=True\n",
    ")\n",
    "\n",
    "param1 = params.item().get(\"param1\")\n",
    "param2 = params.item().get(\"param2\")\n",
    "minrad = params.item().get(\"minrad\")\n",
    "maxrad = params.item().get(\"maxrad\")\n",
    "dp = params.item().get(\"dp\")\n",
    "mindist = params.item().get(\"mindist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "ballpos = []\n",
    "\n",
    "\n",
    "# Hough circles parameters to tune\n",
    "# param1 = 120\n",
    "# param2 = 45\n",
    "# minrad = 5\n",
    "# maxrad = 20\n",
    "# dp = 1.5\n",
    "# mindist = 500\n",
    "\n",
    "# Old: dp = 2 param2 = 50\n",
    "\n",
    "# Counter for failed detections\n",
    "fails = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read()  # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "        cropped = im_full_gray[cropping_parameters[0] : cropping_parameters[1], :]\n",
    "\n",
    "        # filtered = cv2.medianBlur(cropped, 5)\n",
    "        filtered = cv2.GaussianBlur(cropped, (9, 9), 0)\n",
    "\n",
    "        # rows = filt.shape[0]\n",
    "        circles = cv2.HoughCircles(\n",
    "            filtered,\n",
    "            cv2.HOUGH_GRADIENT,\n",
    "            dp=dp,\n",
    "            minDist=mindist,\n",
    "            param1=param1,\n",
    "            param2=param2,\n",
    "            minRadius=minrad,\n",
    "            maxRadius=maxrad,\n",
    "        )\n",
    "\n",
    "        out = cv2.cvtColor(cropped, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "\n",
    "                ballpos.append(center)\n",
    "\n",
    "                # circle center\n",
    "                cv2.circle(out, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                cv2.circle(out, center, radius, (255, 0, 255), 3)\n",
    "        elif len(ballpos) > 0:\n",
    "            fails += 1\n",
    "            ballpos.append(ballpos[-1])\n",
    "            cv2.circle(out, ballpos[-1], 1, (0, 0, 255), 3)\n",
    "            cv2.circle(out, center, radius, (0, 0, 255), 3)\n",
    "\n",
    "        # if len(ballpos) > 1:\n",
    "        #     if np.absolute(ballpos[-1][1] - ballpos[-2][1]) > 25:\n",
    "        #         ballpos_corr.append(ballpos[-2])\n",
    "        #         cv2.circle(out, ballpos_corr[-1], 1, (0, 255, 0), 3)\n",
    "        #         cv2.circle(out, center, radius, (0, 255, 0), 3)\n",
    "        #     else:\n",
    "        #         ballpos_corr.append(ballpos[-1])\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(\n",
    "            img=out,\n",
    "            text=str(i) + \"/\" + str(TotFrame),\n",
    "            color=(255, 0, 0),\n",
    "            org=(0, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.3,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"detected circles\", out)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print(\n",
    "    \"Parameters test finished. Detection success: \"\n",
    "    + str(((TotFrame - fails) / TotFrame) * 100)\n",
    "    + \"%.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If there are bad chunks of video, I should note them and adjust hough parameters to sucessfully track the ball in those chunks, then re-run the whole video."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could also save notes on each video as txt during tracking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis arena in particular : change param2 to 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VideoPath.parent.joinpath(\"notes.txt\").as_posix(), \"w\") as f:\n",
    "    f.write(\"Fly did not manage to push the ball to the end of the track.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "131k, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2time(131000, 80, timeformat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Check tracking quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this part, ball position over time is checked for any aberration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(ballpos)\n",
    "# plt.plot(list(filter(lambda item: item is not None, ballpos[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all second values of ballpos tuples\n",
    "ballpos_y = [i[1] for i in ballpos]\n",
    "cutoff = 0.01  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "ysmooth = butter_lowpass_filter(ballpos_y, cutoff, order)\n",
    "\n",
    "plt.plot(ysmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Save Ball positions in a dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trackresults = {\n",
    "    \"frame\": list(range(1, len(ballpos) + 1)),\n",
    "    \"xpos\": list(map(lambda x: x[0], ballpos)),\n",
    "    \"ypos\": list(map(lambda x: x[1], ballpos)),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(trackresults)\n",
    "\n",
    "df.to_csv(VideoPath.parent.joinpath(\"BallPositions.csv\").as_posix(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : add adaptive equalization to the pipeline to account for edges videos that are not well lit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive equalization for edge arenas\n",
    "\n",
    "Arenas 1 and 6 can be hard to track due to heterogeneous illumination. Here we test the effect of adaptive equalization on the tracking quality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial load and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a difficult video\n",
    "VideoPath = Path(r'/mnt/labserver/DURRIEU_Matthias/Experimental_data/Optogenetics/Optobot/MultiMazeBiS_Steel15_Wax/Starved_noWater_MagnetBlock/221130/093728_s0a0_p0-0/Arena6/Arena6.mp4')\n",
    "TrimmedPath = Path(r'/mnt/labserver/DURRIEU_Matthias/Experimental_data/Optogenetics/Optobot/MultiMazeBiS_Steel15_Wax/Starved_noWater_MagnetBlock/221130/093728_s0a0_p0-0/Arena6/Arena6_Trimmed.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "for i in range(1):\n",
    "    success, im_full = vidcap.read()\n",
    "\n",
    "im_full_gray = cv2.cvtColor(im_full, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#hv.Image(im_full_gray)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(im_full_gray, cmap='gray', vmin=0, vmax=255); # semicolon removes print of matplotlib object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "cropping_parameters = (150,710)\n",
    "cropped = im_full_gray[cropping_parameters[0]:cropping_parameters[1],:]\n",
    "# Note that this is arbitrary but shouldn't move from one arena to the other.\n",
    "# 120:650 was chosen for previous videos, here 155:685 is better aligned with arenas\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(cropped, cmap='gray', vmin=0, vmax=255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksave(VideoPath.parent.joinpath('Cropping_params.npy'), object='parameter', file=cropping_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply adaptive equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0,\n",
    "                        tileGridSize=(8,8))\n",
    "im_full_gray_clahe = clahe.apply(im_full_gray,)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im_full_gray, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_full_gray_clahe, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Equalized')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ball tracking quality on video samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vidcap = cv2.VideoCapture(TrimmedPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "\n",
    "# Hough circles parameters to tune\n",
    "param1=255\n",
    "param2=23\n",
    "minrad=5\n",
    "maxrad=20\n",
    "\n",
    "# Counter for failed detections\n",
    "fails = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read() # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "        cropped = im_full_gray[cropping_parameters[0]:cropping_parameters[1],:]\n",
    "\n",
    "        filtered = cv2.medianBlur(cropped,5)\n",
    "\n",
    "        #rows = filt.shape[0]\n",
    "        circles = cv2.HoughCircles(filtered, cv2.HOUGH_GRADIENT, 1, 125,\n",
    "                                   param1=param1, param2=param2,\n",
    "                                   minRadius=minrad, maxRadius=maxrad)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "                # circle center\n",
    "                cv2.circle(cropped, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                #cv2.circle(cropped, center, radius, (255, 0, 255), 3)\n",
    "        else: fails += 1\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(img=cropped, text=str(i)+'/'+str(TotFrame), color=(255,0,0), org=(0,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.3, thickness=1, lineType=cv2.LINE_AA,)\n",
    "        cv2.imshow(\"detected circles\", cropped)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print('Parameters test finished. Detection success for original: ' + str(((TotFrame-fails)/TotFrame)*100) + '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vidcap = cv2.VideoCapture(TrimmedPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "\n",
    "# Hough circles parameters to tune\n",
    "param1=255\n",
    "param2=23\n",
    "minrad=5\n",
    "maxrad=20\n",
    "\n",
    "# Counter for failed detections\n",
    "fails = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read() # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "        \n",
    "        im_full_gray_clahe = clahe.apply(im_full_gray,)\n",
    "        \n",
    "        cropped = im_full_gray_clahe[cropping_parameters[0]:cropping_parameters[1],:]\n",
    "\n",
    "        filtered = cv2.medianBlur(cropped,5)\n",
    "\n",
    "        #rows = filt.shape[0]\n",
    "        circles = cv2.HoughCircles(filtered, cv2.HOUGH_GRADIENT, 1, 125,\n",
    "                                   param1=param1, param2=param2,\n",
    "                                   minRadius=minrad, maxRadius=maxrad)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "                # circle center\n",
    "                cv2.circle(cropped, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                #cv2.circle(cropped, center, radius, (255, 0, 255), 3)\n",
    "        else: fails += 1\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(img=cropped, text=str(i)+'/'+str(TotFrame), color=(255,0,0), org=(0,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.3, thickness=1, lineType=cv2.LINE_AA,)\n",
    "        cv2.imshow(\"detected circles\", cropped)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print('Parameters test finished. Detection success for equalized: ' + str(((TotFrame-fails)/TotFrame)*100) + '%.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Went from 74.22% to 80.85% of successfully tracked frames. Now test on whole video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpos = []\n",
    "fails = 0\n",
    "\n",
    "Vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read() # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "        \n",
    "        im_full_gray_clahe = clahe.apply(im_full_gray,)\n",
    "        \n",
    "        cropped = im_full_gray_clahe[cropping_parameters[0]:cropping_parameters[1],:]\n",
    "\n",
    "        filtered = cv2.medianBlur(cropped,5)\n",
    "\n",
    "        circles = cv2.HoughCircles(filtered, cv2.HOUGH_GRADIENT, 1, 125,\n",
    "                                   param1=param1, param2=param2,\n",
    "                                   minRadius=minrad, maxRadius=maxrad)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "                ballpos.append(center)\n",
    "                # circle center\n",
    "                cv2.circle(cropped, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                #cv2.circle(cropped, center, radius, (255, 0, 255), 3)\n",
    "        elif len(ballpos) > 0:\n",
    "            fails += 1\n",
    "            ballpos.append(ballpos[-1])\n",
    "        else:\n",
    "            fails += 1\n",
    "            ballpos.append((None, None))\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(img=cropped, text=str(i)+'/'+str(TotFrame), color=(255,0,0), org=(0,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.3, thickness=1, lineType=cv2.LINE_AA,)\n",
    "        cv2.imshow(\"detected circles\", cropped)\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print('Tracking finished. Detection success on equalized video: ' + str(((TotFrame-fails)/TotFrame)*100) + '%.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success : 91.64 for equalized. Let's try the other one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this case, false positives were detected at the bottleneck. Either change cropping parameters to avoid this area or post process ball position signal to remove false positives. Eventually, implement the outlier removal directly in the ball tracking algorithm. \n",
    "> I could probably also detect specific recurring y positions that seem unrealistically low and replace them by previous frame value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballposCorr1 = ballpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpos = []\n",
    "fails = 0\n",
    "\n",
    "Vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "TotFrame = int(Vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "last = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = Vidcap.read() # Grab frame\n",
    "    this = Vidcap.get(1)\n",
    "    if ret:\n",
    "\n",
    "        im_full_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "        cropped = im_full_gray[cropping_parameters[0]:cropping_parameters[1],:]\n",
    "\n",
    "        filtered = cv2.medianBlur(cropped,5)\n",
    "\n",
    "        circles = cv2.HoughCircles(filtered, cv2.HOUGH_GRADIENT, 1, 125,\n",
    "                                   param1=param1, param2=param2,\n",
    "                                   minRadius=minrad, maxRadius=maxrad)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "                ballpos.append(center)\n",
    "                # circle center\n",
    "                cv2.circle(cropped, center, 1, (255, 0, 255), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                #cv2.circle(cropped, center, radius, (255, 0, 255), 3)\n",
    "        elif len(ballpos) > 0:\n",
    "            fails += 1\n",
    "            ballpos.append(ballpos[-1])\n",
    "        else:\n",
    "            fails += 1\n",
    "            ballpos.append((None, None))\n",
    "\n",
    "        i = int(this)\n",
    "\n",
    "        cv2.putText(img=cropped, text=str(i)+'/'+str(TotFrame), color=(255,0,0), org=(0,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.3, thickness=1, lineType=cv2.LINE_AA,)\n",
    "        cv2.imshow(\"detected circles\", cropped)\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "Vidcap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "print('Tracking finished. Detection success: ' + str(((TotFrame-fails)/TotFrame)*100) + '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpos_raw = ballpos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare both ball positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ballposCorr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ballpos_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Supplementary 1: Understand how Hough circles parameters 1 and 2 work\n",
    "\n",
    "Before performing the Hough transform, opencv's Hough circles function performs a canny edge detection. This algorithm uses the same parameters 1 and 2 and can be performed independently to see how frames would look like during processing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![parameters 1 and 2 explanation](/home/durrieu/Tracking_Analysis/Tracktor/Pictures/hysteresis.jpg)\n",
    "\n",
    "In this image parameter 1 is maxVal, it is the threshold of gray values above which any pixel should be considered an edge. Conversely, parameter 2 is minVal. Any value below parameter 2 should be considered as not edge.\n",
    "\n",
    "Once these values are set, edges are detected according to their connectivity. In this example, A is considered sure edge. B and C are both within the right threshold values but while C is connected to a sure edge, B isn't. B will not be considered as edge while C will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MinVal = 90\n",
    "MaxVal = 150\n",
    "\n",
    "cannyedge = cv2.Canny(im_full_gray, MinVal, MaxVal)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im_full_gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cannyedge, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"Canny edge detection\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that in Canny syntax, parameter 1 and 2 are in the 'minval to maxval' order, while in the HoughCircles syntax it's the opposite."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea0496e7bdb7df2fec0585b1e78371aa45021b70d7521719559543ff2bbe48cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
