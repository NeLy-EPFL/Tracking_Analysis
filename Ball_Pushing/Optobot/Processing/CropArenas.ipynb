{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made for detecting arena edges and cropping videos accordingly. It is focused on 6 corridors pushing arenas and has not been adapted to crop top and bottom  of the arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "import more_itertools as mit\n",
    "from pathlib import Path\n",
    "import os\n",
    "from scipy import signal\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh',\n",
    "             #'matplotlib',\n",
    "             )\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load video path and get first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoPath = pathlib.Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/Optogenetics/Optobot/MultiMaze_15stepped_gated_bowtie/Starved_noWater/230209/111026_s0a0_p0-0/MultiMaze_15stepped_gated_bowtie_Starved_noWater_p0-0_80fps.mp4\"\n",
    ")\n",
    "vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "for i in range(1):\n",
    "    success, im_full = vidcap.read()\n",
    "\n",
    "im_full_gray = cv2.cvtColor(im_full, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_full_gray, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display gray values profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = im_full_gray.sum(axis=0)\n",
    "\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=40,\n",
    "    height=35_000,\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(cols)))\n",
    "PeaksPos = (x[peaks[0]], cols[peaks[0]])\n",
    "hv.Histogram(cols).opts(tools=[\"hover\"]) * hv.Points(PeaksPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(peaks[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate arenas zones coordinates and add tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ArenaList = []\n",
    "for i in range(0, len(peaks[0])):\n",
    "    if (i % 2) == 0:\n",
    "        ArenaList.append(list(range(peaks[0][i] - 40, peaks[0][i + 1] + 40)))\n",
    "\n",
    "# Visual test if crop was successful\n",
    "plt.imshow(im_full_gray[:, ArenaList[5]], cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make folder in which each cropped video will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 7):\n",
    "    os.mkdir(VideoPath.parent.joinpath(\"Arena\" + str(n)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build videowriters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "\n",
    "# Writer parameters\n",
    "codec = \"mp4v\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "A1 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena1/Arena1.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[0]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "A2 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena2/Arena2.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[1]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A3 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena3/Arena3.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[2]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A4 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena4/Arena4.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[3]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A5 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena5/Arena5.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[4]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A6 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena6/Arena6.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=80.0,\n",
    "    frameSize=(len(ArenaList[5]), int(cap.read()[1].shape[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "scaling = 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write cropped videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Grab frame\n",
    "    this = cap.get(1)\n",
    "    if ret == True:\n",
    "\n",
    "        # frame = cv2.resize(frame, None, fx=scaling, fy=scaling,\n",
    "        # interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        ImGr = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "        # (height, width) = frame.shape[:2]\n",
    "\n",
    "        Arena1 = frame[:, ArenaList[0]]\n",
    "        Arena2 = frame[:, ArenaList[1]]\n",
    "        Arena3 = frame[:, ArenaList[2]]\n",
    "        Arena4 = frame[:, ArenaList[3]]\n",
    "        Arena5 = frame[:, ArenaList[4]]\n",
    "        Arena6 = frame[:, ArenaList[5]]\n",
    "\n",
    "        # Display each arena in a dedicated window (here it will be replaced by cv2 video writer in the end\n",
    "        # cv2.imshow('Arena1', Arena1)\n",
    "        # cv2.imshow('Arena2', Arena2)\n",
    "        # cv2.imshow('Arena3', Arena3)\n",
    "        # cv2.imshow('Arena4', Arena4)\n",
    "        # cv2.imshow('Arena5', Arena5)\n",
    "        # cv2.imshow('Arena6', Arena6)\n",
    "\n",
    "        A1.write(Arena1)\n",
    "        A2.write(Arena2)\n",
    "        A3.write(Arena3)\n",
    "        A4.write(Arena4)\n",
    "        A5.write(Arena5)\n",
    "        A6.write(Arena6)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "cap.release()\n",
    "A1.release()\n",
    "A2.release()\n",
    "A3.release()\n",
    "A4.release()\n",
    "A5.release()\n",
    "A6.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Code speed is way higher if cropped videos are not displays during the process. If you want to display them, uncomment the \"cv2.imshow\" lines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop an horizontal layout arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoPath = pathlib.Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/TrainingVideo/multiMazeTrimmed1.mp4\"\n",
    ")\n",
    "vidcap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "for i in range(1):\n",
    "    success, im_full = vidcap.read()\n",
    "\n",
    "im_full_gray = cv2.cvtColor(im_full, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_full_gray, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = im_full_gray.sum(axis=1)\n",
    "\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = signal.find_peaks(\n",
    "    rows,\n",
    "    distance=40,\n",
    "    height=30_000,\n",
    ")\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0, len(rows)))\n",
    "PeaksPos = (x[peaks[0]], rows[peaks[0]])\n",
    "hv.Histogram(rows).opts(tools=[\"hover\"]) * hv.Points(PeaksPos).opts(\n",
    "    color=\"orange\", tools=[\"hover\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interestingly when looking at x values instead of y, the information on frame, timing and all displayed on top left produces a sharp peak that needs to be removed before cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklocs = peaks[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ArenaList = []\n",
    "for i in range(0, len(peaklocs)):\n",
    "    if (i % 2) == 0:\n",
    "        ArenaList.append(list(range(peaklocs[i] - 40, peaklocs[i + 1] + 40)))\n",
    "\n",
    "# Visual test if crop was successful\n",
    "plt.imshow(im_full_gray[ArenaList[5], :], cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArenaList[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save cropping parameters for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first and last value of each element in ArenaList\n",
    "CroppingParams = []\n",
    "for i in range(0, len(ArenaList)):\n",
    "    CroppingParams.append([ArenaList[i][0], ArenaList[i][-1]])\n",
    "\n",
    "CroppingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CroppingParams[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cropping parameters for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksave(\n",
    "    path=VideoPath.parent.joinpath(\"Arena_indices.npy\"),\n",
    "    object=\"parameter\",\n",
    "    file=CroppingParams,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 7):\n",
    "    os.mkdir(VideoPath.parent.joinpath(\"Arena\" + str(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VideoPath.as_posix())\n",
    "\n",
    "fps = 40.0\n",
    "\n",
    "# Writer parameters\n",
    "codec = \"mp4v\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "A1 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena1/Arena1.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[0])),\n",
    "    isColor=True,\n",
    ")\n",
    "A2 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena2/Arena2.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[1])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A3 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena3/Arena3.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[2])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A4 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena4/Arena4.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[3])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A5 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena5/Arena5.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[4])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "A6 = cv2.VideoWriter(\n",
    "    filename=VideoPath.parent.joinpath(\"Arena6/Arena6.mp4\").as_posix(),\n",
    "    fourcc=fourcc,\n",
    "    fps=fps,\n",
    "    frameSize=(int(cap.read()[1].shape[0]), len(ArenaList[5])),\n",
    "    isColor=True,\n",
    ")\n",
    "\n",
    "scaling = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Grab frame\n",
    "    this = cap.get(1)\n",
    "    if ret == True:\n",
    "\n",
    "        # frame = cv2.resize(frame, None, fx=scaling, fy=scaling,\n",
    "        # interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        ImGr = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
    "        # (height, width) = frame.shape[:2]\n",
    "\n",
    "        Arena1 = frame[ArenaList[0], :]\n",
    "        Arena2 = frame[ArenaList[1], :]\n",
    "        Arena3 = frame[ArenaList[2], :]\n",
    "        Arena4 = frame[ArenaList[3], :]\n",
    "        Arena5 = frame[ArenaList[4], :]\n",
    "        Arena6 = frame[ArenaList[5], :]\n",
    "\n",
    "        # Display each arena in a dedicated window (here it will be replaced by cv2 video writer in the end\n",
    "        # cv2.imshow('Arena1', Arena1)\n",
    "        # cv2.imshow('Arena2', Arena2)\n",
    "        # cv2.imshow('Arena3', Arena3)\n",
    "        # cv2.imshow('Arena4', Arena4)\n",
    "        # cv2.imshow('Arena5', Arena5)\n",
    "        # cv2.imshow('Arena6', Arena6)\n",
    "\n",
    "        A1.write(Arena1)\n",
    "        A2.write(Arena2)\n",
    "        A3.write(Arena3)\n",
    "        A4.write(Arena4)\n",
    "        A5.write(Arena5)\n",
    "        A6.write(Arena6)\n",
    "\n",
    "        # Display a progress bar\n",
    "        sys.stdout.write(\"Frame: \" + str(this) + \" / \" + str(cap.get(7)) + \"\\r\")\n",
    "        # sys.stdout.write(\"Frame: \" + str(this) + \" / \" + str(cap.get(7)) + \" - \" + str(round(this/cap.get(7)*100,2)) + \"%\\r\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            exit(0)\n",
    "    if last >= this:\n",
    "        break\n",
    "    last = this\n",
    "cap.release()\n",
    "A1.release()\n",
    "A2.release()\n",
    "A3.release()\n",
    "A4.release()\n",
    "A5.release()\n",
    "A6.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check frame accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check progress accuracy by comparing key frames between original and cropped videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackingAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a10dcd6c5ba4f841b08c213cb10df2391c63c1275edb19c558150bb17ce2d2c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
