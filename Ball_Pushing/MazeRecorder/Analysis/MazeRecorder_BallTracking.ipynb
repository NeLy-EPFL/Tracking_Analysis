{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the folders I want to use\n",
    "# For instance, I want to use the folders that have the \"FeedingState\" in the name\n",
    "\n",
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "    # Only use the folders that have 'feedingstate' and 'tracked' but not 'dark' in the name\n",
    "    #if \"feedingstate\" in minfolder and \"tracked\" in minfolder and \"dark\" not in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the path to the data folder\n",
    "data_folder = Path('/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos')\n",
    "\n",
    "# Build a dataframe that will store the ball y positions and the arena and corridor numbers as metadata\n",
    "Dataset = pd.DataFrame(columns=[\"Fly\", \"yball\", \"arena\", \"corridor\", \"start\", \"end\"])\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "Flynum = 0\n",
    "# Loop over all the folders that don't have \"Dark\" in the name\n",
    "for folder in Folders:\n",
    "    print(f\"Adding experiment {folder} to the dataset...\")\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "        \n",
    "        print (metadata_dict)\n",
    "        \n",
    "    for file in folder.glob(\"**/*.analysis.h5\"):\n",
    "        #print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            dset_names = list(f.keys())\n",
    "            locations = f[\"tracks\"][:].T\n",
    "            node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "        locations.shape\n",
    "        \n",
    "        if \"Flipped\" in folder.name:\n",
    "            yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "\n",
    "        else:\n",
    "            yball : np.ndarray = locations[:, :, 1, :]\n",
    "        \n",
    "        # Get the filename from the path\n",
    "        foldername = folder.name\n",
    "\n",
    "        # Get the arena and corridor numbers from the parent (corridor) and grandparent (arena) folder names\n",
    "        arena = file.parent.parent.name\n",
    "        corridor = file.parent.name\n",
    "        \n",
    "        # Get the metadata for this arena\n",
    "        arena_key = arena.capitalize()\n",
    "        arena_metadata = {var: pd.Categorical([metadata_dict[var][arena_key]]) for var in metadata_dict}\n",
    "        \n",
    "        Flynum += 1\n",
    "        \n",
    "        # Load the start and end coordinates from coordinates.npy\n",
    "        start, end = np.load(file.parent / 'coordinates.npy')\n",
    "        \n",
    "        # Store the ball y positions, start and end coordinates, and the arena and corridor numbers as metadata\n",
    "        data = {\"Fly\": pd.Categorical([\"Fly\" + str(Flynum)]),\n",
    "                \"yball\": [list(yball[:, 0, 0])], \n",
    "                \"experiment\": pd.Categorical([foldername]),\n",
    "                \"arena\": pd.Categorical([arena]), \n",
    "                \"corridor\": pd.Categorical([corridor]),\n",
    "                \"start\": pd.Categorical([start]),\n",
    "                \"end\": pd.Categorical([end])}\n",
    "        data.update(arena_metadata)\n",
    "\n",
    "        # Use pandas.concat instead of DataFrame.append\n",
    "        Dataset = pd.concat([Dataset, pd.DataFrame(data)], ignore_index=True) \n",
    "\n",
    "# Explode yball column to have one row per timepoint\n",
    "\n",
    "#Dataset.drop(columns=[\"Genotye\", \"Date\",], inplace=True)\n",
    "\n",
    "Dataset = Dataset.explode('yball')\n",
    "Dataset['yball'] = Dataset['yball'].astype(float)\n",
    "\n",
    "print('Computing yball relative to start...')\n",
    "# Compute yball_relative relative to start\n",
    "Dataset['yball_relative'] = abs(Dataset['yball'] - Dataset['start'])\n",
    "\n",
    "# Fill missing values using linear interpolation\n",
    "Dataset['yball_relative'] = Dataset['yball_relative'].interpolate(method='linear')\n",
    "\n",
    "Dataset.drop(columns=[\"yball\",], inplace=True)\n",
    "\n",
    "\n",
    "# Filter parameters\n",
    "cutoff = 0.0015  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "#Dataset['yball_smooth'] = butter_lowpass_filter(Dataset['yball_relative'], cutoff, order)\n",
    "print('Filtering yball relative to start...')\n",
    "Dataset['yball_SG'] = savgol_lowpass_filter(Dataset['yball_relative'], 221, 1)\n",
    "\n",
    "print('Removing yball relative to start...')\n",
    "Dataset.drop(columns=[\"yball_relative\",], inplace=True)\n",
    "\n",
    "print('Defining frame and time columns...')\n",
    "Dataset[\"Frame\"] = Dataset.groupby(\"Fly\").cumcount()\n",
    "\n",
    "Dataset[\"time\"] = Dataset[\"Frame\"] / 30\n",
    "\n",
    "# Remove the original yball column\n",
    "\n",
    "print('Removing Frame column...')\n",
    "Dataset.drop(columns=[\"Frame\",], inplace=True)\n",
    "\n",
    "print('Resetting index...')\n",
    "Dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parameters\n",
    "window_length = 301\n",
    "polyorder = 1\n",
    "\n",
    "Dataset['yball_SG'] = savgol_lowpass_filter(Dataset['yball_relative'], 93, 1)\n",
    "Dataset['yball_SG2'] = savgol_lowpass_filter(Dataset['yball_relative'], 151, 1)\n",
    "Dataset['yball_SG3'] = savgol_lowpass_filter(Dataset['yball_relative'], 191, 1)\n",
    "Dataset['yball_SG4'] = savgol_lowpass_filter(Dataset['yball_relative'], 201, 1)\n",
    "Dataset['yball_SG5'] = savgol_lowpass_filter(Dataset['yball_relative'], 221, 1) # This is the one i'll go with for now\n",
    "# Filter parameters\n",
    "# cutoff = 0.01  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "# order = 1 \n",
    "# Dataset['yball_SG_butter'] = butter_lowpass_filter(Dataset['yball_SG'], cutoff, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_SG = ((Dataset['yball_SG'] - Dataset['yball_relative']) ** 2).mean()\n",
    "mse_SG2 = ((Dataset['yball_SG2'] - Dataset['yball_relative']) ** 2).mean()\n",
    "mse_SG3 = ((Dataset['yball_SG3'] - Dataset['yball_relative']) ** 2).mean()\n",
    "mse_SG4 = ((Dataset['yball_SG4'] - Dataset['yball_relative']) ** 2).mean()\n",
    "mse_SG5 = ((Dataset['yball_SG5'] - Dataset['yball_relative']) ** 2).mean()\n",
    "\n",
    "print(mse_SG, mse_SG2, mse_SG3, mse_SG4, mse_SG5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mutual_info_score, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "window_lengths = range(3, 103, 10)\n",
    "mae_values = []\n",
    "r2_values = []\n",
    "mi_values = []\n",
    "\n",
    "for window_length in window_lengths:\n",
    "    # Apply the Savitzky-Golay filter with the current window_length\n",
    "    y = savgol_lowpass_filter(Dataset['yball_relative'], window_length, polyorder=1)\n",
    "    \n",
    "    # Compute the MAE between the filtered signal and the raw data\n",
    "    mae = np.abs(y - Dataset['yball_relative']).mean()\n",
    "    mae_values.append(mae)\n",
    "    \n",
    "    # Compute the R-squared between the filtered signal and the raw data\n",
    "    r2 = r2_score(Dataset['yball_relative'], y)\n",
    "    r2_values.append(r2)\n",
    "    \n",
    "    # Compute the mutual information between the filtered signal and the raw data\n",
    "    mi = mutual_info_score(y, Dataset['yball_relative'])\n",
    "    mi_values.append(mi)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "axs[0].plot(window_lengths, mae_values)\n",
    "axs[0].set_title('MAE')\n",
    "axs[1].plot(window_lengths, r2_values)\n",
    "axs[1].set_title('R-squared')\n",
    "axs[2].plot(window_lengths, mi_values)\n",
    "axs[2].set_title('Mutual Information')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the minimum MAE value\n",
    "best_mae_index = np.argmin(mae_values)\n",
    "# Find the corresponding window_length value\n",
    "best_mae_window_length = window_lengths[best_mae_index]\n",
    "\n",
    "# Find the index of the maximum R-squared value\n",
    "best_r2_index = np.argmax(r2_values)\n",
    "# Find the corresponding window_length value\n",
    "best_r2_window_length = window_lengths[best_r2_index]\n",
    "\n",
    "# Find the index of the maximum mutual information value\n",
    "best_mi_index = np.argmax(mi_values)\n",
    "# Find the corresponding window_length value\n",
    "best_mi_window_length = window_lengths[best_mi_index]\n",
    "\n",
    "print(f'Best MAE: {best_mae_window_length}')\n",
    "print(f'Best R-squared: {best_r2_window_length}')\n",
    "print(f'Best Mutual Information: {best_mi_window_length}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_estimate = np.std(Dataset['yball_relative'] - Dataset['yball_SG'])\n",
    "snr_SG = 10 * np.log10(np.mean(Dataset['yball_SG'] ** 2) / noise_estimate ** 2)\n",
    "\n",
    "noise_estimate = np.std(Dataset['yball_relative'] - Dataset['yball_SG2'])\n",
    "snr_SG2 = 10 * np.log10(np.mean(Dataset['yball_SG2'] ** 2) / noise_estimate ** 2)\n",
    "\n",
    "noise_estimate = np.std(Dataset['yball_relative'] - Dataset['yball_SG3'])\n",
    "snr_SG3 = 10 * np.log10(np.mean(Dataset['yball_SG3'] ** 2) / noise_estimate ** 2)\n",
    "\n",
    "noise_estimate = np.std(Dataset['yball_relative'] - Dataset['yball_SG4'])\n",
    "snr_SG4 = 10 * np.log10(np.mean(Dataset['yball_SG4'] ** 2) / noise_estimate ** 2)\n",
    "\n",
    "noise_estimate = np.std(Dataset['yball_relative'] - Dataset['yball_SG5'])\n",
    "snr_SG5 = 10 * np.log10(np.mean(Dataset['yball_SG5'] ** 2) / noise_estimate ** 2)\n",
    "\n",
    "print(snr_SG, snr_SG2, snr_SG3, snr_SG4, snr_SG5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on filtering: \n",
    "\n",
    "\n",
    "\n",
    "AL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parameters\n",
    "cutoff = 0.01  # desired cutoff frequency of the filter, Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "rp = 2  # maximum ripple allowed in passband (dB)\n",
    "\n",
    "Dataset['yball_C'] = cheby1_lowpass_filter(Dataset['yball_relative'], cutoff, order, rp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parameters\n",
    "cutoff = 0.0015  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "\n",
    "\n",
    "Dataset['yball_smooth'] = butter_lowpass_filter(Dataset['yball_relative'], cutoff, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def median_filter(data, kernel_size):\n",
    "    # Apply the median filter\n",
    "    y = signal.medfilt(data, kernel_size)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def morphological_filter(data, structure):\n",
    "    # Apply the morphological filter\n",
    "    y = ndimage.grey_opening(data, structure=structure)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "def adaptive_moving_average_filter(data, cutoff, order, window_size):\n",
    "    # Apply the Butterworth low-pass filter\n",
    "    y = butter_lowpass_filter(data, cutoff, order)\n",
    "    # Compute the local standard deviation of the signal\n",
    "    std = np.std(y)\n",
    "    # Compute the adaptive moving average window size\n",
    "    window = int(np.maximum(1, np.minimum(window_size, np.median(std / np.abs(y)))))\n",
    "    # Apply the adaptive moving average filter\n",
    "    y = np.convolve(y, np.ones(window) / window, mode='same')\n",
    "    return y\n",
    "\n",
    "\n",
    "# Filter parameters\n",
    "cutoff = 0.005  # desired cutoff frequency of the Butterworth filter, Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "window_size = 10  # maximum size of the moving average window\n",
    "\n",
    "Dataset['yball_smooth_adapt'] = adaptive_moving_average_filter(Dataset['yball_relative'], cutoff, order, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median filter parameters\n",
    "kernel_size = 21\n",
    "\n",
    "Dataset['yball_smooth_median'] = median_filter(Dataset['yball_relative'], kernel_size)\n",
    "\n",
    "# Morphological filter parameters\n",
    "structure = np.ones(21)\n",
    "\n",
    "Dataset['yball_smooth_morph'] = morphological_filter(Dataset['yball_relative'], structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Select the flies to plot\n",
    "flies_to_plot = ['Fly58']\n",
    "\n",
    "# Create an empty overlay\n",
    "overlay = hv.Overlay()\n",
    "\n",
    "# Plot the data for each fly\n",
    "for fly in flies_to_plot:\n",
    "    fly_data = Dataset[Dataset['Fly'] == fly]\n",
    "    yball_relative_curve = hv.Curve((fly_data['Frame'], fly_data['yball_relative']), label=f'{fly} yball_relative')\n",
    "    yball_smoothed_curve = hv.Curve((fly_data['Frame'], fly_data['yball_smooth']), label=f'{fly} yball_smooth')\n",
    "    # yball_smoothed_adapt = hv.Curve((fly_data['Frame'], fly_data['yball_smooth_adapt']), label=f'{fly} yball_smooth_adapt')\n",
    "    yball_sg_curve = hv.Curve((fly_data['Frame'], fly_data['yball_SG']), label=f'{fly} yball_SG')\n",
    "    # yball_sg2_curve = hv.Curve((fly_data['Frame'], fly_data['yball_SG2']), label=f'{fly} yball_SG2')\n",
    "    # yball_sg3_curve = hv.Curve((fly_data['Frame'], fly_data['yball_SG3']), label=f'{fly} yball_SG3')\n",
    "    # yball_sg4_curve = hv.Curve((fly_data['Frame'], fly_data['yball_SG4']), label=f'{fly} yball_SG4')\n",
    "    # yball_sg5_curve = hv.Curve((fly_data['Frame'], fly_data['yball_SG5']), label=f'{fly} yball_SG5')\n",
    "    #yball_sg_butter = hv.Curve((fly_data['Frame'], fly_data['yball_SG_butter']), label=f'{fly} yball_SG_butter')\n",
    "\n",
    "    #yball_smoothed_median = hv.Curve((fly_data['Frame'], fly_data['yball_smooth_median']), label=f'{fly} yball_smooth_median')\n",
    "    #yball_smoothed_morph = hv.Curve((fly_data['Frame'], fly_data['yball_smooth_morph']), label=f'{fly} yball_smooth_morph')\n",
    "    overlay *= yball_relative_curve * yball_sg_curve  * yball_smoothed_curve\n",
    "\n",
    "# Set the options for the plot\n",
    "overlay.opts(\n",
    "    opts.Curve(width=1500, height=1000, tools=['hover', 'box_zoom'], line_width=3)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "overlay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data head for these flies\n",
    "Dataset[Dataset['Fly'].isin(flies_to_plot)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values using linear interpolation\n",
    "Dataset['yball_relative'] = Dataset['yball_relative'].interpolate(method='linear')\n",
    "\n",
    "# Filter parameters\n",
    "cutoff = 0.01  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "Dataset['yball_smooth'] = butter_lowpass_filter(Dataset['yball_relative'], cutoff, order)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that we want to keep\n",
    "Dataset = Dataset[[\"Fly\", \"Genotype\", \"time\", \"yball_relative\", \"yball_smooth\", \"yball_SG\"]]\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of \"Fed\" with \"fed\" in the 'FeedingState' column\n",
    "Dataset[\"FeedingState\"] = Dataset[\"FeedingState\"].replace(\"Fed\", \"fed\")\n",
    "\n",
    "# Add \"flipped\" to the list of categories for the Orientation column\n",
    "Dataset['Orientation'] = Dataset['Orientation'].cat.add_categories(['flipped'])\n",
    "\n",
    "# If there is 'Flipped' in the foldername, replace the corresponding 'Orientation' with 'flipped'\n",
    "Dataset.loc[Dataset[\"experiment\"].str.contains(\"Flipped\"), \"Orientation\"] = \"flipped\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedDF_TNT = Dataset.groupby(['Genotype','time',])['yball_SG'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size for each Genotype group based on the number of individual flies\n",
    "sample_size = Dataset.groupby('Genotype')['Fly'].nunique()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the 'yball' column over time, colored by the 'Genotype' column\n",
    "sns.lineplot(data=GroupedDF_TNT, x='time', y='yball_SG', hue='Genotype', linewidth=1)\n",
    "\n",
    "# Invert the y-axis\n",
    "#plt.gca().invert_yaxis()\n",
    "\n",
    "# Modify the labels of the legend to include the sample size for each Genotype group\n",
    "legend = plt.legend()\n",
    "for text, genotype in zip(legend.texts, sample_size.index):\n",
    "    text.set_text(f'{genotype} (n = {sample_size[genotype]})')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference between consecutive yball_relative values for each fly\n",
    "Dataset['yball_relative_diff'] = Dataset.groupby('Fly')['yball_SG'].diff()\n",
    "\n",
    "# Compute the cumulative_push and cumulative_pull for each fly\n",
    "Dataset['cumulative_push'] = Dataset.apply(lambda x: x['yball_relative_diff'] if x['yball_relative_diff'] > 0 else 0, axis=1).groupby(Dataset['Fly']).cumsum()\n",
    "Dataset['cumulative_pull'] = Dataset.apply(lambda x: -x['yball_relative_diff'] if x['yball_relative_diff'] < 0 else 0, axis=1).groupby(Dataset['Fly']).cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by Genotype and time and compute the mean of the cumulative_push and cumulative_pull columns\n",
    "GroupedDF = Dataset.groupby(['Genotype', 'time'])[['cumulative_push', 'cumulative_pull']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative_push and cumulative_pull columns over time, colored by the Genotype column in two separate subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "sns.lineplot(data=GroupedDF, x='time', y='cumulative_push', hue='Genotype', linewidth=1, ax=axes[0])\n",
    "sns.lineplot(data=GroupedDF, x='time', y='cumulative_pull', hue='Genotype', linewidth=1, ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative_push and cumulative_pull over time for 3 randomly selected flies in 3 subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
    "for ax, fly in zip(axes, np.random.choice(Dataset['Fly'].unique(), 3)):\n",
    "    sns.lineplot(data=Dataset[Dataset['Fly'] == fly], x='time', y='cumulative_push', hue='Genotype', linewidth=1, ax=ax)\n",
    "    sns.lineplot(data=Dataset[Dataset['Fly'] == fly], x='time', y='cumulative_pull', hue='Genotype', linewidth=1, ax=ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the yball_relative_diff column for each fly over time each in their separate subplot, colored by the Genotype column\n",
    "g = sns.FacetGrid(data=Dataset, col='Fly', col_wrap=4, hue='Genotype', sharey=False, height=3, aspect=1.5)\n",
    "g.map(sns.lineplot, 'time', 'yball_relative', linewidth=1)\n",
    "g.set_titles('{col_name}')\n",
    "g.set_axis_labels('Time (s)', 'yball_relative')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of \"Fed\" with \"fed\" in the 'FeedingState' column\n",
    "Dataset[\"FeedingState\"] = Dataset[\"FeedingState\"].replace(\"Fed\", \"fed\")\n",
    "\n",
    "# Add \"flipped\" to the list of categories for the Orientation column\n",
    "Dataset['Orientation'] = Dataset['Orientation'].cat.add_categories(['flipped'])\n",
    "\n",
    "# If there is 'Flipped' in the foldername, replace the corresponding 'Orientation' with 'flipped'\n",
    "Dataset.loc[Dataset[\"experiment\"].str.contains(\"Flipped\"), \"Orientation\"] = \"flipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedDF = Dataset.groupby(['Period','FeedingState', 'time'])['yball_SG'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size for each Genotype group based on the number of individual flies\n",
    "sample_size = Dataset.groupby('Period','FeedingState')['Fly'].nunique()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the 'yball' column over time, colored by the 'Genotype' column\n",
    "sns.lineplot(data=GroupedDF_TNT, x='time', y='yball_SG', hue='Genotype', linewidth=1)\n",
    "\n",
    "# Invert the y-axis\n",
    "#plt.gca().invert_yaxis()\n",
    "\n",
    "# Modify the labels of the legend to include the sample size for each Genotype group\n",
    "legend = plt.legend()\n",
    "for text, genotype in zip(legend.texts, sample_size.index):\n",
    "    text.set_text(f'{genotype} (n = {sample_size[genotype]})')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a FacetGrid object with the 'Period' column as the row variable\n",
    "g = sns.FacetGrid(data=GroupedDF, row='Period')\n",
    "\n",
    "# Map a line plot of the 'yball_SG' column over time to each facet, with the hue set to 'FeedingState'\n",
    "g.map(sns.lineplot, 'time', 'yball_SG', 'FeedingState', linewidth=1)\n",
    "\n",
    "# Add a legend to the plot\n",
    "sample_size = Dataset.groupby(['Period','FeedingState'])['Fly'].nunique()\n",
    "legend = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "for text, genotype in zip(legend.texts, sample_size.index):\n",
    "    text.set_text(f'{genotype} (n = {sample_size[genotype]})')\n",
    "\n",
    "# Invert the y-axis of each Axes object in the FacetGrid\n",
    "for ax in g.axes.flat:\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = Dataset.groupby(['Period','FeedingState'])['Fly'].nunique()\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data\n",
    "data = GroupedDF\n",
    "\n",
    "# Create a list of periods\n",
    "periods = data['Period'].unique()\n",
    "\n",
    "# Create a figure with two subplots, one for each period\n",
    "fig, axes = plt.subplots(nrows=len(periods), figsize=(8, 6))\n",
    "\n",
    "# Set the same x and y limits for both subplots\n",
    "axes[0].set_xlim(data['time'].min(), data['time'].max())\n",
    "axes[0].set_ylim(data['yball_SG'].min(), data['yball_SG'].max())\n",
    "axes[1].set_xlim(data['time'].min(), data['time'].max())\n",
    "axes[1].set_ylim(data['yball_SG'].min(), data['yball_SG'].max())\n",
    "\n",
    "# Iterate over the periods and create a plot for each one\n",
    "for i, period in enumerate(periods):\n",
    "    # Subset the data by period\n",
    "    data_period = data[data['Period'] == period]\n",
    "    \n",
    "    # Create a line plot of 'yball_SG' over time, with the hue set to 'FeedingState'\n",
    "    sns.lineplot(data=data_period, x='time', y='yball_SG', hue='FeedingState', linewidth=1, ax=axes[i])\n",
    "    \n",
    "    # Set the title of the subplot\n",
    "    axes[i].set_title(period)\n",
    "    \n",
    "    # Invert the y-axis of the subplot\n",
    "    #axes[i].invert_yaxis()\n",
    "    \n",
    "    # Add a legend to the subplot\n",
    "    sample_size = Dataset.groupby(['Period','FeedingState'])['Fly'].nunique()\n",
    "    legend = axes[i].legend(title='FeedingState', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    for text, genotype in zip(legend.texts[1:], sample_size.loc[period].index):\n",
    "        text.set_text(f'{genotype} (n = {sample_size.loc[period, genotype]})')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_am.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Define data\n",
    "data = GroupedDF\n",
    "\n",
    "# Create a dataset\n",
    "ds = hv.Dataset(data, kdims=['time', 'Period'], vdims=['yball_SG', 'FeedingState'])\n",
    "\n",
    "# Create a grid of line plots\n",
    "grid = ds.to(hv.Curve, 'time', 'yball_SG', groupby=['Period', 'FeedingState']).opts(\n",
    "    opts.Curve(width=600, height=400, invert_yaxis=True, show_legend=True))\n",
    "\n",
    "# Add sample size to legend\n",
    "sample_size = Dataset.groupby(['Period','FeedingState'])['Fly'].nunique()\n",
    "#grid = grid.opts(opts.Curve(legend_limit=len(sample_size)))\n",
    "for i, genotype in enumerate(sample_size.index):\n",
    "    grid = grid.opts(opts.Curve(legend_title=f'{genotype} (n = {sample_size[genotype]})', #legend_position='right',\n",
    "                                show_legend=True), index=i)\n",
    "\n",
    "# Display the plot\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "# Define data\n",
    "data = GroupedDF\n",
    "\n",
    "# Create a grid of line plots\n",
    "grid = data.hvplot.line(\n",
    "    x='time', y='yball_SG', by='FeedingState', subplots=True, row='Period',\n",
    "    width=600, height=400, invert_yaxis=True, legend='top_right'\n",
    ")\n",
    "\n",
    "# Add sample size to legend\n",
    "sample_size = Dataset.groupby(['Period','FeedingState'])['Fly'].nunique()\n",
    "for i, genotype in enumerate(sample_size.index):\n",
    "    grid[i].legend.title = f'{genotype} (n = {sample_size[genotype]})'\n",
    "\n",
    "# Display the plot\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Define data\n",
    "data = GroupedDF\n",
    "\n",
    "# Create a dataset\n",
    "ds = hv.Dataset(data, kdims=['time', 'Period'], vdims=['yball_SG', 'FeedingState'])\n",
    "\n",
    "# Create a list of curves\n",
    "curves = []\n",
    "for period in data['Period'].unique():\n",
    "    for feeding_state in data['FeedingState'].unique():\n",
    "        curve = ds.select(Period=period, FeedingState=feeding_state).to(hv.Curve, 'time', 'yball_SG')\n",
    "        curve = curve.relabel(f'{period} - {feeding_state}')\n",
    "        curves.append(curve)\n",
    "\n",
    "# Overlay the curves\n",
    "overlay = hv.Overlay(curves).opts(\n",
    "    opts.Curve(width=600, height=400, show_legend=True))\n",
    "\n",
    "# Display the plot\n",
    "overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
