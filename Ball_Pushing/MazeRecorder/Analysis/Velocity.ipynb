{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to explore methods to compute flies velocity during ball pushing experiments using sleap based fly's tracking data. This is also the first notebook in which I experiment datasets handling with polars in later parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../..\")\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import iqplot\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "import bokeh.plotting\n",
    "\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of the directories containing the tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the folders I want to use. For instance, I want to use the folders that have the \"tnt\" in the name as I will explore velocities for different crossings with UAS-TNT. I'm also only getting flies tested in the afternoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the tracking data and generating the dataset\n",
    "\n",
    "In this part, we import the Metatadata .json file and the tracking data .h5 file. Then we compute smoothed fly y positions and generate time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.DataFrame()\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "Flynum = 0\n",
    "# Loop over all the folders that don't have \"Dark\" in the name\n",
    "for folder in Folders:\n",
    "    print(f\"Adding experiment {folder} to the dataset...\")\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "        \n",
    "        print (metadata_dict)\n",
    "        \n",
    "    for file in folder.glob(\"**/*tracked_fly*.analysis.h5\"):\n",
    "        \n",
    "        flypath = file\n",
    "        with h5py.File(flypath.as_posix(), \"r\") as f:\n",
    "            dset_names = list(f.keys())\n",
    "            fly_locs = f[\"tracks\"][:].T\n",
    "            node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "            \n",
    "    for file in folder.glob(\"**/*.analysis.h5\"):\n",
    "        #print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            dset_names = list(f.keys())\n",
    "            locations = f[\"tracks\"][:].T\n",
    "            node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "        locations.shape\n",
    "        \n",
    "        if \"Flipped\" in folder.name:\n",
    "            yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "\n",
    "        else:\n",
    "            yball : np.ndarray = locations[:, :, 1, :]    \n",
    "        yfly = fly_locs[:, :, 1, :]\n",
    "        \n",
    "        # Get the filename from the path\n",
    "        foldername = folder.name\n",
    "\n",
    "        # Get the arena and corridor numbers from the parent (corridor) and grandparent (arena) folder names\n",
    "        arena = file.parent.parent.name\n",
    "        corridor = file.parent.name\n",
    "        \n",
    "        # Get the metadata for this arena\n",
    "        arena_key = arena.capitalize()\n",
    "        arena_metadata = {var: pd.Categorical([metadata_dict[var][arena_key]]) for var in metadata_dict}\n",
    "        \n",
    "        Flynum += 1\n",
    "        \n",
    "        # Load the start and end coordinates from coordinates.npy\n",
    "        start, end = np.load(file.parent / 'coordinates.npy')\n",
    "        \n",
    "        # Store the ball y positions, start and end coordinates, and the arena and corridor numbers as metadata\n",
    "        data = {\"Fly\": pd.Categorical([\"Fly\" + str(Flynum)]),\n",
    "                #\"yfly\": [list(yfly[:, 0, 0])], \n",
    "                \"yball\": [list(yball[:, 0, 0])],\n",
    "                \"experiment\": pd.Categorical([foldername]),\n",
    "                \"arena\": pd.Categorical([arena]), \n",
    "                \"corridor\": pd.Categorical([corridor]),\n",
    "                \"start\": pd.Categorical([start]),\n",
    "                \"end\": pd.Categorical([end])}\n",
    "        data.update(arena_metadata)\n",
    "\n",
    "        # Use pandas.concat instead of DataFrame.append\n",
    "        Dataset = pd.concat([Dataset, pd.DataFrame(data)], ignore_index=True) \n",
    "\n",
    "# Explode yfly column to have one row per timepoint\n",
    "\n",
    "#Dataset.drop(columns=[\"Genotye\", \"Date\",], inplace=True)\n",
    "\n",
    "# Dataset = Dataset.explode('yfly')\n",
    "# Dataset['yfly'] = Dataset['yfly'].astype(float)\n",
    "\n",
    "Dataset = Dataset.explode('yball')\n",
    "Dataset['yball'] = Dataset['yball'].astype(float)\n",
    "\n",
    "# Filter parameters\n",
    "cutoff = 0.0015  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dataset['yfly_smooth'] = butter_lowpass_filter(Dataset['yfly_relative'], cutoff, order)\n",
    "# print('Filtering yfly relative to start...')\n",
    "# Dataset['yfly_SG'] = savgol_lowpass_filter(Dataset['yfly'], 221, 1)\n",
    "\n",
    "# Compute yball_relative relative to start\n",
    "Dataset['yball_relative'] = abs(Dataset['yball'] - Dataset['start'])\n",
    "\n",
    "# Fill missing values using linear interpolation\n",
    "Dataset['yball_relative'] = Dataset['yball_relative'].interpolate(method='linear')\n",
    "\n",
    "Dataset['yball_relative_SG'] = savgol_lowpass_filter(Dataset['yball_relative'], 221, 1)\n",
    "\n",
    "print('Defining frame and time columns...')\n",
    "Dataset[\"Frame\"] = Dataset.groupby(\"Fly\").cumcount()\n",
    "\n",
    "Dataset[\"time\"] = Dataset[\"Frame\"] / 30\n",
    "\n",
    "# Remove the original yfly column\n",
    "\n",
    "print('Removing Frame column...')\n",
    "Dataset.drop(columns=[\"Frame\",], inplace=True)\n",
    "\n",
    "print('Resetting index...')\n",
    "Dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "\n",
    "Dataset.to_feather(DataPath / \"230913_Velocity.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['CumulDist'] = Dataset['yfly_SG'].diff().abs().cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['MaxDist'] = Dataset.groupby('Fly')['CumulDist'].transform('max')\n",
    "\n",
    "Dataset['MaxDist_cm'] = (Dataset['MaxDist'] / 17) / 10\n",
    "\n",
    "Dataset['MaxDist_cm'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedDF_TNT = Dataset.groupby(['Genotype','Fly'])['MaxDist_cm'].mean().reset_index()\n",
    "\n",
    "GroupedDF_TNT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "670131.334511951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique fly values\n",
    "FlyList = Dataset['Fly'].unique()\n",
    "\n",
    "FlyList\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = GroupedDF_TNT[GroupedDF_TNT.duplicated(['Fly'], keep=False)]\n",
    "\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import Range1d\n",
    "\n",
    "p = iqplot.stripbox(\n",
    "    data=GroupedDF_TNT,\n",
    "    q=\"MaxDist_cm\",\n",
    "    cats=\"Genotype\",\n",
    "    spread='jitter',\n",
    ")\n",
    "p.x_range = Range1d(0, max(Dataset['MaxDist_cm']))\n",
    "p.xaxis.axis_label = 'Distance travelled (cm)'\n",
    "\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plotting.save(p, DataPath / \"Plots/230913_Grouped_TNT_Distance.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import Range1d\n",
    "\n",
    "pv = iqplot.stripbox(\n",
    "    data=GroupedDF_TNT,\n",
    "    q=\"MaxDist_cm\",\n",
    "    cats=\"Genotype\",\n",
    "    spread='jitter',\n",
    "    q_axis = \"y\",\n",
    ")\n",
    "pv.y_range = Range1d(0, max(Dataset['MaxDist_cm']))\n",
    "pv.yaxis.axis_label = 'Distance travelled (cm)'\n",
    "\n",
    "\n",
    "bokeh.io.show(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plotting.save(pv, DataPath / \"Plots/230913_Grouped_TNT_Distance_Vertical.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import Range1d\n",
    "\n",
    "pv = iqplot.stripbox(\n",
    "    data=GroupedDF_TNT,\n",
    "    q=\"MaxDist_cm\",\n",
    "    cats=\"Genotype\",\n",
    "    spread='jitter',\n",
    "    q_axis = \"y\",\n",
    "    show_legend = True,\n",
    "    #legend_location= \"center\",\n",
    "    color_column = \"Genotype\",\n",
    ")\n",
    "pv.y_range = Range1d(0, max(Dataset['MaxDist_cm']))\n",
    "pv.yaxis.axis_label = 'Distance travelled (cm)'\n",
    "# Remove all text from the x-axis\n",
    "pv.xaxis.axis_label = None\n",
    "pv.xaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "#pv.legend.title = 'Genotype'\n",
    "\n",
    "\n",
    "bokeh.io.show(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plotting.save(pv, DataPath / \"Plots/230913_Grouped_TNT_Distance_Vertical_legend.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird that the distance is so much grouped among flies, perhaps the day matters? Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import gridplot\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "range = Range1d(0, max(Dataset['MaxDist_cm']))\n",
    "\n",
    "# Create a new column 'color' in the DataFrame that maps the 'Genotype' values to colors\n",
    "Dataset['color'] = Dataset['Genotype'].map(color_map)\n",
    "\n",
    "\n",
    "dates = Dataset['Date'].unique()\n",
    "plots = []\n",
    "\n",
    "for d in dates:\n",
    "    data = Dataset[Dataset['Date'] == d]\n",
    "    \n",
    "    grouped_data = data.groupby(['Genotype','Fly'])['MaxDist_cm'].mean().reset_index()\n",
    "    \n",
    "    merged_data = pd.merge(grouped_data, data[['Genotype', 'color']].drop_duplicates(), on='Genotype', how='left')\n",
    "    \n",
    "    p = iqplot.stripbox(\n",
    "        data= merged_data,\n",
    "        q=\"MaxDist_cm\",\n",
    "        cats=\"Genotype\",\n",
    "        spread='jitter',\n",
    "        color_column='color',\n",
    "    )\n",
    "    p.x_range = range\n",
    "    p.xaxis.axis_label = 'Distance travelled (cm)'\n",
    "    \n",
    "    plots.append([p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import layout\n",
    "# Create a grid of plots\n",
    "grid = layout([plots[0], plots[1]], \n",
    "              [plots[2], plots[3]])\n",
    "\n",
    "# Show the grid\n",
    "bokeh.io.show(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.plotting.save(grid, DataPath / \"Plots/230913_Datewise_TNT_Distance.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fly velocity as the distance travelled per second a.k.a distance traveled by the fly between 30 consecutive frames\n",
    "Dataset['Velocity'] = Dataset['yfly_SG'].diff().abs() * 30\n",
    "Dataset['Velocity_cm'] = (Dataset['Velocity'] / 17) / 10\n",
    "# Plot the velocity of the first fly\n",
    "hv.Curve(Dataset[Dataset['Fly'] == 'Fly1'], 'time', 'Velocity_cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the velocity using a Savitzky-Golay filter and store it in a new column\n",
    "Dataset['Velocity_SG'] = savgol_lowpass_filter(Dataset['Velocity_cm'], 221, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the velocity of the first fly\n",
    "hv.Curve(Dataset[Dataset['Fly'] == 'Fly1'], 'time', 'Velocity_SG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grouped_velocity = Dataset.groupby(['Genotype','time'])['Velocity_SG'].mean().reset_index()\n",
    "\n",
    "# Assuming df is your DataFrame and 'Genotype' is the column with the genotypes\n",
    "selected_genotypes = [\"PR\", \"TNTxE-PG\", \"TNTxTH\"]\n",
    "subset_df = Grouped_velocity[Grouped_velocity['Genotype'].isin(selected_genotypes)]\n",
    "\n",
    "# Plot the mean velocity across time for colored by Genotype\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot = subset_df.hvplot.line(x='time', y='Velocity_SG', by='Genotype', width=600, height=400)\n",
    "#plot.labels(y=\"Average Velocity (cm/s)\", x=\"time (s)\")\n",
    "plot.opts(xlabel=\"time (s)\", ylabel=\"Average Velocity (cm/s)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(plot, DataPath / \"Plots/230913_Grouped_TNT_Velocity.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter the data for 'Fly'\n",
    "\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Get the unique genotypes\n",
    "genotypes = Dataset['Genotype'].unique()\n",
    "\n",
    "# For each genotype, create a stripplot and add it to the axes\n",
    "for i, genotype in enumerate(genotypes):\n",
    "    data = Dataset[Dataset['Genotype'] == genotype]\n",
    "    sns.stripplot(x=data['time'], y=data['yball_relative_SG'], hue=data['yball_relative_SG'], ax=ax, dodge=True, jitter=True, palette='viridis')\n",
    "\n",
    "    # Add some space between the stripplots for clarity\n",
    "    if i < len(genotypes) - 1:\n",
    "        ax.axhline(i + 0.5, color='grey', linestyle='--')\n",
    "\n",
    "# Set the yticks to be the genotypes\n",
    "ax.set_yticks(range(len(genotypes)))\n",
    "ax.set_yticklabels(genotypes)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
