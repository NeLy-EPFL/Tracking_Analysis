{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i'm gonna compare the difference between this each image and the last one to detect if there is a pause in the video.\n",
    "\n",
    "First i'm gonna select a test video that has an easy to spot pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import datashader as ds\n",
    "\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.plotting.util import process_cmap\n",
    "from bokeh.palettes import Viridis256\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread\n",
    "hv.extension('bokeh')\n",
    "\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../../..\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Spectral11\n",
    "from bokeh.io import output_notebook\n",
    "import iqplot\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import LinearColorMapper, ColorBar\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "from Utilities.Ballpushing_utils import *\n",
    "# Data loading\n",
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)\n",
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders\n",
    "SavePath = Path(\"/mnt/labserver/DURRIEU_Matthias/Pictures/RasterPlots/\")\n",
    "\n",
    "from Utilities.Ballpushing_utils import *\n",
    "\n",
    "Dataset_list = []\n",
    "Flycount = 0\n",
    "\n",
    "for folder in Folders:\n",
    "    #print(f\"Processing {folder}...\")\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "\n",
    "        # In the metadata_dict, make all they Arena subkeys lower case\n",
    "\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {k.lower(): v for k, v in metadata_dict[var].items()}\n",
    "        #print(metadata_dict)\n",
    "\n",
    "        files = list(folder.glob(\"**/*.mp4\"))\n",
    "\n",
    "    for file in files:\n",
    "        #print(file.name)\n",
    "        # Get the arena and corridor numbers from the parent (corridor) and grandparent (arena) folder names\n",
    "        arena = file.parent.parent.name\n",
    "        # print(arena)\n",
    "        corridor = file.parent.name\n",
    "\n",
    "        # Get the Genotype and Dates from the metadata, arena should have a upper case first letter\n",
    "\n",
    "        Genotype = metadata_dict[\"Genotype\"][arena]\n",
    "        #print(f\"Genotype: {Genotype} for arena {arena}\")\n",
    "\n",
    "        Date = metadata_dict[\"Date\"][arena]\n",
    "        # print(f\"Date: {Date} for arena {arena}\")\n",
    "\n",
    "        Light = metadata_dict[\"Light\"][arena]\n",
    "        FeedingState = metadata_dict[\"FeedingState\"][arena]\n",
    "        Period = metadata_dict[\"Period\"][arena]\n",
    "\n",
    "        start, end = np.load(file.parent / 'coordinates.npy')\n",
    "        \n",
    "        dir = file.parent\n",
    "\n",
    "        # Define flypath as the *flytrack*.analysis.h5 file in the same folder as the video\n",
    "        try:\n",
    "            flypath = list(dir.glob(\"*flytrack*.analysis.h5\"))[0]\n",
    "            #print(flypath.name)\n",
    "        except IndexError:\n",
    "            #print(f\"No fly tracking file found for {file.name}, skipping...\")\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # Define ballpath as the *tracked*.analysis.h5 file in the same folder as the video\n",
    "        try:\n",
    "            ballpath = list(dir.glob(\"*tracked*.analysis.h5\"))[0]\n",
    "            #print(ballpath.name)\n",
    "        except IndexError:\n",
    "            #print(f\"No ball tracking file found for {file.name}, skipping...\")\n",
    "            \n",
    "            continue\n",
    "\n",
    "        vidpath = file\n",
    "        vidname = f\"{Genotype}_{Date}_Light_{Light}_{FeedingState}_{Period}_{arena}_{corridor}\"\n",
    "\n",
    "        try:\n",
    "            # Extract interaction events and mark them in the DataFrame\n",
    "            data = extract_interaction_events(ballpath, flypath, mark_in_df=True)\n",
    "            data[\"start\"] = start\n",
    "            data[\"end\"] = end\n",
    "            data[\"Genotype\"] = Genotype\n",
    "            data[\"Date\"] = Date\n",
    "            data[\"arena\"] = arena\n",
    "            data[\"corridor\"] = corridor\n",
    "            Flycount += 1\n",
    "            data[\"Fly\"] = f'Fly {Flycount}'\n",
    "            # Compute yball_relative relative to start\n",
    "            data['yball_relative'] = abs(data['yball_smooth'] - data['start'])\n",
    "\n",
    "            # Fill missing values using linear interpolation\n",
    "            data['yball_relative'] = data['yball_relative'].interpolate(method='linear')\n",
    "            \n",
    "            \n",
    "            # Append the data to the all_data DataFrame\n",
    "            Dataset_list.append(data)\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            traceback_message = traceback.format_exc()\n",
    "            #print(f\"Error processing video {vidname}: {error_message}\")\n",
    "            #print(traceback_message)\n",
    "\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "Dataset = pd.concat(Dataset_list, ignore_index=True)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a particular fly video from the dataset\n",
    "\n",
    "TestFly = DataPath/'230803_TNTscreen_PM_1_Videos_Tracked/arena2/corridor3/corridor3.mp4'\n",
    "\n",
    "DataFly = Dataset[(Dataset['Date'] == '230803') & (Dataset['arena'] == 'arena2') & (Dataset['corridor'] == 'corridor3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(TestFly.as_posix())\n",
    "\n",
    "# Initialize a variable to store the previous frame\n",
    "prev_frame = None\n",
    "\n",
    "# Initialize a list to store the sum of pixel differences for each frame\n",
    "pixel_diffs = []\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If the frame was read successfully\n",
    "    if ret == True:\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # If this is not the first frame\n",
    "        if prev_frame is not None:\n",
    "            # Compute the absolute difference between the current and previous frame\n",
    "            diff = cv2.absdiff(gray, prev_frame)\n",
    "\n",
    "            # Sum up all pixel differences and append to the list\n",
    "            pixel_diffs.append(np.sum(diff))\n",
    "\n",
    "        # Save the current frame for use in the next iteration\n",
    "        prev_frame = gray\n",
    "\n",
    "    else:\n",
    "        # If there was an error reading the frame, we break the loop\n",
    "        break\n",
    "\n",
    "# Release the video file\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pixel differences\n",
    "\n",
    "curve_diff = hv.Curve(pixel_diffs, 'Frame', 'Sum of pixel differences')\n",
    "\n",
    "curve_fly = hv.Curve(DataFly, 'Frame', 'yfly_smooth')\n",
    "\n",
    "curve_diff.opts(width=600, height=400, tools=['hover'], show_grid=True)\n",
    "curve_fly.opts(width=600, height=400, tools=['hover'], show_grid=True)\n",
    "\n",
    "curve_diff + curve_fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "147*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to the dataframe to store where the fly is pausing\n",
    "\n",
    "# Calculate the difference between consecutive frames\n",
    "Dataset['yfly_diff'] = Dataset['yfly_smooth'].diff().abs()\n",
    "\n",
    "# Identify periods where the difference is less than 5 for at least 200 frames\n",
    "Dataset['Pausing'] = (Dataset['yfly_diff'] < 0.05).rolling(200).sum() == 200\n",
    "\n",
    "# Replace NaN values with False\n",
    "Dataset['Pausing'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFly = Dataset[(Dataset['Date'] == '230803') & (Dataset['arena'] == 'arena2') & (Dataset['corridor'] == 'corridor3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'PauseGroup' where change in 'Pausing' is detected\n",
    "DataFly['PauseGroup'] = (DataFly['Pausing'] != DataFly['Pausing'].shift()).cumsum()\n",
    "\n",
    "# Filter rows where 'Pausing' is True\n",
    "pauses = DataFly[DataFly['Pausing'] == True]\n",
    "\n",
    "# Group by 'PauseGroup' and get the first and last frame of each pause event\n",
    "pause_events = pauses.groupby('PauseGroup')['time'].agg(['first', 'last'])\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "pause_events.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the pause events\n",
    "print(pause_events)\n",
    "\n",
    "# Convert them to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'first' and 'last' columns to datetime format\n",
    "pause_events['first'] = pd.to_datetime(pause_events['first'], unit='s').dt.time\n",
    "pause_events['last'] = pd.to_datetime(pause_events['last'], unit='s').dt.time\n",
    "\n",
    "# Print the pause events\n",
    "print(pause_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yflydiff = hv.Curve(DataFly, 'Frame', 'yfly_diff')\n",
    "\n",
    "yflydiff.opts(width=600, height=400, tools=['hover'], show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8700/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10800/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 200/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
