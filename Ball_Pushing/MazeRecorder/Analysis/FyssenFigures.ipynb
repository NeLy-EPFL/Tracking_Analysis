{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import importlib\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../../..\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Spectral11\n",
    "from bokeh.io import output_notebook\n",
    "import iqplot\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import Utilities.Ballpushing_utils\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *\n",
    "from Utilities.Ballpushing_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of the directories containing the tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the folders I want to use. For instance, I want to use the folders that have the \"tnt\" in the name as I will explore velocities for different crossings with UAS-TNT. I'm also only getting flies tested in the afternoon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision + Starvation state effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"feedingstate\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder and 'flipped' not in minfolder and 'flip' not in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the tracking data and generating the dataset\n",
    "\n",
    "In this part, we import the Metatadata .json file and the tracking data .h5 file. Then we compute smoothed fly y positions and generate time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = generate_dataset(Folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedData = Dataset.groupby([\"time\", \"Light\", \"FeedingState\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "GroupedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#GroupedData.loc[GroupedData['time'] < 0.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Define a function to return alpha value based on Light condition\n",
    "def alpha_val(light_condition):\n",
    "    return 0.5 if light_condition == 'off' else 1.0\n",
    "\n",
    "# Apply the function to the dataset to create a new column 'alpha'\n",
    "GroupedData['alpha'] = GroupedData['Light'].apply(alpha_val)\n",
    "\n",
    "color_dict = {\"fed\": \"blue\", \"starved\": \"orange\", \"starved_noWater\": \"green\"}\n",
    "\n",
    "# Create an empty overlay\n",
    "overlay = hv.NdOverlay({})\n",
    "\n",
    "# Create separate overlays for each FeedingState\n",
    "for feeding_state, color in color_dict.items():\n",
    "    # Filter data for the current FeedingState\n",
    "    data = GroupedData[GroupedData['FeedingState'] == feeding_state]\n",
    "    \n",
    "    # Create curves and overlay them\n",
    "    curves = hv.Curve(data, kdims=['time'], vdims=['yball_relative', 'Light', 'alpha'])\n",
    "    curves = curves.groupby('Light').overlay().opts(opts.Curve(color=color, alpha='alpha'))\n",
    "    \n",
    "    # Add to the overall overlay\n",
    "    overlay[feeding_state] = curves\n",
    "\n",
    "overlay = overlay.opts( \n",
    "        height=750,\n",
    "        width=1000,\n",
    "        #alpha=1,\n",
    "        #line_width=2,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=2,\n",
    "        title=\"\",)\n",
    "# Display the plot\n",
    "overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "# Define a function to map FeedingState to color\n",
    "def feedingstate_to_color(feedingstate):\n",
    "    color_dict = {\"fed\": \"blue\", \"starved\": \"orange\", \"starved_noWater\": \"green\"}\n",
    "    return color_dict.get(feedingstate, 0)\n",
    "\n",
    "# Define a function to map Light condition to alpha\n",
    "def light_to_alpha(light):\n",
    "    return 0.5 if light == 'off' else 1.0  # replace with your actual logic of mapping light to alpha\n",
    "\n",
    "# Apply the mappings to FeedingState and Light condition\n",
    "GroupedData['FeedingStateColor'] = GroupedData['FeedingState'].apply(feedingstate_to_color)\n",
    "#print(GroupedData['FeedingStateColor'])\n",
    "GroupedData['LightAlpha'] = GroupedData['Light'].apply(light_to_alpha)\n",
    "\n",
    "# Define a function to map FeedingState to new labels\n",
    "def feedingstate_to_label(feedingstate):\n",
    "    label_dict = {\"fed\": \"fed\", \"starved\": \"starved with water\", \"starved_noWater\": \"starved without water\"}\n",
    "    return label_dict.get(feedingstate, feedingstate)\n",
    "\n",
    "# Apply the mapping to FeedingState\n",
    "GroupedData['FeedingStateLabel'] = GroupedData['FeedingState'].apply(feedingstate_to_label)\n",
    "\n",
    "# Calculate the sample size\n",
    "sample_size = Dataset.groupby(['Light','FeedingState'])['Fly'].nunique()\n",
    "\n",
    "# Define a function to map FeedingState, Light, and sample size to new labels\n",
    "def feedingstate_light_to_label(row):\n",
    "    label = row['FeedingStateLabel']\n",
    "    light = row['Light']\n",
    "    size = sample_size.loc[light, row['FeedingState']]\n",
    "    return f\"{label}, {light} (n={size})\"\n",
    "\n",
    "# Apply the mapping to FeedingState, Light, and sample size\n",
    "GroupedData['Feeding state, Light'] = GroupedData.apply(feedingstate_light_to_label, axis=1)\n",
    "\n",
    "# Create the curves and apply the options\n",
    "curves = hv.Curve(GroupedData, kdims=['time'], vdims=['yball_relative','FeedingStateLabel', 'Light', 'FeedingStateColor', 'LightAlpha', 'alpha', 'Feeding state, Light']).groupby(['Feeding state, Light']).overlay()\n",
    "curves.opts(opts.Curve(color='FeedingStateColor', alpha='LightAlpha', \n",
    "        height=750,\n",
    "        width=1000,\n",
    "        line_width=1,\n",
    "        xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        ))\n",
    "curves.opts(legend_position='bottom_right')\n",
    "\n",
    "curves\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a png\n",
    "hv.save(\n",
    "    curves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/feeding_and_light.png\",\n",
    "    fmt=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot as a html\n",
    "hv.save(\n",
    "    curves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/feeding_and_light.html\",\n",
    "    fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "# Define a function to map FeedingState to color\n",
    "def feedingstate_to_color(feedingstate):\n",
    "    color_dict = {\"fed\": \"blue\", \"starved\": \"orange\", \"starved_noWater\": \"green\"}\n",
    "    return color_dict.get(feedingstate, 0)\n",
    "\n",
    "# Define a function to map Light condition to alpha\n",
    "def light_to_alpha(light):\n",
    "    return 0.5 if light == 'off' else 1.0\n",
    "\n",
    "# Apply the mappings to FeedingState and Light condition\n",
    "GroupedData['FeedingStateColor'] = GroupedData['FeedingState'].apply(feedingstate_to_color)\n",
    "GroupedData['LightAlpha'] = GroupedData['Light'].apply(light_to_alpha)\n",
    "\n",
    "# Define a function to map FeedingState to new labels\n",
    "def feedingstate_to_label(feedingstate):\n",
    "    label_dict = {\"fed\": \"fed\", \"starved\": \"starved with water\", \"starved_noWater\": \"starved without water\"}\n",
    "    return label_dict.get(feedingstate, feedingstate)\n",
    "\n",
    "# Apply the mapping to FeedingState\n",
    "GroupedData['FeedingStateLabel'] = GroupedData['FeedingState'].apply(feedingstate_to_label)\n",
    "\n",
    "# Calculate the sample size\n",
    "sample_size = Dataset.groupby(['Light','FeedingState'])['Fly'].nunique()\n",
    "\n",
    "# Define a function to map FeedingState, Light, and sample size to new labels\n",
    "def feedingstate_light_to_label(row):\n",
    "    label = row['FeedingStateLabel']\n",
    "    light = row['Light']\n",
    "    size = sample_size.loc[light, row['FeedingState']]\n",
    "    return f\"{label}, {light} (n={size})\"\n",
    "\n",
    "# Apply the mapping to FeedingState, Light, and sample size\n",
    "GroupedData['Feeding state, Light'] = GroupedData.apply(feedingstate_light_to_label, axis=1)\n",
    "\n",
    "# Create separate overlays for each FeedingState and Light condition\n",
    "overlay_feedingstate = hv.NdOverlay({})\n",
    "overlay_light = hv.NdOverlay({})\n",
    "\n",
    "for feeding_state in GroupedData['FeedingState'].unique():\n",
    "    # Filter data for the current FeedingState\n",
    "    data_feedingstate = GroupedData[GroupedData['FeedingState'] == feeding_state]\n",
    "    \n",
    "    # Create curves and overlay them for FeedingState\n",
    "    curves_feedingstate = hv.Curve(data_feedingstate, kdims=['time'], vdims=['yball_relative', 'Feeding state, Light']).groupby('Feeding state, Light').overlay()\n",
    "    \n",
    "    # Add to the FeedingState overlay\n",
    "    overlay_feedingstate[feeding_state] = curves_feedingstate.opts(opts.Curve(color='FeedingStateColor', alpha='LightAlpha'))\n",
    "\n",
    "for light in GroupedData['Light'].unique():\n",
    "    # Filter data for the current Light condition\n",
    "    data_light = GroupedData[GroupedData['Light'] == light]\n",
    "    \n",
    "    # Create curves and overlay them for Light condition\n",
    "    curves_light = hv.Curve(data_light, kdims=['time'], vdims=['yball_relative', 'Feeding state, Light']).groupby('Feeding state, Light').overlay()\n",
    "    \n",
    "    # Add to the Light condition overlay\n",
    "    overlay_light[light] = curves_light.opts(opts.Curve(color='FeedingStateColor', alpha='LightAlpha'))\n",
    "\n",
    "# Set options for the plots\n",
    "opts_dict = dict(height=750, width=1000, line_width=1, xlabel=\"Time(s)\", ylabel=\"Average relative distance pushed (px)\", show_grid=True, fontscale=1.5, title=\"\", legend_position='bottom_right')\n",
    "\n",
    "# Apply options to the overlays\n",
    "overlay_feedingstate = overlay_feedingstate.opts(**opts_dict)\n",
    "overlay_light = overlay_light.opts(**opts_dict)\n",
    "\n",
    "# Display the plots side by side\n",
    "hv.Layout(overlay_feedingstate + overlay_light).cols(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to save the datasets \n",
    "\n",
    "DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "\n",
    "GroupedData.to_feather(DataPath / \"230928_GroupedDataFeedingStateLightMean.feather\")\n",
    "\n",
    "Dataset.to_feather(DataPath / \"230928_DatasetFeedingStateLight.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the tracking data and generating the dataset\n",
    "\n",
    "In this part, we import the Metatadata .json file and the tracking data .h5 file. Then we compute smoothed fly y positions and generate time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = generate_dataset(Folders, Events = 'interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupOps = Dataset.groupby(\n",
    "    [\n",
    "        \"time\",\n",
    "        \"Genotype\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupData = GroupOps.mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part below is too heavy to be executed in a notebook. I just ran it in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confints = GroupOps[\"yball_relative\"].apply(lambda x: draw_bs_ci(x, n_reps=300))\n",
    "\n",
    "# DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "\n",
    "# #GroupOps.to_feather(DataPath / \"230928_GroupedDataTNT.feather\")\n",
    "\n",
    "#Dataset.to_feather(DataPath / \"231010_DatasetTNT.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should now be possible to load the confints from the script output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "\n",
    "Confints = pd.read_feather(DataPath / \"231010_Confints.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints[[\"ci_lower\", \"ci_upper\"]] = Confints[\"yball_relative\"].tolist()\n",
    "\n",
    "Confints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints_process = Confints.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GroupData[\"ci_minus\"] and GroupData[\"ci_plus\"] as the columns containing the values of Confints\n",
    "GroupData[\"ci_lower\"] = Confints_process[\"ci_lower\"]\n",
    "GroupData[\"ci_upper\"] = Confints_process[\"ci_upper\"]\n",
    "\n",
    "# Define GroupData[\"ci_minus\"] and GroupData[\"ci_plus\"] as the columns containing the values of Confints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, Line, VArea\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Spectral11\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Call once to configure Bokeh to display plots inline in the notebook.\n",
    "output_notebook()\n",
    "\n",
    "# Create a new plot with a title and axis labels\n",
    "p = figure(title=\"yball over time\", x_axis_label='time', y_axis_label='yball_relative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the list of genotypes\n",
    "genotypes = GroupData['Genotype'].unique()\n",
    "\n",
    "#genotypes = ['PR', 'TNTxTH', 'TNTxE-PG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each genotype, create a line plot with confidence intervals\n",
    "for i, genotype in enumerate(genotypes):\n",
    "    df_genotype = GroupData[GroupData['Genotype'] == genotype]\n",
    "    source = ColumnDataSource(df_genotype)\n",
    "    \n",
    "    # Draw the line for yball_relative\n",
    "    p.line('time', 'yball_relative', source=source, line_width=2, color=Spectral11[i], legend_label=genotype)\n",
    "    \n",
    "    # Draw the upper and lower bounds for the confidence interval\n",
    "    p.varea(x='time', y1='ci_lower', y2='ci_upper', source=source, fill_color=Spectral11[i], fill_alpha=0.4)\n",
    "\n",
    "# Show the results\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas  # noqa\n",
    "\n",
    "# First, we melt the DataFrame to have 'Genotype' as columns for 'yball_relative'\n",
    "df_melted = GroupData.melt(id_vars=['time'], value_vars=['yball_relative'], col_level=0, var_name='Genotype')\n",
    "\n",
    "# Then, we create a HoloViews Dataset from the melted DataFrame\n",
    "ds = hv.Dataset(df_melted)\n",
    "\n",
    "# Now, we can use the hvPlot interface to plot it\n",
    "plot = ds.to(hv.Curve, 'time', 'value')\n",
    "\n",
    "# We also want to display the confidence intervals. For that, we need to melt the 'ci_lower' and 'ci_upper' columns too\n",
    "df_confidence = GroupData.melt(id_vars=['time'], value_vars=['ci_lower', 'ci_upper'], col_level=0, var_name='Genotype')\n",
    "\n",
    "# And create a HoloViews Dataset from the melted DataFrame for confidence intervals\n",
    "ds_confidence = hv.Dataset(df_confidence)\n",
    "\n",
    "# Create a HoloViews Area between the lower and upper confidence bounds\n",
    "confidence = ds_confidence.to(hv.Area, 'time', ['ci_lower', 'ci_upper'])\n",
    "\n",
    "# Finally, we overlay the two plots\n",
    "final_plot = (plot * confidence).opts(hv.opts.Area(fill_alpha=0.2))\n",
    "\n",
    "final_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_genotypes = ['TNTxE-PG', 'TNTxTH', 'TNTxLAL1'] \n",
    "\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "# Get the unique genotypes\n",
    "genotypes = GroupData.Genotype.unique()\n",
    "\n",
    "# Create a dictionary that maps each genotype to a color\n",
    "colormap = {genotype: Category10[len(genotypes)][i] for i, genotype in enumerate(genotypes)}\n",
    "\n",
    "GenoCurves = hv.Overlay([hv.Curve(GroupData.query(\"Genotype == @genotype\"), kdims=[\"time\"], vdims=['yball_relative'], label = genotype).opts(color=colormap[genotype], muted_line_alpha=0, muted = False if genotype in visible_genotypes else True) for genotype in genotypes])\n",
    "\n",
    "Areas = hv.Overlay([hv.Area(GroupData.query(\"Genotype == @genotype\"), kdims=['time'], vdims=['ci_lower','ci_upper','Genotype'], label = genotype).opts(fill_color=colormap[genotype], fill_alpha= 0.2 if genotype in visible_genotypes else 0, line_alpha=0, muted_fill_alpha=0, muted_line_alpha=0,  muted = False if genotype in visible_genotypes else True) for genotype in genotypes])\n",
    "\n",
    "\n",
    "hint_text = hv.Text(3500, 100, 'How to navigate: click on genotype labels in the legend to display/mute them.\\n Refreshing can be slow, do not click multiple times.\\n Downloading the html file locally makes it easier to navigate.', halign='left')\n",
    "\n",
    "AvgCurves = (GenoCurves \n",
    "             * Areas \n",
    "             #* hint_text\n",
    "             ).opts(width=1280, height=720, show_legend=True, xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None\n",
    "        )\n",
    "hv.save(\n",
    "    AvgCurves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/AverageCurvesTNTHV_notext.png\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_genotypes = ['TNTxE-PG', 'TNTxTH', 'TNTxLAL1'] \n",
    "\n",
    "Sub = GroupData.query(\"Genotype == @visible_genotypes\")\n",
    "\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "# Get the unique genotypes\n",
    "genotypes = Sub.Genotype.unique()\n",
    "\n",
    "# Create a dictionary that maps each genotype to a color\n",
    "colormap = {genotype: Category10[len(genotypes)][i] for i, genotype in enumerate(genotypes)}\n",
    "\n",
    "GenoCurves = hv.Overlay([hv.Curve(Sub.query(\"Genotype == @genotype\"), kdims=[\"time\"], vdims=['yball_relative'], label = genotype).opts(color=colormap[genotype], muted_line_alpha=0, muted = False if genotype in visible_genotypes else True) for genotype in genotypes])\n",
    "\n",
    "Areas = hv.Overlay([hv.Area(Sub.query(\"Genotype == @genotype\"), kdims=['time'], vdims=['ci_lower','ci_upper','Genotype'], label = genotype).opts(fill_color=colormap[genotype], fill_alpha= 0.2 if genotype in visible_genotypes else 0, line_alpha=0, muted_fill_alpha=0, muted_line_alpha=0,  muted = False if genotype in visible_genotypes else True) for genotype in genotypes])\n",
    "\n",
    "\n",
    "hint_text = hv.Text(3500, 100, 'How to navigate: click on genotype labels in the legend to display/mute them.\\n Refreshing can be slow, do not click multiple times.\\n Downloading the html file locally makes it easier to navigate.', halign='left')\n",
    "\n",
    "AvgCurves = (GenoCurves \n",
    "             * Areas \n",
    "             #* hint_text\n",
    "             ).opts(width=1280, height=720, show_legend=True, xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None\n",
    "        )\n",
    "hv.save(\n",
    "    AvgCurves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/AverageCurvesTNTHV_notext.png\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenoCurves = hv.Curve(GroupData, kdims=[\"time\"], vdims=['yball_relative', 'Genotype']).groupby('Genotype').opts(muted_line_alpha=0, muted = True).overlay()\n",
    "\n",
    "Areas = hv.Area(GroupData, kdims=['time'], vdims=['ci_lower','ci_upper','Genotype']).groupby('Genotype').opts(fill_alpha= 0.2, line_alpha=0, muted_fill_alpha=0, muted_line_alpha=0, muted = True).overlay()\n",
    "\n",
    "hint_text = hv.Text(100, 5000, 'How to navigate: click on genotype labels in the legend to display/mute them.\\n Refreshing can be slow, do not click multiple times.\\n Downloading the plot locally makes it easier to navigate.')\n",
    "\n",
    "AvgCurves = (GenoCurves * Areas * hint_text).opts(width=1280, height=720, show_legend=True, xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None)\n",
    "hv.save(\n",
    "    AvgCurves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/AverageCurvesTNTHV_muted.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import holoviews as hv\n",
    "\n",
    "# Create a CheckboxGroup widget with all genotypes\n",
    "checkboxes = pn.widgets.CheckboxGroup(name='Genotypes', options=list(GroupData.Genotype.unique()), value=['TNTxE-PG', 'TNTxTH', 'TNTxLAL1'])\n",
    "\n",
    "@pn.depends(checkboxes.param.value)\n",
    "def plot_genotypes(genotypes):\n",
    "    GenoCurves = hv.Overlay([hv.Curve(GroupData.query(\"Genotype == @genotype\"), kdims=[\"time\"], vdims=['yball_relative'], label = genotype) for genotype in genotypes])\n",
    "    Areas = hv.Overlay([hv.Area(GroupData.query(\"Genotype == @genotype\"), kdims=['time'], vdims=['ci_lower','ci_upper','Genotype'], label = genotype) for genotype in genotypes])\n",
    "    hint_text = hv.Text(100, 5000, 'How to navigate: click on genotype labels in the legend to display/mute them.\\n Refreshing can be slow, do not click multiple times.\\n Downloading the plot locally makes it easier to navigate.')\n",
    "    AvgCurves = (GenoCurves * Areas * hint_text).opts(width=1280, height=720, show_legend=True, xlabel=\"Time(s)\",\n",
    "            ylabel=\"Average relative distance pushed (px)\",\n",
    "            show_grid=True,\n",
    "            fontscale=1.5,\n",
    "            title=\"\",)\n",
    "    return AvgCurves\n",
    "\n",
    "# Create a Panel layout with the checkboxes and the plot\n",
    "layout = pn.Row(checkboxes, plot_genotypes)\n",
    "\n",
    "# Save the layout as an HTML file\n",
    "layout.save(\"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/AverageCurvesTNTHV_checkbox.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import holoviews.operation.datashader as hd\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "# Get the colormap colors\n",
    "my_cmap = cmap(np.arange(cmap.N))\n",
    "\n",
    "# Set alpha\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap.N)\n",
    "\n",
    "# Create new colormap\n",
    "my_cmap = plt.ListedColormap(my_cmap)\n",
    "\n",
    "visible_genotypes = ['TNTxE-PG', 'TNTxTH', 'TNTxLAL1'] \n",
    "\n",
    "GenoCurves = hv.Overlay([hd.datashade(hv.Curve(GroupData.query(\"Genotype == @genotype\"), kdims=[\"time\"], vdims=['yball_relative'], label = genotype), aggregator='mean') for genotype in GroupData.Genotype.unique()])\n",
    "\n",
    "Areas = hv.Overlay([hd.datashade(hv.Area(GroupData.query(\"Genotype == @genotype\"), kdims=['time'], vdims=['ci_lower','ci_upper','Genotype'], label = genotype), aggregator='mean', cmap=my_cmap) for genotype in GroupData.Genotype.unique()])\n",
    "\n",
    "hint_text = hv.Text(100, 5000, 'How to navigate: click on genotype labels in the legend to display/mute them. Refreshing can be slow, do not click multiple times. Downloading the plot locally makes it easier to navigate.', halign='right')\n",
    "\n",
    "AvgCurves = (GenoCurves * Areas * hint_text).opts(width=1280, height=720, show_legend=True, xlabel=\"Time(s)\",\n",
    "        ylabel=\"Average relative distance pushed (px)\",\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",)\n",
    "hv.save(\n",
    "    AvgCurves,\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Pictures/FyssenReport/AverageCurvesTNTHV.html\",\n",
    "    #fmt=\"html\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenoCurves.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(p, Savepath/\"AverageBallpushingTNT.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import Model\n",
    "\n",
    "if 'plot' in globals():\n",
    "    for model in plot.select({'type': Model}):\n",
    "        prev_doc = model.document\n",
    "        model._document = None\n",
    "        if prev_doc:\n",
    "            prev_doc.remove_root(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import CheckboxGroup, CustomJS\n",
    "from bokeh.layouts import column\n",
    "\n",
    "# Create a CheckboxGroup\n",
    "checkbox_group = CheckboxGroup(labels=genotypes.tolist(), active=list(range(len(genotypes))))\n",
    "\n",
    "# For each genotype, create a line plot with confidence intervals\n",
    "for i, genotype in enumerate(genotypes):\n",
    "    df_genotype = GroupData[GroupData['Genotype'] == genotype]\n",
    "    \n",
    "    # Downsample your data by taking every nth point\n",
    "    \n",
    "    n = 30\n",
    "    df_genotype = df_genotype.iloc[::n]  # replace n with the desired sampling rate\n",
    "    \n",
    "    source = ColumnDataSource(df_genotype)\n",
    "    \n",
    "    # Draw the line for yball_relative\n",
    "    line = p.line('time', 'yball_relative', source=source, line_width=2, color=Spectral11[i], legend_label=genotype)\n",
    "    \n",
    "    # Draw the upper and lower bounds for the confidence interval\n",
    "    varea = p.varea(x='time', y1='ci_lower', y2='ci_upper', source=source, fill_color=Spectral11[i], fill_alpha=0.2)\n",
    "\n",
    "    # Add a callback to the checkbox group to hide/show the line and varea\n",
    "    checkbox_group.js_on_change(\"active\", CustomJS(args=dict(line=line, varea=varea), code=\"\"\"\n",
    "        line.visible = cb_obj.active.includes(i);\n",
    "        varea.visible = cb_obj.active.includes(i);\n",
    "    \"\"\"))\n",
    "\n",
    "# Enable WebGL\n",
    "#p.output_backend = \"webgl\"\n",
    "\n",
    "# Show the results\n",
    "#show(column(checkbox_group, p))\n",
    "plot = column(checkbox_group, p)\n",
    "bokeh.io.save(plot, Savepath/\"AverageBallpushingTNT_check.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckData = Dataset.loc[Dataset['Fly'] == 'Fly 1']\n",
    "\n",
    "CheckData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckData['yball_smooth'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing interaction metrics and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we reuse the code from ConcatClips.py to get the interaction events from each video, and using these we can quantify metrics listed in 'Plotting ideas' in my notebook. These are :\n",
    "\n",
    "* Number of events\n",
    "* Event at which the ball is brought to the end\n",
    "* Time at which the ball is brought to the end\n",
    "* Amount of significant events\n",
    "* Push vs pull \n",
    "* plot the interactions chronology\n",
    "* time between interactions\n",
    "* First meaningful interaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the Event function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.reset_index()\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = Dataset.loc[Dataset['Fly'] == 'Fly 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find_interaction_events(df, Thresh, min_time):\n",
    "    df.loc[:, \"dist\"] = df.loc[:, \"yfly_smooth\"] - df.loc[:, \"yball_smooth\"]\n",
    "    df.loc[:, \"close\"] = df.loc[:,  \"dist\"] < Thresh\n",
    "    df.loc[:, \"block\"] = (df.loc[:, \"close\"].shift(1) != df.loc[:, \"close\"]).cumsum()\n",
    "    events = (\n",
    "        df[df[\"close\"]]\n",
    "        .groupby(\"block\")\n",
    "        .agg(start=(\"index\", \"min\"), end=(\"index\", \"max\"))\n",
    "    )\n",
    "    interaction_events = [\n",
    "        (start, end)\n",
    "        for start, end in events[[\"start\", \"end\"]].itertuples(index=False)\n",
    "    ]\n",
    "    interaction_events = [\n",
    "        event for event in interaction_events if event[1] - event[0] >= min_time\n",
    "    ]\n",
    "    return interaction_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = test_find_interaction_events(TestData, 80, 60)\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData2 = Dataset.loc[Dataset['Fly'] == 'Fly 2', :]\n",
    "\n",
    "events2 = test_find_interaction_events(TestData2, 80, 60)\n",
    "\n",
    "events2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extract_interaction_events(source,Thresh=80, min_time=60, as_df = False):\n",
    "    if isinstance(source, Path):\n",
    "        print(f\"Path: {source}\")\n",
    "        flypath = next(source.glob(\"*tracked_fly*.analysis.h5\"))\n",
    "        ballpath = next(source.glob(\"*tracked*.analysis.h5\"))\n",
    "        df = get_coordinates(flypath=flypath, ballpath=ballpath)\n",
    "\n",
    "    elif isinstance(source, pd.DataFrame):\n",
    "        print(f\"DataFrame: {source.shape}\")\n",
    "        df = source\n",
    "        \n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"Invalid source format: source must be a pathlib Path, string or a pandas DataFrame\"\n",
    "        )\n",
    "\n",
    "    # Create a new column 'Event' and initialize it with None\n",
    "    df.loc[:, \"Event\"] = None\n",
    "\n",
    "    if 'Fly' in df.columns:\n",
    "        flies = df['Fly'].unique()\n",
    "        for fly in flies:\n",
    "            print(f\"Processing {fly}...\")\n",
    "\n",
    "            # Compute interaction events for this fly only\n",
    "            interaction_events_fly = test_find_interaction_events(df.loc[df['Fly'] == fly, :], Thresh, min_time)\n",
    "            \n",
    "            print (f'found {len(interaction_events_fly)} events')\n",
    "\n",
    "            # Assign an event number to each event\n",
    "            for i, (start_time, end_time) in enumerate(interaction_events_fly, start=1):\n",
    "                df.loc[(df['Fly'] == fly) & (df.index >= start_time) & (df.index <= end_time), \"Event\"] = i\n",
    "                \n",
    "            NumbEvents = df.loc[df['Fly'] == fly, 'Event'].nunique()\n",
    "            print(f\"Number of events: {NumbEvents}\")\n",
    "    else:\n",
    "        # Compute interaction events for all data\n",
    "        interaction_events = test_find_interaction_events(df, Thresh, min_time)\n",
    "\n",
    "        # Assign an event number to each event\n",
    "        for i, (start_time, end_time) in enumerate(interaction_events, start=1):\n",
    "            df.loc[(df.index >= start_time) & (df.index <= end_time), \"Event\"] = i\n",
    "\n",
    "    if as_df:\n",
    "        return df\n",
    "    else:\n",
    "        return interaction_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flies = Dataset['Fly'].unique()\n",
    "\n",
    "flies = flies [:3]\n",
    "# Generate a dataset with only the first 3 flies\n",
    "Dataset_flies = Dataset[Dataset['Fly'].isin(flies)].reset_index()\n",
    "\n",
    "Dataset_flies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extract_interaction_events(Dataset_flies, Thresh=80, min_time=60, as_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the module\n",
    "importlib.reload(Utilities.Ballpushing_utils)\n",
    "\n",
    "# Now re-import your functions\n",
    "from Utilities.Ballpushing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = extract_interaction_events(Dataset, as_df = True)\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each Fly, compute how many unique values of Event that are not None there are\n",
    "\n",
    "# Group the data by Fly and Event\n",
    "GroupedData = Dataset.groupby([\"Fly\", \"Genotype\"]).nunique(['Event']).reset_index()\n",
    "\n",
    "# Count the number of unique values of Event for each Fly\n",
    "#Counts = GroupedData[\"Event\"].nunique()\n",
    "GroupedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_NumbEvents = iqplot.stripbox(data=GroupedData, q=\"Event\", cats=\"Genotype\", title=\"Number of events\", frame_width= 750, frame_height= 500, tooltips=[(\"Event\", \"@{Event}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "\n",
    "show(p_NumbEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Savepath = Path(\"/mnt/labserver/DURRIEU_Matthias/Pictures/InteractionEvents/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews version\n",
    "\n",
    "h_NumbEvents_bp = hv.BoxWhisker(data=GroupedData, vdims=\"Event\", kdims=\"Genotype\", color = \"Genotype\").opts(box_fill_color=None, box_line_color=\"black\", outlier_fill_color=None, outlier_line_color=None)\n",
    "h_NumbEvents_sc = hv.Scatter(data=GroupedData, vdims=\"Event\", kdims=\"Genotype\", color = \"Genotype\").opts(jitter=0.3, color= \"Genotype\", alpha = 0.5, size = 6, cmap=\"Category10\",  tools = ['hover'])\n",
    "\n",
    "hvplot_NumbEvents = (h_NumbEvents_bp * h_NumbEvents_sc).opts(width=750, height=500, show_legend=False, xlabel=\"\",\n",
    "        ylabel=\"Number of Events\",\n",
    "        invert_axes=True,\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None)\n",
    "\n",
    "hvplot_NumbEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(\n",
    "    hvplot_NumbEvents,\n",
    "    Savepath/\"NumberEvents.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub = GroupedData.loc[GroupedData['Genotype'].isin(visible_genotypes), :]\n",
    "\n",
    "# Holoviews version\n",
    "\n",
    "h_NumbEvents_bp = hv.BoxWhisker(data=Sub, vdims=\"Event\", kdims=\"Genotype\", color = \"Genotype\").opts(box_fill_color=None, box_line_color=\"black\", outlier_fill_color=None, outlier_line_color=None)\n",
    "h_NumbEvents_sc = hv.Scatter(data=Sub, vdims=\"Event\", kdims=\"Genotype\", color = \"Genotype\").opts(jitter=0.3, color= \"Genotype\", alpha = 0.5, size = 6, cmap=\"Category10\",  tools = ['hover'])\n",
    "\n",
    "hvplot_NumbEvents_sub = (h_NumbEvents_bp * h_NumbEvents_sc).opts(width=750, height=500, show_legend=False, xlabel=\"\",\n",
    "        ylabel=\"Number of Events\",\n",
    "        invert_axes=True,\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None)\n",
    "\n",
    "hvplot_NumbEvents_sub\n",
    "\n",
    "\n",
    "hv.save(\n",
    "    hvplot_NumbEvents_sub,\n",
    "    Savepath/\"NumberEvents_sub.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(p_NumbEvents, filename=Savepath / \"NumbEvents.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_NumbEvents.toolbar_location = None\n",
    "bokeh.io.export_png(p_NumbEvents, filename=str(Savepath / \"NumbEvents.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_unique_events = Dataset.groupby(['Fly', 'Genotype'])['Event'].nunique().groupby('Genotype').mean()\n",
    "\n",
    "#average_unique_events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event at which the ball is brough to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_threshold = 10\n",
    "\n",
    "# Group by 'Fly' column and find the maximum 'yball_relative' for each group\n",
    "max_positions = Dataset.groupby('Fly')['yball_relative'].max()\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "result = []\n",
    "\n",
    "# For each Fly, find the first event where 'yball_relative' is equal to max_position\n",
    "for fly, max_position in max_positions.items():\n",
    "    print(f'{fly} has a max position of {max_position}')\n",
    "    fly_data = Dataset[Dataset['Fly'] == fly]\n",
    "    fly_data = fly_data.sort_values('Event')\n",
    "    event = fly_data[fly_data['yball_relative'] >= max_position - end_threshold]['Event'].drop_duplicates().iloc[0]\n",
    "    result.append({'Fly': fly, 'Event': event})\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "result_df = pd.DataFrame(result)\n",
    "\n",
    "# Merge the result_df with the original Dataset\n",
    "Dataset = pd.merge(Dataset, result_df, on=['Fly', 'Event'], how='left')\n",
    "\n",
    "# Create the 'IsFinal' column, which is True if 'Event' is in result_df and False otherwise\n",
    "Dataset['IsFinal'] = False\n",
    "Dataset.loc[Dataset['Event'].isin(result_df['Event']), 'IsFinal'] = True\n",
    "\n",
    "Dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.groupby('Fly')['yball_relative'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['max_position'] = Dataset.groupby('Fly')['yball_relative'].transform('max')\n",
    "\n",
    "end_threshold = 10\n",
    "Dataset['IsFinal'] = Dataset['yball_relative'] >= (Dataset['max_position'] - end_threshold)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset[\"Event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Event' is NaN\n",
    "#Dataset = Dataset.dropna(subset=['Event'])\n",
    "\n",
    "# Now extract the event number from the 'Event' column\n",
    "#Dataset['EventNumber'] = Dataset['Event'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Filter rows where 'IsFinal' is True\n",
    "final_events_trimmed = Dataset[Dataset['IsFinal'] == True]\n",
    "\n",
    "#final_events_trimmed = final_events_trimmed.dropna(subset=['Event'])\n",
    "final_events_trimmed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_final = final_events_trimmed.groupby(['Fly'])['Event'].min()\n",
    "first_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'FinalEvent' in the original DataFrame\n",
    "Dataset = Dataset.merge(first_final.rename('FinalEvent'), left_on='Fly', right_index=True, how='left')\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of Final event grouped by Fly\n",
    "Dataset.groupby('Fly')['FinalEvent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of Event for final_events grouped by Fly\n",
    "final_events_trimmed.groupby('Fly')['Event'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each Fly, find the minimum 'EventNumber' where 'IsFinal' is True\n",
    "result = []\n",
    "for fly in final_events['Fly'].unique():\n",
    "    fly_data = final_events[final_events['Fly'] == fly]\n",
    "    min_event_number = fly_data['Event'].min()\n",
    "    result.append({'Fly': fly, 'MinEventNumber': min_event_number})\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "result_df = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with one row per fly\n",
    "data_per_fly = Dataset.drop_duplicates(subset='Fly')\n",
    "\n",
    "# Plot the data\n",
    "p_finalevent = iqplot.stripbox(data=data_per_fly, q=\"FinalEvent\", cats=\"Genotype\", title=\"Event at which the fly reaches the end of the corridor\", frame_width= 750, frame_height= 500, tooltips=[(\"FinalEvent\", \"@{FinalEvent}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "\n",
    "bokeh.io.show(p_finalevent)\n",
    "\n",
    "#TODO: Figure out why this doesn't work properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the plot as html\n",
    "bokeh.io.save(\n",
    "    p_finalevent,\n",
    "    Savepath / \"FinalEvent.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with rows where 'Event' equals 'FinalEvent'\n",
    "final_event_rows = Dataset[Dataset['Event'] == Dataset['FinalEvent']]\n",
    "\n",
    "# Drop duplicates based on 'Fly' to keep only the first occurrence of each fly\n",
    "final_event_rows = final_event_rows.drop_duplicates(subset='Fly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_final_event_time = iqplot.stripbox(data=final_event_rows, q=\"time\", cats=\"Genotype\", title=\"Time at which the fly reaches the end of the corridor\", frame_width= 750, frame_height= 500, tooltips=[(\"time\", \"@{time}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "\n",
    "bokeh.io.show(p_final_event_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holoviews version\n",
    "\n",
    "h_TimeLastEvents_bp = hv.BoxWhisker(data=final_event_rows, vdims=\"time\", kdims=\"Genotype\", color = \"Genotype\").opts(box_fill_color=None, box_line_color=\"black\", outlier_fill_color=None, outlier_line_color=None)\n",
    "h_TimeLastEvents_sc = hv.Scatter(data=final_event_rows, vdims=\"time\", kdims=\"Genotype\", color = \"Genotype\").opts(jitter=0.3, color= \"Genotype\", alpha = 0.5, size = 6, cmap=\"Category10\",  tools = ['hover'])\n",
    "\n",
    "hvplot_TimeLastEvents = (h_TimeLastEvents_bp * h_TimeLastEvents_sc).opts(width=750, height=500, show_legend=False, xlabel=\"\",\n",
    "        ylabel=\"Time(s)\",\n",
    "        invert_axes=True,\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None)\n",
    "\n",
    "hvplot_TimeLastEvents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(\n",
    "    hvplot_TimeLastEvents,\n",
    "    Savepath/\"TimeLastEvents.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_time = final_event_rows.loc[final_event_rows['Genotype'].isin(visible_genotypes), :]\n",
    "\n",
    "h_TimeLastEvents_bp = hv.BoxWhisker(data=Sub_time, vdims=\"time\", kdims=\"Genotype\", color = \"Genotype\").opts(box_fill_color=None, box_line_color=\"black\", outlier_fill_color=None, outlier_line_color=None)\n",
    "h_TimeLastEvents_sc = hv.Scatter(data=Sub_time, vdims=\"time\", kdims=\"Genotype\", color = \"Genotype\").opts(jitter=0.3, color= \"Genotype\", alpha = 0.5, size = 6, cmap=\"Category10\",  tools = ['hover'])\n",
    "\n",
    "hvplot_TimeLastEvents_sub = (h_TimeLastEvents_bp * h_TimeLastEvents_sc).opts(width=750, height=500, show_legend=False, xlabel=\"\",\n",
    "        ylabel=\"Time(s)\",\n",
    "        invert_axes=True,\n",
    "        show_grid=True,\n",
    "        fontscale=1.5,\n",
    "        title=\"\",\n",
    "        toolbar=None)\n",
    "\n",
    "hvplot_TimeLastEvents_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Holoviews version\n",
    "hv.save(\n",
    "    hvplot_TimeLastEvents_sub,\n",
    "    Savepath/\"TimeLastEvents_sub.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_final_event_time.toolbar_location = None\n",
    "bokeh.io.export_png(p_final_event_time, filename=str(Savepath / \"FinalEventTime.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_final_event_time,\n",
    "    Savepath / \"FinalTime.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "\n",
    "Dataset.to_feather(DataPath / \"231002_DatasetTNT_InteractionEvents.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_yball_variation(event_df, threshold=10):\n",
    "    yball_segment = event_df[\"yball_smooth\"]\n",
    "    variation = yball_segment.max() - yball_segment.min()\n",
    "    return variation > threshold\n",
    "\n",
    "# Apply the function and reset the index\n",
    "significant_events = Dataset.groupby([\"Fly\", \"Event\"]).apply(check_yball_variation).reset_index()\n",
    "\n",
    "# Rename the 0 column to 'SignificantEvent'\n",
    "significant_events.rename(columns={0: 'SignificantEvent'}, inplace=True)\n",
    "\n",
    "# Merge the significant_events DataFrame with the original Dataset\n",
    "Dataset = pd.merge(Dataset, significant_events, on=['Fly', 'Event'], how='left')\n",
    "\n",
    "Dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique events that are significant for each 'Fly' and 'Genotype'\n",
    "unique_significant_events = Dataset[Dataset['SignificantEvent'] == True].groupby(['Fly', 'Genotype'])['Event'].nunique()\n",
    "\n",
    "#print(unique_significant_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_unique_significant_events = iqplot.stripbox(data=unique_significant_events.reset_index(), q=\"Event\", cats=\"Genotype\", title=\"Number of significant events\", frame_width= 750, frame_height= 500,  tooltips=[(\"Event\", \"@{Event}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "\n",
    "bokeh.io.show(p_unique_significant_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_unique_significant_events,\n",
    "    Savepath / \"NumbSignificantEvents.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only the significant events\n",
    "significant_events = Dataset[Dataset['SignificantEvent'] == True]\n",
    "\n",
    "# For each 'Fly', find the first significant event and get its time\n",
    "first_significant_event_times = significant_events.groupby('Fly')['time'].idxmin()\n",
    "\n",
    "# Use these indices to get the corresponding rows from the original DataFrame\n",
    "first_significant_events = Dataset.loc[first_significant_event_times]\n",
    "\n",
    "first_significant_events.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each 'Fly' and 'Genotype', find the first significant event and get its time\n",
    "first_significant_event_times = significant_events.groupby(['Fly', 'Genotype'])['time'].idxmin()\n",
    "\n",
    "# Use these indices to get the corresponding rows from the original DataFrame\n",
    "first_significant_events = Dataset.loc[first_significant_event_times]\n",
    "\n",
    "# Plot the data\n",
    "p_first_significant_event_times = iqplot.stripbox(data=first_significant_events.reset_index(), q=\"time\", cats=\"Genotype\", title=\"Time of first significant event\", frame_width= 750, frame_height= 500,   tooltips=[(\"time\", \"@{time}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "bokeh.io.show(p_first_significant_event_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_first_significant_event_times,\n",
    "    Savepath / \"FirstSignificantEvent_Time.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only the significant events\n",
    "significant_events = Dataset[Dataset['SignificantEvent'] == True]\n",
    "\n",
    "# For each 'Fly', find the first significant event and get its time\n",
    "first_significant_event_times = significant_events.groupby('Fly')['time'].idxmin()\n",
    "\n",
    "# Use these indices to get the corresponding rows from the original DataFrame\n",
    "first_significant_events = Dataset.loc[first_significant_event_times]\n",
    "\n",
    "#first_significant_events[\"EventNumber\"] = first_significant_events.loc[:,\"Event\"].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "first_significant_events.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "p_first_significant_event_numbers = iqplot.stripbox(data=first_significant_events.reset_index(), q=\"Event\", cats=\"Genotype\", title=\"Number of first significant event\", frame_width= 750, frame_height= 500, tooltips=[(\"Event\", \"@{Event}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "bokeh.io.show(p_first_significant_event_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_first_significant_event_numbers,\n",
    "    Savepath / \"FirstSignificantEvent_Number.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Dataset['Event'] = Dataset['Event'].replace('None', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['IsEvent'] = Dataset['Event'].notna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['TimeSinceLastEvent'] = Dataset.groupby('Fly').apply(lambda x: x['time'] - x.loc[x['IsEvent'], 'time'].shift()).reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each 'Fly', calculate the time difference between consecutive events\n",
    "Dataset['TimeSinceLastEvent'] = Dataset[Dataset['IsEvent']].groupby('Fly')['time'].diff()\n",
    "\n",
    "# Calculate the average time between events for each 'Fly' and 'Genotype'\n",
    "average_time_between_events = Dataset.groupby(['Fly', 'Genotype'])['TimeSinceLastEvent'].mean().reset_index()\n",
    "\n",
    "# Plot the data\n",
    "p_average_time_between_events = iqplot.stripbox(data=average_time_between_events, q=\"TimeSinceLastEvent\", cats=\"Genotype\", title=\"Average time between events\", frame_width= 750, frame_height= 500, tooltips=[(\"TimeSinceLastEvent\", \"@{TimeSinceLastEvent}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "bokeh.io.show(p_average_time_between_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_average_time_between_events,\n",
    "    Savepath / \"AverageTimeBetweenEvents.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset['IsNonEvent'] = Dataset['Event'].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time difference between consecutive rows\n",
    "Dataset['TimeDifference'] = Dataset.groupby('Fly')['time'].diff()\n",
    "\n",
    "# For non-event rows, sum these time differences\n",
    "Dataset['NonEventTime'] = Dataset.loc[Dataset['IsNonEvent'], 'TimeDifference']\n",
    "\n",
    "# Calculate the cumulative time spent in non-events for each 'Fly' and 'Genotype'\n",
    "cumulative_time_in_non_events = Dataset.groupby(['Fly', 'Genotype'])['NonEventTime'].sum().reset_index()\n",
    "\n",
    "# Plot the data\n",
    "p_cumulative_time_in_non_events = iqplot.stripbox(data=cumulative_time_in_non_events, q=\"NonEventTime\", cats=\"Genotype\", title=\"Cumulative time spent not interacting\", frame_width= 750, frame_height= 500, tooltips=[(\"NonEventTime\", \"@{NonEventTime}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "bokeh.io.show(p_cumulative_time_in_non_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_cumulative_time_in_non_events,\n",
    "    Savepath / \"CumulativeTimeNonEvents.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each 'Fly', 'Event', and 'Genotype', get the timestamp of the first frame\n",
    "first_frame_timestamps = Dataset.groupby(['Fly', 'Event', 'Genotype'])['time'].first().reset_index()\n",
    "\n",
    "# Plot the data\n",
    "p_first_frame_timestamps = iqplot.histogram(data=first_frame_timestamps, q=\"time\", cats=\"Genotype\", title=\"Timestamp of first frame of each event\", frame_width= 750, frame_height= 2000, )\n",
    "bokeh.io.show(p_first_frame_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_first_frame_timestamps,\n",
    "    Savepath / \"FirstFrameTimestamps.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in 'yball_relative' between the start and end of each event\n",
    "yball_relative_diff = Dataset.groupby(['Fly', 'Event'])['yball_relative'].apply(lambda x: x.iloc[-1] - x.iloc[0]).reset_index(name='yball_relative_diff')\n",
    "\n",
    "# Merge yball_relative_diff with Dataset\n",
    "Dataset = pd.merge(Dataset, yball_relative_diff, on=['Fly', 'Event'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify whether each event is a 'Push', 'Pull', or 'None'\n",
    "Dataset['Event_Type'] = np.where(Dataset['yball_relative_diff'] > 10, 'Push', np.where(Dataset['yball_relative_diff'] < -10, 'Pull', 'None'))\n",
    "\n",
    "# Count the number of each event type for each 'Fly' and 'Genotype'\n",
    "event_type_counts = Dataset.groupby(['Fly', 'Genotype', 'Event_Type']).size().reset_index(name='Count')\n",
    "\n",
    "# Count the number of unique events with event type for each fly and genotype\n",
    "unique_event_type_counts = event_type_counts.groupby(['Fly', 'Genotype'])['Event_Type'].nunique().reset_index(name='Count')\n",
    "\n",
    "# Filter the DataFrame to include only the 'Pull' events\n",
    "pull_events = Dataset[Dataset['Event_Type'] == 'Pull']\n",
    "\n",
    "# Count the number of 'Pull' events for each 'Fly' and 'Genotype'\n",
    "pull_event_counts = pull_events.groupby(['Fly', 'Genotype']).size().reset_index(name='Count')\n",
    "\n",
    "# Count the number of unique 'Pull' events for each 'Fly' and 'Genotype'\n",
    "unique_pull_event_counts = pull_events.groupby(['Fly', 'Genotype'])['Event'].nunique().reset_index(name='Count')\n",
    "\n",
    "# Plot the data\n",
    "\n",
    "\n",
    "p_pull_event_counts = iqplot.stripbox(data=unique_pull_event_counts, q=\"Count\", cats=\"Genotype\", title=\"Number of 'Pull' events\", frame_width= 750, frame_height= 500, tooltips=[(\"Count\", \"@{Count}\"),(\"Genotype\", \"@{Genotype}\")], spread=\"jitter\")\n",
    "bokeh.io.show(p_pull_event_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.save(\n",
    "    p_pull_event_counts,\n",
    "    Savepath / \"PullEventCounts.html\",\n",
    "    #fmt=\"html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Pull and push within event\n",
    "\n",
    "#TODO : Make a dashboard with all the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dashboard\n",
    "\n",
    "## Chapters\n",
    "\n",
    "\n",
    "*Interactions chronology\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the plots to include in the dashboard\n",
    "\n",
    "Plots = [p_NumbEvents, p_finalevent, p_final_event_time, p_unique_significant_events, p_first_significant_event_times, p_first_significant_event_numbers, p_average_time_between_events, p_cumulative_time_in_non_events, p_first_frame_timestamps, p_pull_event_counts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import Model\n",
    "\n",
    "for p in Plots:\n",
    "    for model in p.select({'type': Model}):\n",
    "        prev_doc = model.document\n",
    "        model._document = None\n",
    "        if prev_doc:\n",
    "            prev_doc.remove_root(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a gridplot of the plots\n",
    "\n",
    "grid = bokeh.layouts.gridplot([[p_first_frame_timestamps, p_NumbEvents],\n",
    "                               [None, p_cumulative_time_in_non_events],\n",
    "                               [None, p_unique_significant_events],\n",
    "                               [p_finalevent, p_final_event_time],\n",
    "                               [p_first_significant_event_numbers, p_first_significant_event_times],\n",
    "                               [p_average_time_between_events, p_pull_event_counts]])\n",
    "\n",
    "bokeh.io.save(grid,\n",
    "              Savepath / \"Dashboard.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import column, row\n",
    "\n",
    "# Create a column layout for the large plot\n",
    "column1 = column(p_first_frame_timestamps)\n",
    "\n",
    "# Create a column layout for the smaller plots\n",
    "column2 = column(p_NumbEvents, p_cumulative_time_in_non_events, p_unique_significant_events)\n",
    "\n",
    "# Put the two columns into a row layout\n",
    "row1 = row(column1, column2)\n",
    "\n",
    "# Create a gridplot for the remaining plots\n",
    "grid = bokeh.layouts.gridplot([[row1], [p_finalevent, p_final_event_time],\n",
    "                               [p_first_significant_event_numbers, p_first_significant_event_times],\n",
    "                               [p_average_time_between_events, p_pull_event_counts]])\n",
    "\n",
    "bokeh.io.save(grid, Savepath / \"Dashboard.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
