{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to load the ball coordinates from the .analysis.h5 file\n",
    "\n",
    "filename =\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Sleap/Datasets/FirstExp/labels_centres_.v001_230602.001_arena1_corridor_2.analysis.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    locations = f[\"tracks\"][:].T\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Sleap/Datasets/Tests1_2_Merged/\")\n",
    "\n",
    "# Build a dataframe that will store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "df = pd.DataFrame(columns=[\"yball\", \"arena\", \"corridor\"])\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "for file in inputfolder.glob(\"*.analysis.h5\"):\n",
    "    print(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "    locations.shape\n",
    "\n",
    "    yball : np.ndarray = locations[:, :, 1, :]\n",
    "\n",
    "   \n",
    "\n",
    "    # Get the arena and corridor numbers from the filename\n",
    "    filename = file.name\n",
    "    arena = filename.split(\"_\")[4]\n",
    "    corridor = filename.split(\"_\")[5] + filename.split(\"_\")[6][0]\n",
    "\n",
    "     # If arena is 4, 5 or 6, revert the y coordinates\n",
    "    if arena == \"arena2\" or arena == \"arena5\" or arena == \"arena8\":\n",
    "        yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "    \n",
    "    # Store the ball y positions and the arena and corridor numbers as metadata\n",
    "    df = df.append({\"yball\": yball[:, 0, 0], \"arena\": arena, \"corridor\": corridor}, ignore_index=True)\n",
    "    \n",
    "# Unpack yball positions\n",
    "\n",
    "df = df.explode(\"yball\")\n",
    "df['time'] = df.groupby(['arena', 'corridor']).cumcount() / 30\n",
    "\n",
    "df['Fly'] = 'Fly' + (df.groupby(['arena', 'corridor']).ngroup() + 1).astype(str)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corresponding video path\n",
    "video_path = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Test2_Videos/Videos_NumOrdered/arena1_corridor_2.mp4\")\n",
    "\n",
    "outpath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/LabeledTest.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first 15O frames of the video, plot the ball coordinates\n",
    "\n",
    "startFrame = 4000   # only variables you need to change to run the code\n",
    "endFrame = 6600     # start and end frame of the abstract that you want to record\n",
    "\n",
    "videoCapture = cv2.VideoCapture(video_path.as_posix()) #TODO change the pathname\n",
    "\n",
    "# Make a video writer\n",
    "fps = 30\n",
    "frameSize = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(outpath.as_posix(), fourcc, fps, frameSize)\n",
    "\n",
    "\n",
    "\n",
    "# Read the video and for each frame plot a circle at the ball coordinates\n",
    "frameNumber = 0\n",
    "while True:\n",
    "    ret, frame = videoCapture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frameNumber += 1\n",
    "    print(frameNumber)\n",
    "\n",
    "    if startFrame <= frameNumber <= endFrame:\n",
    "\n",
    "        # get the skeleton of the frame\n",
    "        cv2.circle(frame, (int(locations[frameNumber][0][0]), int(locations[frameNumber][0][1])), 5, (0, 0, 255), -1)\n",
    "        #cv2.imshow(\"frame\", frame)\n",
    "        out.write(frame)\n",
    "\n",
    "    if frameNumber > endFrame:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # to quit the video press q\n",
    "    \n",
    "    \n",
    "videoCapture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Test2/image0.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(ImagePath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yball : np.ndarray = locations[:, :, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the y coordinates of the ball\n",
    "plt.plot(yball[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Sleap/Datasets/FirstExp/\")\n",
    "\n",
    "# Build a dataframe that will store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "df = pd.DataFrame(columns=[\"yball\", \"arena\", \"corridor\"])\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "for file in inputfolder.glob(\"*.analysis.h5\"):\n",
    "    print(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "    locations.shape\n",
    "\n",
    "    yball : np.ndarray = locations[:, :, 1, :]\n",
    "\n",
    "   \n",
    "\n",
    "    # Get the arena and corridor numbers from the filename\n",
    "    filename = file.name\n",
    "    arena = filename.split(\"_\")[4]\n",
    "    corridor = filename.split(\"_\")[5] + filename.split(\"_\")[6][0]\n",
    "\n",
    "     # If arena is 4, 5 or 6, revert the y coordinates\n",
    "    if arena == \"arena2\" or arena == \"arena5\" or arena == \"arena8\":\n",
    "        yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "    \n",
    "    # Store the ball y positions and the arena and corridor numbers as metadata\n",
    "    df = df.append({\"yball\": yball[:, 0, 0], \"arena\": arena, \"corridor\": corridor}, ignore_index=True)\n",
    "    \n",
    "# Unpack yball positions\n",
    "\n",
    "df = df.explode(\"yball\")\n",
    "df['time'] = df.groupby(['arena', 'corridor']).cumcount() / 30\n",
    "\n",
    "df['Fly'] = 'Fly' + (df.groupby(['arena', 'corridor']).ngroup() + 1).astype(str)\n",
    "\n",
    "df.head()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first value of yball for each arena and corridor\n",
    "\n",
    "df_first = df.groupby(['arena', 'corridor']).first().reset_index()\n",
    "\n",
    "# Same for last value\n",
    "\n",
    "df_last = df.groupby(['arena', 'corridor']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.01  # desired cutoff frequency of the filter, Hz ,      slightly higher than actual 1.2 Hz\n",
    "order = 1  # sin wave can be approx represented as quadratic\n",
    "\n",
    "df['ysmooth'] = butter_lowpass_filter(df['yball'], cutoff, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column where for each fly the lowest yball value is 0 and the rest is relative to that\n",
    "\n",
    "df['yball_relative'] = df['yball'] - df_first['yball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grouped = df.groupby(['time',]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints = df.groupby(['time'])['yball_relative'].apply(lambda x: draw_bs_ci(x, n_reps=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints_process = Confints.reset_index()\n",
    "\n",
    "# Split values of Confints_process[\"cumulated_success\"] into two columns ci_lower and ci_upper\n",
    "Confints_process[[\"ci_lower\", \"ci_upper\"]] = pd.DataFrame(\n",
    "    Confints_process[\"yball_relative\"].tolist(), index=Confints_process.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Grouped[\"ci_lower\"] = Confints_process[\"ci_lower\"]\n",
    "Grouped[\"ci_upper\"] = Confints_process[\"ci_upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ball y positions as function of time for each fly and display it as a grid with matplotlib\n",
    "\n",
    "Flynum = 54\n",
    "\n",
    "# Compute the number of rows and columns for the grid\n",
    "nrows = math.ceil(math.sqrt(Flynum))\n",
    "ncols = math.ceil(Flynum / nrows)\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Find the minimum and maximum y values across all subplots\n",
    "ymin = df['yball'].min()\n",
    "ymax = df['yball'].max()\n",
    "\n",
    "for i, fly in enumerate(df['Fly'].unique()):\n",
    "    df[df['Fly'] == fly].plot(x='time', y='yball', ax=axs[i], title=fly, legend=False)\n",
    "    axs[i].set_ylim(ymin, ymax)\n",
    "    \n",
    "# Set the same x and y labels for all subplots\n",
    "fig.text(0.5, 0.04, 'Time (s)', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, 'Y position (px)', ha='center', va='center', rotation='vertical')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust plot size to make everything bigger\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "# Change font size accordingly\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Compute mean relative yball position across flies for each time point\n",
    "df_mean = df.groupby('time').mean().reset_index()\n",
    "\n",
    "# Compute upper and lower confidence intervals\n",
    "# (replace this with your own code to compute the confidence intervals)\n",
    "upper = Grouped['ci_upper']\n",
    "lower = Grouped['ci_lower']\n",
    "\n",
    "# Plot the mean relative yball position as function of time and display it\n",
    "plt.plot(df_mean['time'], df_mean['yball_relative'])\n",
    "plt.fill_between(df_mean['time'], lower, upper, alpha=0.2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Mean relative yball position (px)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Fly')\n",
    "for name, group in grouped:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder2 = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Sleap/Datasets/230606_DarkishTest_Full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a dataframe that will store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "df2 = pd.DataFrame(columns=[\"yball\", \"arena\", \"corridor\"])\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "for file in inputfolder2.glob(\"*.analysis.h5\"):\n",
    "    print(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "    locations.shape\n",
    "\n",
    "    yball : np.ndarray = locations[:, :, 1, :]\n",
    "\n",
    "   \n",
    "\n",
    "    # Get the arena and corridor numbers from the filename\n",
    "    filename = file.name\n",
    "    arena = filename.split(\"_\")[4]\n",
    "    corridor = filename.split(\"_\")[5] + filename.split(\"_\")[6][0]\n",
    "\n",
    "     # If arena is 4, 5 or 6, revert the y coordinates\n",
    "    #if arena == \"arena2\" or arena == \"arena5\" or arena == \"arena8\":\n",
    "    if arena == \"arena1\" or arena == \"arena3\" or arena == \"arena4\" or arena == \"arena6\" or arena == \"arena7\" or arena == \"arena9\":\n",
    "        yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "    \n",
    "    # Store the ball y positions and the arena and corridor numbers as metadata\n",
    "    df2 = df2.append({\"yball\": yball[:, 0, 0], \"arena\": arena, \"corridor\": corridor}, ignore_index=True)\n",
    "    \n",
    "# Unpack yball positions\n",
    "\n",
    "df2 = df2.explode(\"yball\")\n",
    "df2['time'] = df2.groupby(['arena', 'corridor']).cumcount() / 30\n",
    "\n",
    "df2['Fly'] = 'Fly' + (df2.groupby(['arena', 'corridor']).ngroup() + 1).astype(str)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first value of yball for each arena and corridor\n",
    "\n",
    "df2_first = df2.groupby(['arena', 'corridor']).first().reset_index()\n",
    "\n",
    "# Same for last value\n",
    "\n",
    "df2_last = df2.groupby(['arena', 'corridor']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column where for each fly the lowest yball value is 0 and the rest is relative to that\n",
    "\n",
    "df2['yball_relative'] = df2['yball'] - df2_first['yball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ball y positions as function of time for each fly and display it as a grid with matplotlib\n",
    "\n",
    "Flynum = 54\n",
    "\n",
    "# Compute the number of rows and columns for the grid\n",
    "nrows = math.ceil(math.sqrt(Flynum))\n",
    "ncols = math.ceil(Flynum / nrows)\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Find the minimum and maximum y values across all subplots\n",
    "ymin = df2['yball_relative'].min()\n",
    "ymax = df2['yball_relative'].max()\n",
    "\n",
    "for i, fly in enumerate(df2['Fly'].unique()):\n",
    "    df2[df2['Fly'] == fly].plot(x='time', y='yball_relative', ax=axs[i], title=fly, legend=False, color='orange')\n",
    "    axs[i].set_ylim(ymin, ymax)\n",
    "    \n",
    "# Set the same x and y labels for all subplots\n",
    "fig.text(0.5, 0.04, 'Time (s)', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, 'Y position (px)', ha='center', va='center', rotation='vertical')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grouped2 = df2.groupby(['time',]).mean().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confints2 = df2.groupby(['time'])['yball_relative'].apply(lambda x: draw_bs_ci(x, n_reps=300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Confints_process2 = Confints2.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split values of Confints_process[\"cumulated_success\"] into two columns ci_lower and ci_upper\n",
    "Confints_process2[[\"ci_lower\", \"ci_upper\"]] = pd.DataFrame(\n",
    "    Confints_process2[\"yball_relative\"].tolist(), index=Confints_process2.index\n",
    ")\n",
    "\n",
    "Grouped2[\"ci_lower\"] = Confints_process2[\"ci_lower\"]\n",
    "Grouped2[\"ci_upper\"] = Confints_process2[\"ci_upper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust plot size to make everything bigger\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "# Change font size accordingly\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Compute mean relative yball position across flies for each time point\n",
    "df2_mean = df2.groupby('time').mean().reset_index()\n",
    "\n",
    "df2_mean[\"ci_lower\"] = Confints_process2[\"ci_lower\"]\n",
    "df2_mean[\"ci_upper\"] = Confints_process2[\"ci_upper\"]\n",
    "\n",
    "# Compute upper and lower confidence intervals\n",
    "# (replace this with your own code to compute the confidence intervals)\n",
    "upper2 = Grouped2['ci_upper']\n",
    "lower2 = Grouped2['ci_lower']\n",
    "\n",
    "# Plot the mean relative yball position as function of time and display it\n",
    "plt.plot(df2_mean['time'], df2_mean['yball_relative'], color='orange')\n",
    "plt.fill_between(df2_mean['time'], lower2, upper2, alpha=0.2, color='orange')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Mean relative yball position (px)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both df1 and df2 mean curves with confidence intervals on the same plot\n",
    "\n",
    "plt.plot(df_mean['time'], df_mean['yball_relative'], color='blue')\n",
    "\n",
    "plt.plot(df2_mean['time'], df2_mean['yball_relative'], color='orange')\n",
    "plt.legend(['Control', 'Darkish'])\n",
    "plt.fill_between(df_mean['time'], lower, upper, alpha=0.1, color='blue')\n",
    "plt.fill_between(df2_mean['time'], lower2, upper2, alpha=0.1, color='orange')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Mean relative yball position (px)')\n",
    "# Add a legend with blue bar being control and orange bar being darkish\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksave(\n",
    "    path=savepath.joinpath(\"230606_Darkish_1_Averaged.feather\"),\n",
    "    object=\"dataframe\",\n",
    "    file=df2_mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I added a small change here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import platform\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "from Utilities.Utils import *\n",
    "from Utilities.Processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the folders I want to use\n",
    "# For instance, I want to use the folders that have the \"FeedingState\" in the name\n",
    "\n",
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    #if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "    if 'feedingstate' in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Build a dataframe that will store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "Dataset = pd.DataFrame(columns=[\"Fly\", \"yball\", \"arena\", \"corridor\"])\n",
    "\n",
    "# Loop over all the .analysis.h5 files in the folder and store the ball y positions and the arena and corridor numbers as metadata\n",
    "\n",
    "Flynum = 0\n",
    "# Loop over all the foldes that don't have \"Dark\" in the name\n",
    "for folder in Folders:\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "        \n",
    "        print (metadata_dict)\n",
    "        \n",
    "    for file in folder.glob(\"**/*.analysis.h5\"):\n",
    "        #print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            dset_names = list(f.keys())\n",
    "            locations = f[\"tracks\"][:].T\n",
    "            node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "        locations.shape\n",
    "        \n",
    "        if \"Flipped\" in folder.name:\n",
    "            yball[:, 0, 0] = -yball[:, 0, 0]\n",
    "\n",
    "        else:\n",
    "            yball : np.ndarray = locations[:, :, 1, :]\n",
    "        \n",
    "        # Get the filename from the path\n",
    "        foldername = folder.name\n",
    "\n",
    "        # Get the arena and corridor numbers from the parent (corridor) and grandparent (arena) folder names\n",
    "        arena = file.parent.parent.name\n",
    "        corridor = file.parent.name\n",
    "        \n",
    "        # Get the metadata for this arena\n",
    "        arena_key = arena.capitalize()\n",
    "        arena_metadata = {var: metadata_dict[var][arena_key] for var in metadata_dict}\n",
    "        \n",
    "        Flynum += 1\n",
    "        \n",
    "        # Store the ball y positions and the arena and corridor numbers as metadata\n",
    "        data = {\"Fly\": \"Fly\" + str(Flynum),\n",
    "                \"yball\": yball[:, 0, 0], \n",
    "                \"experiment\": foldername,\n",
    "                \"arena\": arena, \n",
    "                \"corridor\": corridor}\n",
    "        data.update(arena_metadata)\n",
    "        Dataset = Dataset.append(data, ignore_index=True).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack yball positions\n",
    "\n",
    "Dataset = Dataset.explode(\"yball\")\n",
    "\n",
    "Dataset['Frame'] = Dataset.groupby('Fly').cumcount()\n",
    "\n",
    "Dataset['time'] = Dataset['Frame'] / 30\n",
    "#DataFrame['time'] = DataFrame.groupby(['experiment', 'arena', 'corridor']).cumcount() / 30\n",
    "\n",
    "#DataFrame['Fly'] = 'Fly' + (DataFrame.groupby(['experiment', 'arena', 'corridor']).ngroup() + 1).astype(str)\n",
    "\n",
    "Dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of \"Fed\" with \"fed\" in the 'FeedingState' column\n",
    "Dataset['FeedingState'] = Dataset['FeedingState'].replace('Fed', 'fed')\n",
    "\n",
    "# If there is 'Flipped' in the foldername, replace the correspondint 'Orientation' with 'flipped'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.loc[Dataset['experiment'].str.contains('Flipped'), 'Orientation'] = 'flipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Datasets\")\n",
    "checksave(\n",
    "    path=savepath.joinpath(\"FeedingState230811.feather\"),\n",
    "    object=\"dataframe\",\n",
    "    file=Dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maximum time value for each fly\n",
    "max_time = Dataset.groupby(\"Fly\")[\"time\"].max()\n",
    "\n",
    "# Compute the number of rows for each fly\n",
    "num_rows = Dataset.groupby(\"Fly\").size()\n",
    "\n",
    "# Display the results\n",
    "print(\"Maximum time value for each fly:\")\n",
    "print(max_time)\n",
    "print()\n",
    "print(\"Number of rows for each fly:\")\n",
    "print(num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print each possible value of 'Fly'\n",
    "print(Dataset['Fly'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightDataset = Dataset[Dataset['Light'] == 'on']\n",
    "\n",
    "GroupedDF = Dataset.groupby(['Orientation','time',])['yball'].mean().reset_index()\n",
    "\n",
    "GroupedDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique values of the column FeedingState\n",
    "feeding_states = GroupedDF['FeedingState'].unique()\n",
    "\n",
    "print(feeding_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a FacetGrid object with the 'Period' column as the row variable\n",
    "g = sns.FacetGrid(data=GroupedDF, row='Period')\n",
    "\n",
    "# Map a line plot of the 'yball' column over time to each facet, with the hue set to 'FeedingState'\n",
    "g.map(sns.lineplot, 'time', 'yball', 'FeedingState')\n",
    "\n",
    "# Add a legend to the plot\n",
    "g.add_legend()\n",
    "\n",
    "# Invert the y-axis of each Axes object in the FacetGrid\n",
    "for ax in g.axes.flat:\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(sns.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "# Plot the data for each period on a separate axis\n",
    "for i, period in enumerate(GroupedDF['Period'].unique()):\n",
    "    data = GroupedDF[GroupedDF['Period'] == period]\n",
    "    for feeding_state in data['FeedingState'].unique():\n",
    "        subset = data[data['FeedingState'] == feeding_state]\n",
    "        axes[i].plot(subset['time'], subset['yball'], label=feeding_state)\n",
    "    axes[i].set_title(period)\n",
    "    axes[i].invert_yaxis()\n",
    "\n",
    "# Add a legend to the first axis\n",
    "axes[0].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the data to only include rows where 'Light' == 'on'\n",
    "GroupedDF = GroupedDF[GroupedDF['Light'] == 'on']\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axes = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "# Plot the data for each period on a separate axis\n",
    "for i, period in enumerate(GroupedDF['Period'].unique()):\n",
    "    data = GroupedDF[GroupedDF['Period'] == period]\n",
    "    for feeding_state in data['FeedingState'].unique():\n",
    "        subset = data[data['FeedingState'] == feeding_state]\n",
    "        axes[i].plot(subset['time'], subset['yball'], label=feeding_state)\n",
    "    axes[i].set_title(period)\n",
    "    axes[i].invert_yaxis()\n",
    "\n",
    "# Add a legend to the first axis\n",
    "axes[0].legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define colors for each feeding state and light combination\n",
    "colors = {('fed', 'on'): 'C0', ('fed', 'off'): 'lightblue',\n",
    "          ('starved', 'on'): 'C1', ('starved', 'off'): 'lightgreen',\n",
    "          ('starved_noWater', 'on'): 'C2', ('starved_noWater', 'off'): 'pink'}\n",
    "\n",
    "# Plot the data for the PM period\n",
    "data = GroupedDF[GroupedDF['Period'] == 'PM']\n",
    "for feeding_state in data['FeedingState'].unique():\n",
    "    subset = data[data['FeedingState'] == feeding_state]\n",
    "    for light in subset['Light'].unique():\n",
    "        subsubset = subset[subset['Light'] == light]\n",
    "        linestyle = '-' if light == 'on' else '-'\n",
    "        label = f'{feeding_state} - Light {light}'\n",
    "        color = colors[(feeding_state, light)]\n",
    "        ax.plot(subsubset['time'], subsubset['yball'], linestyle=linestyle, color=color, label=label)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('PM')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add a legend to the axis\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to compute the confidence interval for a given array of values\n",
    "def confint(x, alpha=0.05):\n",
    "    # Check if the input array contains at least two values\n",
    "    if len(x) < 2:\n",
    "        # If not, return a tuple containing two nan values\n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "    # Compute the mean and standard error of the mean\n",
    "    mean = np.mean(x)\n",
    "    sem = stats.sem(x)\n",
    "    \n",
    "    # Compute the confidence interval\n",
    "    ci = stats.t.interval(1 - alpha, len(x) - 1, loc=mean, scale=sem)\n",
    "    \n",
    "    return ci\n",
    "\n",
    "# Apply the confint function to each group of rows in your original dataframe\n",
    "confint_df = DataFrame.groupby(['Period', 'time'])['yball'].apply(confint).reset_index()\n",
    "\n",
    "# Rename the columns of the resulting dataframe\n",
    "confint_df.columns = ['Period', 'time', 'yball_lower', 'yball_upper']\n",
    "\n",
    "# Merge the resulting dataframe with your grouped dataframe\n",
    "GroupedDF = pd.merge(GroupedDF, confint_df, on=['Period', 'time'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot of the 'yball' column over time, grouped by the 'Period' column\n",
    "sns.lineplot(data=GroupedDF, x='time', y='yball', hue='Period')\n",
    "\n",
    "# Add the confidence intervals to the plot\n",
    "for period, group in GroupedDF.groupby('Period'):\n",
    "    plt.fill_between(group['time'], group['yball_lower'], group['yball_upper'], alpha=0.1)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutants\n",
    "\n",
    "GroupedDF_TNT = Dataset.groupby(['Genotype','time',])['yball'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a line plot of the 'yball' column over time, colored by the 'Genotype' column\n",
    "sns.lineplot(data=GroupedDF_TNT, x='time', y='yball', hue='Genotype', linewidth=1)\n",
    "\n",
    "# Invert the y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
