{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../../../Utilities\")\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "\n",
    "import Ballpushing_utils\n",
    "import Utils\n",
    "import Processing\n",
    "import HoloviewsTemplates\n",
    "\n",
    "import importlib\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the list of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data path\n",
    "Datapath = Utils.get_data_path()\n",
    "\n",
    "# Get all folders with \"TNT_Fine\" in the name\n",
    "\n",
    "Folders = [\n",
    "    f for f in os.listdir(Datapath) if \"TNT_Fine\" in f and \"Tracked\" in f and os.path.isdir(Datapath / f)\n",
    "]\n",
    "\n",
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Ballpushing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Experiment objects from each folder\n",
    "\n",
    "Experiments = [Ballpushing_utils.Experiment(Datapath / f) for f in Folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some flies nicknames\n",
    "\n",
    "TestFly = Experiments[15].flies[3].nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestFly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Utils.get_labserver() / \"Experimental_data/MultiMazeRecorder/Datasets/240227_TNT_Fine_Experiments.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ballpushing_utils.save_object(Experiments, savepath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the experiments from the saved file\n",
    "Experiments = Ballpushing_utils.load_object(savepath.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Experiments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Ballpushing_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Ballpushing_utils.Dataset(Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each fly in the dataset, if they have 2 nicknames, just keep the first one\n",
    "# for fly in data.flies:\n",
    "#     if len(fly.nickname) > 1:\n",
    "#         fly.nickname = fly.nickname[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the above method as a hack to get rid of a supplementary nickname in PR flies. It is fixed directly in the brain region registry now and doesn't need to be used anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.generate_dataset(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[\"Nickname\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNa = mydata.dropna(subset=[\"FinalEvent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for non numeric values in FinalEvent\n",
    "\n",
    "noNa[noNa[\"FinalEvent\"].apply(lambda x: not isinstance(x, int))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate or missing indices\n",
    "\n",
    "noNa[noNa.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNa = noNa.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mydata[\"FinalEvent\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdim = [\"FinalEvent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in vdim:\n",
    "    if metric in data.data.columns:\n",
    "        print(f\"{metric} exists in the dataset.\")\n",
    "    else:\n",
    "        print(f\"{metric} does not exist in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame and 'vdim' is your metric\n",
    "print(f\"Data type for {vdim}: {mydata[vdim].dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique data types I have in the FinalEvent column\n",
    "noNa[\"FinalEvent\"].apply(lambda x: type(x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.jitter_boxplot(data.data, \"NumberEvents\", show=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of the data that removes None rows from \"FinalEvent\"\n",
    "\n",
    "subsetfinal = data.data.dropna(subset=[\"FinalEvent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.jitter_boxplot(subsetfinal, \"FinalEvent\", show=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting the data error\n",
    "\n",
    "I see that in some dataset loading I get: cannot reindex on an axis with duplicate labels\n",
    "Current dataset. Let's check these.\n",
    "\n",
    "First one is : 231222_TNT_Fine_1_Videos_Tracked_arena6_corridor5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fly that is named \"231222_TNT_Fine_1_Videos_Tracked_arena6_corridor5\"\n",
    "\n",
    "# Find which fly in the dataset has the name \"231222_TNT_Fine_1_Videos_Tracked_arena6_corridor5\"\n",
    "\n",
    "flyname = \"231222_TNT_Fine_1_Videos_Tracked_arena6_corridor5\"\n",
    "\n",
    "fly = [fly for fly in data.flies if fly.name == flyname][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the fly\n",
    "problematicFly = Ballpushing_utils.Dataset(fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematicFly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematicFly.generate_dataset(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly.arena_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematicFly.flies[0].nickname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on the data\n",
    "\n",
    "Here I'll try to do PCA on the data to see if I can get something interesting by reducing the dimensionality of the data, including all the summary metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to only include the label and metrics of interest\n",
    "subset = data.data[\n",
    "    [\n",
    "        \"NumberEvents\",\n",
    "        \"FinalEvent\",\n",
    "        \"FinalTime\",\n",
    "        \"SignificantEvents\",\n",
    "        \"SignificantFirst\",\n",
    "        \"SignificantFirstTime\",\n",
    "        \"CumulatedBreaks\",\n",
    "        \"Pushes\",\n",
    "        \"Pulls\",\n",
    "        \"Genotype\",\n",
    "        \"Brain region\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "# Separate the \"TNTxZ2018\" data from the rest of the data\n",
    "TNTxZ2018_data = PCA_components[PCA_components[\"Genotype\"] == \"TNTxZ2018\"]\n",
    "other_data = PCA_components[PCA_components[\"Genotype\"] != \"TNTxZ2018\"]\n",
    "\n",
    "# Generate one plot per Brain region\n",
    "for brain_region in PCA_components[\"Brain region\"].unique():\n",
    "    df_brain_region = other_data[other_data[\"Brain region\"] == brain_region]\n",
    "\n",
    "    # Create separate scatter plots for the \"TNTxZ2018\" genotype and the other genotypes\n",
    "    plot1 = df_brain_region.hvplot.scatter(\n",
    "        x=\"PC1\", y=\"PC2\", by=\"Genotype\", hover_cols=[\"Genotype\"], cmap=\"nipy_spectral\"\n",
    "    )\n",
    "    plot2 = TNTxZ2018_data.hvplot.scatter(\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        by=\"Genotype\",\n",
    "        hover_cols=[\"Genotype\"],\n",
    "        color=\"black\",\n",
    "        marker=\"x\",\n",
    "        size=100,\n",
    "    )\n",
    "\n",
    "    # Combine the plots\n",
    "    final_plot = plot1 * plot2\n",
    "\n",
    "    # Display the plot\n",
    "    hvplot.show(final_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "# Create a scatter plot for each brain region and genotype\n",
    "plot = PCA_components.hvplot.scatter(\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    by=\"Genotype\",\n",
    "    groupby=\"Brain region\",\n",
    "    hover_cols=[\"Genotype\"],\n",
    "    cmap=\"nipy_spectral\",\n",
    "    dynamic=False,\n",
    ")\n",
    "\n",
    "# Adjust the appearance of the \"TNTxZ2018\" points\n",
    "plot.opts(hv.opts.Scatter(\"TNTxZ2018\", size=100, marker=\"x\", color=\"black\"))\n",
    "\n",
    "# Display the plot\n",
    "hvplot.show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "\n",
    "# Separate the \"TNTxZ2018\" data from the rest of the data\n",
    "TNTxZ2018_data = PCA_components[PCA_components[\"Genotype\"] == \"TNTxZ2018\"]\n",
    "other_data = PCA_components[PCA_components[\"Genotype\"] != \"TNTxZ2018\"]\n",
    "\n",
    "# Initialize an empty Layout\n",
    "plots = hv.Layout()\n",
    "\n",
    "# Generate one plot per Brain region\n",
    "for brain_region in PCA_components[\"Brain region\"].unique():\n",
    "    df_brain_region = other_data[other_data[\"Brain region\"] == brain_region]\n",
    "\n",
    "    # Create separate scatter plots for the \"TNTxZ2018\" genotype and the other genotypes\n",
    "    plot1 = df_brain_region.hvplot.scatter(\n",
    "        x=\"PC1\", y=\"PC2\", by=\"Genotype\", hover_cols=[\"Genotype\"], cmap=\"nipy_spectral\"\n",
    "    )\n",
    "    plot2 = TNTxZ2018_data.hvplot.scatter(\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        by=\"Genotype\",\n",
    "        hover_cols=[\"Genotype\"],\n",
    "        color=\"black\",\n",
    "        marker=\"x\",\n",
    "        size=100,\n",
    "    )\n",
    "\n",
    "    # Combine the plots\n",
    "    final_plot = plot1 * plot2\n",
    "\n",
    "    # Add the plot to the Layout\n",
    "    plots += final_plot.relabel(f\"PCA - Brain Region: {brain_region}\")\n",
    "\n",
    "# Save the Layout\n",
    "hvplot.save(plots.cols(1), \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Plots/240222_PCA_plots.html\")\n",
    "# Display the Layout\n",
    "hvplot.show(plots.cols(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
