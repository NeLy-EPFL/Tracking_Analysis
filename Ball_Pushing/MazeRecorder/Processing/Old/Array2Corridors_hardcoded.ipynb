{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This code is an interactive version of Array2Corridors.py ; Its purpose is to help you understand the code and to troubleshoot it if needed by executing it step by step and visualizing the intermediate results.\n",
    "\n",
    "## 1. Importing the necessary libraries and defining the paths used in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpldatacursor\n",
    "import more_itertools as mit\n",
    "from pathlib import Path\n",
    "import os\n",
    "from scipy import signal\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path definitions\n",
    "\n",
    "inputfolder = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Feeding_state/230704_FeedingState_1_AM/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data and preparing the data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Load the first frame\n",
    "frame = cv2.imread(inputfolder.joinpath(\"image0.jpg\").as_posix())\n",
    "\n",
    "# If it's not already, make it grayscale\n",
    "if len(frame.shape) > 2:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# equalize the histogram to make thresholding easier\n",
    "frame = cv2.equalizeHist(frame)\n",
    "\n",
    "# rotate the image 90 degrees\n",
    "#frame = np.rot90(frame)\n",
    "\n",
    "# display the frame\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('off')\n",
    "im = ax.imshow(frame, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "mpldatacursor.datacursor()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the arenas in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Define and store the arena edges from the peaks locations\n",
    "# xcoords = colbounds[0]\n",
    "# ycoords = rowbounds[0]\n",
    "\n",
    "X1 = 0\n",
    "X2 = 620\n",
    "X3 = 1450\n",
    "X4 = 2130\n",
    "X5 = 2980\n",
    "X6 = 3590\n",
    "\n",
    "Y1 = 0\n",
    "Y2 = 725\n",
    "Y3 = 1140\n",
    "Y4 = 1860\n",
    "Y5 = 2350\n",
    "Y6 = 2995\n",
    "\n",
    "regions_of_interest = [\n",
    "    (X1, Y1, X2, Y2),\n",
    "    (X3, Y1, X4, Y2),\n",
    "    (X5, Y1, X6, Y2),\n",
    "    (X1, Y3, X2, Y4),\n",
    "    (X3, Y3, X4, Y4),\n",
    "    (X5, Y3, X6, Y4),\n",
    "    (X1, Y5, X2, Y6),\n",
    "    (X3, Y5, X4, Y6),\n",
    "    (X5, Y5, X6, Y6),\n",
    "]\n",
    "\n",
    "# Plot the regions of interest on the frame\n",
    "\n",
    "# fig, axs = plt.subplots(3, 3, figsize = (10,10))\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.axis('off')\n",
    "#     ax.imshow(\n",
    "#         frame[\n",
    "#             regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "#             regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "#         ],\n",
    "#         cmap=\"gray\",\n",
    "#         vmin=0,\n",
    "#         vmax=255,\n",
    "#     )\n",
    "    \n",
    "\n",
    "\n",
    "# plt.show()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(len(regions_of_interest)):\n",
    "    ax = fig.add_subplot(3, 3, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(\n",
    "        frame[\n",
    "            regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "            regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "        ],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = np.array(\n",
    "    frame[\n",
    "        regions_of_interest[5][1] : regions_of_interest[5][3],\n",
    "        regions_of_interest[5][0] : regions_of_interest[5][2],\n",
    "    ]\n",
    ")\n",
    "Thresh = subset.copy()\n",
    "# Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "Thresh = cv2.adaptiveThreshold(\n",
    "    Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    ")\n",
    "# plot the thresholded image\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('off')\n",
    "im = ax.imshow(Thresh, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = Thresh.sum(axis=0)\n",
    "rows = subset.sum(axis=1)\n",
    "\n",
    "colpeaks = signal.find_peaks(\n",
    "    cols,\n",
    "    distance=20,\n",
    "    height=(90_000, 120_000),\n",
    "    # width=(5, 30),\n",
    ")\n",
    "colpeaks = (colpeaks[0], colpeaks[1])\n",
    "\n",
    "# plot cols with the colpeaks\n",
    "fig, ax = plt.subplots()\n",
    "#plt.axis('off')\n",
    "ax.plot(cols)\n",
    "ax.plot(colpeaks[0], colpeaks[1][\"peak_heights\"], \"x\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowpeaks = signal.find_peaks(\n",
    "        rows,\n",
    "        distance=200,\n",
    "    )\n",
    "rowpeaks = (rowpeaks[0], rowpeaks[1])\n",
    "\n",
    "# plot rows with the rowpeaks\n",
    "fig, ax = plt.subplots()\n",
    "#plt.axis('off')\n",
    "ax.plot(rows)\n",
    "ax.plot(rowpeaks[0], rows[rowpeaks[0]], \"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each subset, find the cols and rows peaks and store the even peaks in a list\n",
    "Corridors = []\n",
    "for i in range(len(regions_of_interest)):\n",
    "    subset = np.array(\n",
    "        frame[\n",
    "            regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "            regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "        ]\n",
    "    )\n",
    "    Thresh = subset.copy()\n",
    "    # Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "    Thresh = cv2.adaptiveThreshold(\n",
    "        Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    "    )\n",
    "\n",
    "    cols = Thresh.sum(axis=0)\n",
    "    rows = subset.sum(axis=1)\n",
    "\n",
    "    colpeaks = signal.find_peaks(\n",
    "        cols,\n",
    "        distance=20,\n",
    "        height=(90_000, 120_000),\n",
    "        # width=(5, 30),\n",
    "    )\n",
    "    colpeaks = (colpeaks[0], colpeaks[1])\n",
    "\n",
    "    rowpeaks = signal.find_peaks(\n",
    "        rows,\n",
    "        distance=300,\n",
    "    )\n",
    "    #######################################################\n",
    "    Colpos = []\n",
    "    Rowpos = []\n",
    "\n",
    "    for peak_index in colpeaks[0]:\n",
    "        peak_x = regions_of_interest[i][0] + peak_index\n",
    "        peak_y = np.argmax(subset[peak_index])\n",
    "        peak_y += regions_of_interest[i][1]\n",
    "        Colpos.append((peak_x, peak_y))\n",
    "\n",
    "    for peak_index in rowpeaks[0]:\n",
    "        peak_x = np.argmax(subset[peak_index])\n",
    "        peak_x += regions_of_interest[i][0]\n",
    "        peak_y = regions_of_interest[i][1] + peak_index\n",
    "        Rowpos.append((peak_x, peak_y))\n",
    "\n",
    "    bound_x = 30\n",
    "    bound_y = 50\n",
    "\n",
    "    subcors = [\n",
    "        (\n",
    "            Colpos[0][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[1][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[2][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[3][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[4][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[5][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[6][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[7][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[8][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[9][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[10][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[11][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # subcors = generate_subsets(subset, regions_of_interest)\n",
    "\n",
    "    Corridors.append(subcors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I add a check to modify crops that could generate images with odd dimensions. This is not necessary but it makes the generated images easier to interface with ffmpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_corridors(Corridors):\n",
    "    for i in range(len(Corridors)):\n",
    "        for j in range(len(Corridors[i])):\n",
    "            corridor = list(Corridors[i][j])\n",
    "            height = corridor[3] - corridor[1]\n",
    "            width = corridor[2] - corridor[0]\n",
    "            if height % 2 != 0:\n",
    "                corridor[3] += 1\n",
    "            if width % 2 != 0:\n",
    "                corridor[2] += 1\n",
    "            Corridors[i][j] = tuple(corridor)\n",
    "    return Corridors\n",
    "\n",
    "\n",
    "Corridors = modify_corridors(Corridors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but with the corrected corridors\n",
    "fig, axs = plt.subplots(9, 6)\n",
    "for i in range(9):\n",
    "    for j in range(6):\n",
    "        axs[i, j].axis(\"off\")\n",
    "        axs[i, j].imshow(\n",
    "            frame[\n",
    "                Corridors[i][j][1] : Corridors[i][j][3],\n",
    "                Corridors[i][j][0] : Corridors[i][j][2],\n",
    "            ],\n",
    "            cmap=\"gray\",\n",
    "            vmin=0,\n",
    "            vmax=255,\n",
    "        )\n",
    "        \n",
    "# Remove the axis of each subplot and draw them closer together\n",
    "for ax in axs.flat:\n",
    "    ax.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All first steps in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpldatacursor\n",
    "import more_itertools as mit\n",
    "from pathlib import Path\n",
    "import os\n",
    "from scipy import signal\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "# Path definitions\n",
    "\n",
    "inputfolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Feeding_state/230704_FeedingState_1_AM/\")\n",
    "processedfolder = inputfolder.parent / f\"{inputfolder.stem}_Cropped\"\n",
    "\n",
    "# Load the first frame\n",
    "frame = cv2.imread(inputfolder.joinpath(\"image0.jpg\").as_posix())\n",
    "\n",
    "# If it's not already, make it grayscale\n",
    "if len(frame.shape) > 2:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# equalize the histogram to make thresholding easier\n",
    "frame = cv2.equalizeHist(frame)\n",
    "\n",
    "# Crop the image to the regions of interest\n",
    "\n",
    "X1 = 0\n",
    "X2 = 620\n",
    "X3 = 1450\n",
    "X4 = 2130\n",
    "X5 = 2980\n",
    "X6 = 3590\n",
    "\n",
    "Y1 = 0\n",
    "Y2 = 725\n",
    "Y3 = 1140\n",
    "Y4 = 1860\n",
    "Y5 = 2350\n",
    "Y6 = 2995\n",
    "\n",
    "regions_of_interest = [\n",
    "    (X1, Y1, X2, Y2),\n",
    "    (X3, Y1, X4, Y2),\n",
    "    (X5, Y1, X6, Y2),\n",
    "    (X1, Y3, X2, Y4),\n",
    "    (X3, Y3, X4, Y4),\n",
    "    (X5, Y3, X6, Y4),\n",
    "    (X1, Y5, X2, Y6),\n",
    "    (X3, Y5, X4, Y6),\n",
    "    (X5, Y5, X6, Y6),\n",
    "]\n",
    "\n",
    "# For each subset, find the cols and rows peaks and store the even peaks in a list\n",
    "Corridors = []\n",
    "for i in range(len(regions_of_interest)):\n",
    "    subset = np.array(\n",
    "        frame[\n",
    "            regions_of_interest[i][1] : regions_of_interest[i][3],\n",
    "            regions_of_interest[i][0] : regions_of_interest[i][2],\n",
    "        ]\n",
    "    )\n",
    "    Thresh = subset.copy()\n",
    "    # Apply an adaptive threshold to each subset to keep only the brightest pixels\n",
    "    Thresh = cv2.adaptiveThreshold(\n",
    "        Thresh, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 4\n",
    "    )\n",
    "\n",
    "    cols = Thresh.sum(axis=0)\n",
    "    rows = subset.sum(axis=1)\n",
    "\n",
    "    colpeaks = signal.find_peaks(\n",
    "        cols,\n",
    "        distance=20,\n",
    "        height=(80_000, 120_000),\n",
    "        # width=(5, 30),\n",
    "    )\n",
    "    colpeaks = (colpeaks[0], colpeaks[1])\n",
    "\n",
    "    rowpeaks = signal.find_peaks(\n",
    "        rows,\n",
    "        distance=300,\n",
    "    )\n",
    "    #######################################################\n",
    "    Colpos = []\n",
    "    Rowpos = []\n",
    "\n",
    "    for peak_index in colpeaks[0]:\n",
    "        peak_x = regions_of_interest[i][0] + peak_index\n",
    "        peak_y = np.argmax(subset[peak_index])\n",
    "        peak_y += regions_of_interest[i][1]\n",
    "        Colpos.append((peak_x, peak_y))\n",
    "\n",
    "    for peak_index in rowpeaks[0]:\n",
    "        peak_x = np.argmax(subset[peak_index])\n",
    "        peak_x += regions_of_interest[i][0]\n",
    "        peak_y = regions_of_interest[i][1] + peak_index\n",
    "        Rowpos.append((peak_x, peak_y))\n",
    "\n",
    "    bound_x = 30\n",
    "    bound_y = 60\n",
    "\n",
    "    subcors = [\n",
    "        (\n",
    "            Colpos[0][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[1][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[2][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[3][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[4][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[5][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[6][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[7][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[8][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[9][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "        (\n",
    "            Colpos[10][0] - bound_x,\n",
    "            Rowpos[0][1] - bound_y,\n",
    "            Colpos[11][0] + bound_x,\n",
    "            Rowpos[1][1] + bound_y,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # subcors = generate_subsets(subset, regions_of_interest)\n",
    "\n",
    "    Corridors.append(subcors)\n",
    "    \n",
    "def modify_corridors(Corridors):\n",
    "    for i in range(len(Corridors)):\n",
    "        for j in range(len(Corridors[i])):\n",
    "            corridor = list(Corridors[i][j])\n",
    "            height = corridor[3] - corridor[1]\n",
    "            width = corridor[2] - corridor[0]\n",
    "            if height % 2 != 0:\n",
    "                corridor[3] += 1\n",
    "            if width % 2 != 0:\n",
    "                corridor[2] += 1\n",
    "            Corridors[i][j] = tuple(corridor)\n",
    "    return Corridors\n",
    "\n",
    "\n",
    "Corridors = modify_corridors(Corridors)\n",
    "\n",
    "\n",
    "# Same as above but with the corrected corridors\n",
    "fig, axs = plt.subplots(9, 6, figsize=(20, 20))\n",
    "for i in range(9):\n",
    "    for j in range(6):\n",
    "        axs[i, j].axis(\"off\")\n",
    "        axs[i, j].imshow(\n",
    "            frame[\n",
    "                Corridors[i][j][1] : Corridors[i][j][3],\n",
    "                Corridors[i][j][0] : Corridors[i][j][2],\n",
    "            ],\n",
    "            cmap=\"gray\",\n",
    "            vmin=0,\n",
    "            vmax=255,\n",
    "        )\n",
    "        \n",
    "# Remove the axis of each subplot and draw them closer together\n",
    "for ax in axs.flat:\n",
    "    ax.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "croppedfile = processedfolder.joinpath(\"crop_check.png\")\n",
    "if croppedfile.is_file():\n",
    "    user_input = input(\"File already exists. Do you want to replace it? (y/n): \")\n",
    "    if user_input.lower() == 'y':\n",
    "        plt.savefig(str(croppedfile), dpi=300, bbox_inches=\"tight\")\n",
    "else:\n",
    "    plt.savefig(str(croppedfile), dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(str(processedfolder.joinpath(\"crop_check.png\")), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "# Reduce the space between subplots\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "# As an example, display all the corridors from Corridors[0] in a grid based on the frame\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(\n",
    "        frame[\n",
    "            Corridors[0][i][1] : Corridors[0][i][3],\n",
    "            Corridors[0][i][0] : Corridors[0][i][2],\n",
    "        ],\n",
    "        cmap=\"gray\",\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Use the generated coordinates to save corridor crops for each frame of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the images in the target folder\n",
    "folder = Path(\"/home/matthias/Videos/Subset_Test2/\")\n",
    "processedfolder = Path(\"/home/matthias/Videos/Subset_Test2_Cropped/\")\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "processedfolder.mkdir(exist_ok=True)\n",
    "\n",
    "# Get a list of all image files in the input folder\n",
    "images = [f.name for f in folder.glob(\"*\") if f.is_file()]\n",
    "\n",
    "# Sort the list of images by their number\n",
    "images.sort(key=lambda f: int(re.sub(\"\\D\", \"\", f)))\n",
    "\n",
    "for i, image in tqdm(enumerate(images), total=len(images)):\n",
    "    # Read and process the image\n",
    "    frame = cv2.imread(str(folder / image))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = np.rot90(frame)\n",
    "\n",
    "    for j, subset in enumerate(Corridors):\n",
    "        for k, corridor in enumerate(subset):\n",
    "            # Create the subfolder if it doesn't exist\n",
    "            subfolder = processedfolder / f\"arena{j+1}\" / f\"corridor_{k+1}\"\n",
    "            subfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Crop the image\n",
    "            x1, y1, x2, y2 = corridor\n",
    "            cropped_image = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Save the cropped image\n",
    "            cropped_image_file = f\"{Path(image).stem}_cropped.jpg\"\n",
    "            cv2.imwrite(str(subfolder / cropped_image_file), cropped_image)\n",
    "            \n",
    "    if i == 0:\n",
    "        plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "        # Draw a bigger plotting area to display the corridors\n",
    "        plt.figure(figsize=(30, 20))\n",
    "\n",
    "        # Display all the crops corresponding to the corridors of each arena\n",
    "\n",
    "        fig, axs = plt.subplots(9, 6)\n",
    "        for u in range(9):\n",
    "            for j in range(6):\n",
    "                axs[u, j].imshow(\n",
    "                    frame[\n",
    "                        Corridors[u][j][1] : Corridors[u][j][3],\n",
    "                        Corridors[u][j][0] : Corridors[u][j][2],\n",
    "                    ],\n",
    "                    cmap=\"gray\",\n",
    "                    vmin=0,\n",
    "                    vmax=255,\n",
    "                )\n",
    "                \n",
    "        # Remove the axis of each subplot and draw them closer together\n",
    "        for ax in axs.flat:\n",
    "            ax.axis(\"off\")\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we checked that everything is working fine on the subset, we can run the code on the whole sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the images in the target folder\n",
    "folder = inputfolder\n",
    "processedfolder = inputfolder.parent / f\"{inputfolder.stem}_Cropped\"\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "#processedfolder.mkdir(exist_ok=True)\n",
    "processedfolder.joinpath(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_image(image):\n",
    "    # Read and process the image\n",
    "    frame = cv2.imread(str(folder / image))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame = np.rot90(frame)\n",
    "\n",
    "    for j, subset in enumerate(Corridors):\n",
    "        for k, corridor in enumerate(subset):\n",
    "            # Get the subfolder for this arena and corridor\n",
    "            subfolder = processedfolder / f\"arena{j+1}\" / f\"corridor_{k+1}\"\n",
    "\n",
    "            # Crop the image\n",
    "            x1, y1, x2, y2 = corridor\n",
    "            cropped_image = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Save the cropped image\n",
    "            cropped_image_file = f\"{Path(image).stem}_cropped.jpg\"\n",
    "            cv2.imwrite(str(subfolder / cropped_image_file), cropped_image)\n",
    "\n",
    "\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "processedfolder.mkdir(exist_ok=True)\n",
    "\n",
    "# Get a list of all image files in the input folder\n",
    "images = [f.name for f in folder.glob(\"*.[jJ][pP][gG]\") if f.is_file()]\n",
    "\n",
    "# Sort the list of images by their number\n",
    "images.sort(key=lambda f: int(re.sub(\"\\D\", \"\", f)))\n",
    "\n",
    "# Create the subfolders for each arena and corridor\n",
    "for j, subset in enumerate(Corridors):\n",
    "    for k, corridor in enumerate(subset):\n",
    "        subfolder = processedfolder / f\"arena{j+1}\" / f\"corridor_{k+1}\"\n",
    "        subfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process the images in parallel using a process pool\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_image, images), total=len(images)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video writing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath = processedfolder.parent / f\"{processedfolder.stem}_Subsets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subfolder if it doesn't exist\n",
    "subpath.mkdir(exist_ok=True)\n",
    "\n",
    "# Compute the number of images corresponding to 15 minutes\n",
    "n_images = 15 * 60 * 30\n",
    "\n",
    "# For each corridor folder in the processed folder, create a subset folder with only n_images images\n",
    "\n",
    "for arena in processedfolder.glob(\"arena*\"):\n",
    "    for corridor in arena.glob(\"corridor*\"):\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        subfolder = subpath / arena.name / corridor.name\n",
    "        subfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Get a list of all image files in the input folder\n",
    "        images = [f.name for f in corridor.glob(\"*.[jJ][pP][gG]\") if f.is_file()]\n",
    "\n",
    "        # Sort the list of images by their number\n",
    "        images.sort(key=lambda f: int(re.sub(\"\\D\", \"\", f)))\n",
    "\n",
    "        # Copy the first n_images images to the subset folder\n",
    "        for image in images[:n_images]:\n",
    "            shutil.copy(str(corridor / image), str(subfolder / image))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes 3:50 min to process "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important note: current ffmpeg method can be used outside of the notebook using Images2Vids.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the root folder containing the subfolders\n",
    "root_folder = Path(\"/home/matthias/Videos/Test2_subsets\")\n",
    "\n",
    "# define the path to the output 'videos' folder\n",
    "videos_folder = Path(\"/home/matthias/Videos/Test2_Videos/Videos_NumOrdered\")\n",
    "videos_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# define the output video parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # video codec\n",
    "fps = 30  # frames per second\n",
    "\n",
    "# create a progress bar for the whole process\n",
    "pbar = tqdm(total=len(list(root_folder.glob(\"*/*\"))))\n",
    "\n",
    "\n",
    "def sort_by_number(filename):\n",
    "    # extract the number from the filename using a regular expression\n",
    "    number = re.search(r\"\\d+\", filename.name)\n",
    "    if number:\n",
    "        return int(number.group())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# iterate over the subfolders that are one level below the root folder\n",
    "for subdir in root_folder.glob(\"*/*\"):\n",
    "    if not subdir.is_dir():\n",
    "        continue\n",
    "\n",
    "    # read the first image in the subfolder to determine the frame size\n",
    "    first_image_path = list(subdir.glob(\"*\"))[0]\n",
    "    first_image = cv2.imread(str(first_image_path))\n",
    "    if first_image is None:\n",
    "        print(f\"Error: Failed to read image {first_image_path}\")\n",
    "        continue\n",
    "\n",
    "    height, width, _ = first_image.shape\n",
    "    frame_size = (width, height)\n",
    "\n",
    "    # generate a unique output video filename from the subfolder name\n",
    "    video_filename = videos_folder / f\"{subdir.parent.name}_{subdir.name}.mp4\"\n",
    "\n",
    "    # open a VideoWriter object for the current subfolder\n",
    "    out = cv2.VideoWriter(str(video_filename), fourcc, fps, frame_size)\n",
    "\n",
    "    # iterate over the images in the current subfolder sorted by number\n",
    "    for filename in sorted(subdir.glob(\"*\"), key=sort_by_number):\n",
    "        # read the image\n",
    "        image = cv2.imread(str(filename))\n",
    "        if image is None:\n",
    "            print(f\"Error: Failed to read image {filename}\")\n",
    "            continue\n",
    "\n",
    "        # convert the image from BGR to RGB color space (if necessary)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # write the image to the video\n",
    "        out.write(image)\n",
    "\n",
    "    # release the VideoWriter object\n",
    "    out.release()\n",
    "\n",
    "    # update the progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# close the progress bar\n",
    "pbar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "folder_path = processedfolder\n",
    "output_folder = inputfolder.parent / f\"{inputfolder.stem}_ProcessedVidsFFMPEG\"\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = \"30\"\n",
    "\n",
    "f = folder_path.joinpath(\"arena1/corridor_1\").as_posix()\n",
    "\n",
    "terminal_call = \"ffmpeg -r \"+fps+\" -i \"+f+\"/image%d_cropped.jpg -pix_fmt yuv420p -c:v libx265 -x265-params log-level=error -vsync 0 -crf 15 \"+ output_folder.as_posix() + \"Test.mp4\"\n",
    "os.system(terminal_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_video_from_images(images_folder, output_folder, video_name, fps):\n",
    "    f = images_folder.as_posix()\n",
    "    terminal_call = f\"ffmpeg -hwaccel cuda -r {fps} -i {f}/image%d_cropped.jpg -pix_fmt yuv420p -c:v libx265 -x265-params log-level=error -vsync 0 -crf 15 {output_folder.as_posix()}/{video_name}.mp4\"\n",
    "    os.system(terminal_call)\n",
    "\n",
    "def search_folder_for_images(folder_path, output_folder, fps):\n",
    "    for subdir, dirs, files in os.walk(folder_path):\n",
    "        if any(file.endswith('.jpg') for file in files):\n",
    "            video_name = '_'.join(Path(subdir).parts[-2:])\n",
    "            create_video_from_images(Path(subdir), output_folder, video_name, fps)\n",
    "\n",
    "fps = \"30\"\n",
    "search_folder_for_images(folder_path, output_folder, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images(images_folder, output_folder, video_name, fps):\n",
    "    f = images_folder.as_posix()\n",
    "    video_path = f\"{output_folder.as_posix()}/{video_name}.mp4\"\n",
    "    if not os.path.exists(video_path):\n",
    "        terminal_call = f\"ffmpeg -loglevel panic -nostats -hwaccel cuda -r {fps} -i {f}/image%d_cropped.jpg -pix_fmt yuv420p -c:v libx265 -x265-params log-level=error -vsync 0 -crf 15 {video_path}\"\n",
    "        os.system(terminal_call)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def search_folder_for_images(folder_path, output_folder, fps):\n",
    "    subdirs = []\n",
    "    for subdir, dirs, files in os.walk(folder_path):\n",
    "        if any(file.endswith('.jpg') for file in files):\n",
    "            subdirs.append(subdir)\n",
    "    with tqdm(total=len(subdirs), desc=\"Processing videos\") as pbar:\n",
    "        for subdir in subdirs:\n",
    "            video_name = '_'.join(Path(subdir).parts[-2:])\n",
    "            create_video_from_images(Path(subdir), output_folder, video_name, fps)\n",
    "            pbar.update(1)\n",
    "\n",
    "fps = \"30\"\n",
    "search_folder_for_images(folder_path, output_folder, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO improve the progress bar to increment more quickly when the videos already exist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the folders to process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define a path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = Path(\"~/Videos/\")\n",
    "\n",
    "inputfolder = datafolder.joinpath(\"Feeding_state/230704_FeedingState_1_AM/\")\n",
    "\n",
    "print(inputfolder.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path definitions\n",
    "\n",
    "datafolder = Path(\"/home/matthias/Videos/\")\n",
    "# For directories and subdirectories within the datafolder, if they contain images and do not have '_Cropped' in their name, add them to the list of folders to process\n",
    "                                \n",
    "inputfolder = datafolder.joinpath(\"230704_FeedingState_1_AM\")\n",
    "\n",
    "print(inputfolder.as_posix())\n",
    "# Load the first frame\n",
    "frame = cv2.imread(inputfolder.joinpath(\"image0.jpg\").as_posix())\n",
    "# Display the frame\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each directory in the datafolder, check if there is another directory with the same name and '_Cropped' appended\n",
    "# If there is, skip this directory\n",
    "# If there isn't, check if there are images in the directory\n",
    "\n",
    "def check_integrity(folder, source_folder):\n",
    "    if len(list(folder.iterdir())) != 9:\n",
    "        return False\n",
    "    source_image_count = len(list(source_folder.glob('*.png'))) + len(list(source_folder.glob('*.jpg')))\n",
    "    for subfolder in folder.iterdir():\n",
    "        if not subfolder.is_dir() or len(list(subfolder.iterdir())) != 6:\n",
    "            return False\n",
    "        for subsubfolder in subfolder.iterdir():\n",
    "            if not subsubfolder.is_dir():\n",
    "                return False\n",
    "            image_count = len(list(subsubfolder.glob('*.png'))) + len(list(subsubfolder.glob('*.jpg')))\n",
    "            if image_count != source_image_count:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def check_processed(data_folder):\n",
    "    data_folder = Path(data_folder)\n",
    "    for folder in data_folder.iterdir():\n",
    "        if folder.is_dir() and not folder.name.endswith('_Cropped'):\n",
    "            cropped_folder = folder.name + '_Cropped'\n",
    "            cropped_folder_path = data_folder / cropped_folder\n",
    "            if cropped_folder_path.exists():\n",
    "                if check_integrity(cropped_folder_path, folder):\n",
    "                    print(f\"{folder.name} is already processed and its integrity is verified.\")\n",
    "                else:\n",
    "                    print(f\"{folder.name} is already processed but its integrity is not verified.\")\n",
    "                    remove = input(f\"Do you want to remove the {cropped_folder} folder? (y/n): \")\n",
    "                    if remove.lower() == 'y':\n",
    "                        shutil.rmtree(cropped_folder_path)\n",
    "                        print(f\"{cropped_folder} folder removed.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"{folder.name} is not processed.\")\n",
    "                # call your image processing function here\n",
    "                \n",
    "check_processed(datafolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_integrity(folder, source_folder):\n",
    "    folder_items = list(folder.iterdir())\n",
    "    # Check for exactly one image file in folder\n",
    "    image_count = len(list(folder.glob(\"*.png\"))) + len(list(folder.glob(\"*.jpg\")))\n",
    "    if image_count != 1:\n",
    "        print(f\"Cropped check image not found!\")\n",
    "        return False\n",
    "    else: print(f\"Cropped check image found...\")\n",
    "    # Check for exactly 9 subfolders in folder\n",
    "    subfolder_count = sum(1 for item in folder_items if item.is_dir())\n",
    "    if subfolder_count != 9:\n",
    "        print(f\"Number of subfolders in folder: {subfolder_count}\")\n",
    "        return False\n",
    "    else: print(f\"all arenas found...\")\n",
    "    source_image_count = len(list(source_folder.glob(\"*.png\"))) + len(\n",
    "        list(source_folder.glob(\"*.jpg\"))\n",
    "    )\n",
    "    for subfolder in folder.iterdir():\n",
    "        if not subfolder.is_dir():\n",
    "            continue\n",
    "        if len(list(subfolder.iterdir())) != 6:\n",
    "            print(f\"Number of subsubfolders in subfolder: {len(list(subfolder.iterdir()))}\")\n",
    "            return False\n",
    "        else: print(f\"all corridors found...\")\n",
    "        for subsubfolder in subfolder.iterdir():\n",
    "            if not subsubfolder.is_dir():\n",
    "                return False\n",
    "            image_count = len(list(subsubfolder.glob(\"*.png\"))) + len(\n",
    "                list(subsubfolder.glob(\"*.jpg\"))\n",
    "            )\n",
    "            if image_count != source_image_count:\n",
    "                print(f\"Image count for folder: {subsubfolder.name} is {image_count} instead of {source_image_count}\")\n",
    "                return False\n",
    "    print(f\"Folder {folder.name} is verified.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "datafolder = Path(\"/home/matthias/Videos/\")\n",
    "\n",
    "check_integrity(datafolder.joinpath(\"230704_FeedingState_1_AM_Cropped\"), datafolder.joinpath(\"230704_FeedingState_1_AM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder = Path(\"/Volumes/Ramdya-lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/Feeding_state/230704_FeedingState_1_AM_Cropped/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each folder and subfolder within the inputfolder, get the first image and store it in a list\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(inputfolder.as_posix()):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg') or file.endswith('.png'):\n",
    "            image_list.append(os.path.join(root, file))\n",
    "            break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "fig = plt.figure(figsize=(10., 10.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "                 nrows_ncols=(3, 3),\n",
    "                 axes_pad=0.1,\n",
    "                 )\n",
    "\n",
    "for i in range(9):\n",
    "    image = Image.open(image_list[i])\n",
    "    grid[i].imshow(image)\n",
    "\n",
    "plt.show()   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 10.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "                 nrows_ncols=(9, 6),\n",
    "                 axes_pad=0.1,\n",
    "                 )\n",
    "\n",
    "for i in range(9):\n",
    "    image = Image.open(image_list[i])\n",
    "    grid[i].imshow(image)\n",
    "\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackinganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
