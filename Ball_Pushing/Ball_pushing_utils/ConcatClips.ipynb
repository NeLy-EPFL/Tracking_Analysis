{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about creating concatenated interaction events from the source video and fly and ball positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "# from Utilities.Utils import *\n",
    "# from Utilities.Processing import *\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "\n",
    "import os\n",
    "os.environ[\"IMAGEMAGICK_BINARY\"] = \"/usr/bin/convert\"  # Replace with your actual path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "These are the same as FlyBall_interactions.py. In the end I'll probably make sure these are inherited from the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def savgol_lowpass_filter(data, window_length, polyorder):\n",
    "    # Apply the Savitzky-Golay filter\n",
    "    y = signal.savgol_filter(data, window_length, polyorder)\n",
    "    return y\n",
    "\n",
    "def extract_coordinates(h5_file):\n",
    "    with h5py.File(h5_file, \"r\") as f:\n",
    "        locs = f[\"tracks\"][:].T\n",
    "        y = locs[:, :, 1, :].squeeze()\n",
    "        x = locs[:, :, 0, :].squeeze()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def replace_nans_with_previous_value(arr):\n",
    "    # Find the indices of the NaN values\n",
    "    nan_indices = np.where(np.isnan(arr))\n",
    "\n",
    "    # Replace the NaN values with the previous value\n",
    "    for i in nan_indices[0]:\n",
    "        arr[i] = arr[i - 1]\n",
    "\n",
    "\n",
    "def extract_interaction_events(ballpath, flypath, Thresh=80, min_time=60):\n",
    "    \"\"\"\n",
    "    Extracts the interaction events from the ball and fly paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ballpath : str\n",
    "        The path to the ball path file.\n",
    "        flypath : str\n",
    "        The path to the fly path file.\n",
    "        Thresh : int\n",
    "        The threshold distance between the ball and fly.\n",
    "        min_time : int\n",
    "        The minimum duration of an interaction event.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_events : list\n",
    "        A list of DataFrames containing the interaction events.\n",
    "    \"\"\"\n",
    "    xball, yball = extract_coordinates(ballpath.as_posix())\n",
    "    xfly, yfly = extract_coordinates(flypath.as_posix())\n",
    "\n",
    "    # Replace NaNs in yball\n",
    "    replace_nans_with_previous_value(yball)\n",
    "\n",
    "    # Replace NaNs in xball\n",
    "    replace_nans_with_previous_value(xball)\n",
    "\n",
    "    # Replace NaNs in yfly\n",
    "    replace_nans_with_previous_value(yfly)\n",
    "\n",
    "    # Replace NaNs in xfly\n",
    "    replace_nans_with_previous_value(xfly)\n",
    "\n",
    "    # Combine the yball and yfly arrays into a single 2D array\n",
    "    data = np.stack((yball, yfly), axis=1)\n",
    "\n",
    "    # Create a pandas DataFrame from the data\n",
    "    df = pd.DataFrame(data, columns=[\"yball\", \"yfly\"])\n",
    "\n",
    "    df[\"yball_smooth\"] = savgol_lowpass_filter(df[\"yball\"], 221, 1)\n",
    "    df[\"yfly_smooth\"] = savgol_lowpass_filter(df[\"yfly\"], 221, 1)\n",
    "    df = df.assign(Frame=df.index + 1)\n",
    "    df[\"time\"] = df[\"Frame\"] / 30\n",
    "\n",
    "    # Compute the difference between the yball and yfly positions smoothed\n",
    "    df[\"dist\"] = df[\"yfly_smooth\"] - df[\"yball_smooth\"]\n",
    "\n",
    "    # Locate where the distance is below the threshold\n",
    "    df[\"close\"] = df[\"dist\"] < Thresh\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Find the start and end indices of streaks of True values in the 'close' column\n",
    "    df[\"block\"] = (df[\"close\"].shift(1) != df[\"close\"]).cumsum()\n",
    "    events = (\n",
    "        df[df[\"close\"]]\n",
    "        .groupby(\"block\")\n",
    "        .agg(start=(\"index\", \"min\"), end=(\"index\", \"max\"))\n",
    "    )\n",
    "\n",
    "    # Store the interaction events as separate DataFrames\n",
    "    interaction_events = [\n",
    "        df.loc[start:end]\n",
    "        for start, end in events[[\"start\", \"end\"]].itertuples(index=False)\n",
    "    ]\n",
    "\n",
    "    # remove events that are less than min_time frames long\n",
    "    interaction_events = [\n",
    "        event for event in interaction_events if len(event) >= min_time\n",
    "    ]\n",
    "\n",
    "    # event_times = [(df[\"time\"].min(), df[\"time\"].max()) for df in interaction_events]\n",
    "\n",
    "    return interaction_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "ballpath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/corridor3_tracked.000_corridor3.analysis.h5\"\n",
    ")\n",
    "\n",
    "flypath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/flytrack.000_corridor3.analysis.h5\"\n",
    ")\n",
    "\n",
    "vidpath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/corridor3.mp4\"\n",
    ")\n",
    "\n",
    "interaction_events = extract_interaction_events(ballpath, flypath)\n",
    "\n",
    "OutFolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Grids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def check_yball_variation(event_df, threshold=10):\n",
    "    yball_segment = event_df['yball_smooth']\n",
    "    variation = yball_segment.max() - yball_segment.min()\n",
    "    return variation > threshold\n",
    "\n",
    "clips = []\n",
    "# Assuming interaction_events is a list of dataframes\n",
    "for i, event_df in enumerate(interaction_events):\n",
    "    start_frame, end_frame = event_df['Frame'].min(), event_df['Frame'].max()\n",
    "    start_time, end_time = event_df['time'].min(), event_df['time'].max()  # Assuming 'time' is in seconds\n",
    "    start_time_str = str(timedelta(seconds=int(start_time)))\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(str(vidpath))\n",
    "\n",
    "    # Get the video's width, height, and frames per second (fps)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lower case\n",
    "    \n",
    "    clip_path = OutFolder.joinpath(f\"output_{i}.mp4\").as_posix()\n",
    "    \n",
    "    out = cv2.VideoWriter(clip_path, fourcc, fps, (height, width))  # Note that width and height are swapped\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    for _ in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Rotate frame 90 degrees clockwise\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # Write some Text\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = f\"Event:{i+1} - start:{start_time_str}\"\n",
    "        font_scale = width / 150\n",
    "        thickness = int(4 * font_scale)\n",
    "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        \n",
    "        # Position the text at the top center of the frame\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "        text_y = 25\n",
    "        cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Check if yball value varies more than threshold\n",
    "        if check_yball_variation(event_df):  # You need to implement this function\n",
    "            # Add red dot to segment\n",
    "            dot = np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "            dot[:, :, 0] = 0\n",
    "            dot[:, :, 1] = 0\n",
    "            dot[:, :, 2] = 255\n",
    "            dot = cv2.resize(dot, (20, 20))\n",
    "            \n",
    "            # Position the dot right next to the text at the top of the frame\n",
    "            dot_x = text_x + text_size[0] + 10  # Position the dot right next to the text with a margin of 10\n",
    "            \n",
    "            # Adjusted position for dot_y to make it slightly higher\n",
    "            dot_y_adjustment_factor = 1.2  \n",
    "            dot_y = text_y - int(dot.shape[0] * dot_y_adjustment_factor) + text_size[1] // 2\n",
    "            \n",
    "            frame[dot_y:dot_y+dot.shape[0], dot_x:dot_x+dot.shape[1]] = dot\n",
    "\n",
    "        # Write the frame into the output file\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything when done\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    clips.append(clip_path)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec and create a VideoWriter object for the final video\n",
    "out = cv2.VideoWriter(OutFolder.joinpath('final_output.mp4').as_posix(), fourcc, fps, (height, width)) # Note that width and height are swapped\n",
    "\n",
    "# Assuming 'clips' is a list of paths to the clip files\n",
    "for clip_path in clips:\n",
    "    cap = cv2.VideoCapture(clip_path)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Write the frame into the final output file\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Release the final output file when done\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Grids/output.mp4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OutFolder.joinpath(\"output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def check_yball_variation(event_df, threshold=10):\n",
    "    yball_segment = event_df['yball_smooth']\n",
    "    variation = yball_segment.max() - yball_segment.min()\n",
    "    return variation > threshold\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(str(vidpath))\n",
    "\n",
    "# Get a frame from the video\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # Change this to any frame number you want to test\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Failed to read frame from video\")\n",
    "else:\n",
    "    # Rotate frame 90 degrees clockwise\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    # Write some Text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = \"Test Text\"\n",
    "    font_scale = 1.0\n",
    "    thickness = 2\n",
    "\n",
    "    # Calculate the size of the text box\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    \n",
    "    # Position the text at the top center of the frame\n",
    "    text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "    text_y = 50\n",
    "\n",
    "    # Add the text to the frame\n",
    "    cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Create a red dot\n",
    "    dot = np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "    dot[:, :, 0] = 0\n",
    "    dot[:, :, 1] = 0\n",
    "    dot[:, :, 2] = 255\n",
    "    dot = cv2.resize(dot, (20, 20))\n",
    "    \n",
    "    # Position the dot right next to the text at the top of the frame\n",
    "    dot_x = text_x + text_size[0] + 10  # Position the dot right next to the text with a margin of 10\n",
    "    \n",
    "    # Adjusted position for dot_y to make it slightly higher\n",
    "    dot_y_adjustment_factor = 1.5  \n",
    "    dot_y = text_y - int(dot.shape[0] * dot_y_adjustment_factor) + text_size[1] // 2\n",
    "    \n",
    "    # Add the dot to the frame\n",
    "    frame[dot_y:dot_y+dot.shape[0], dot_x:dot_x+dot.shape[1]] = dot\n",
    "\n",
    "# Display the frame\n",
    "cv2.imshow('Test Frame', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
