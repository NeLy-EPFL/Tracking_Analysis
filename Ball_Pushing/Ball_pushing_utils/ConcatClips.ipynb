{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about creating concatenated interaction events from the source video and fly and ball positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "# from Utilities.Utils import *\n",
    "# from Utilities.Processing import *\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "import platform\n",
    "import json\n",
    "\n",
    "import os\n",
    "os.environ[\"IMAGEMAGICK_BINARY\"] = \"/usr/bin/convert\"  # Replace with your actual path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "These are the same as FlyBall_interactions.py. In the end I'll probably make sure these are inherited from the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def savgol_lowpass_filter(data, window_length, polyorder):\n",
    "    # Apply the Savitzky-Golay filter\n",
    "    y = signal.savgol_filter(data, window_length, polyorder)\n",
    "    return y\n",
    "\n",
    "def extract_coordinates(h5_file):\n",
    "    with h5py.File(h5_file, \"r\") as f:\n",
    "        locs = f[\"tracks\"][:].T\n",
    "        y = locs[:, :, 1, :].squeeze()\n",
    "        x = locs[:, :, 0, :].squeeze()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def replace_nans_with_previous_value(arr):\n",
    "    # Find the indices of the NaN values\n",
    "    nan_indices = np.where(np.isnan(arr))\n",
    "\n",
    "    # Replace the NaN values with the previous value\n",
    "    for i in nan_indices[0]:\n",
    "        arr[i] = arr[i - 1]\n",
    "\n",
    "\n",
    "def extract_interaction_events(ballpath, flypath, Thresh=80, min_time=60):\n",
    "    \"\"\"\n",
    "    Extracts the interaction events from the ball and fly paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ballpath : str\n",
    "        The path to the ball path file.\n",
    "        flypath : str\n",
    "        The path to the fly path file.\n",
    "        Thresh : int\n",
    "        The threshold distance between the ball and fly.\n",
    "        min_time : int\n",
    "        The minimum duration of an interaction event.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_events : list\n",
    "        A list of DataFrames containing the interaction events.\n",
    "    \"\"\"\n",
    "    xball, yball = extract_coordinates(ballpath.as_posix())\n",
    "    xfly, yfly = extract_coordinates(flypath.as_posix())\n",
    "\n",
    "    # Replace NaNs in yball\n",
    "    replace_nans_with_previous_value(yball)\n",
    "\n",
    "    # Replace NaNs in xball\n",
    "    replace_nans_with_previous_value(xball)\n",
    "\n",
    "    # Replace NaNs in yfly\n",
    "    replace_nans_with_previous_value(yfly)\n",
    "\n",
    "    # Replace NaNs in xfly\n",
    "    replace_nans_with_previous_value(xfly)\n",
    "\n",
    "    # Combine the yball and yfly arrays into a single 2D array\n",
    "    data = np.stack((yball, yfly), axis=1)\n",
    "\n",
    "    # Create a pandas DataFrame from the data\n",
    "    df = pd.DataFrame(data, columns=[\"yball\", \"yfly\"])\n",
    "\n",
    "    df[\"yball_smooth\"] = savgol_lowpass_filter(df[\"yball\"], 221, 1)\n",
    "    df[\"yfly_smooth\"] = savgol_lowpass_filter(df[\"yfly\"], 221, 1)\n",
    "    df = df.assign(Frame=df.index + 1)\n",
    "    df[\"time\"] = df[\"Frame\"] / 30\n",
    "\n",
    "    # Compute the difference between the yball and yfly positions smoothed\n",
    "    df[\"dist\"] = df[\"yfly_smooth\"] - df[\"yball_smooth\"]\n",
    "\n",
    "    # Locate where the distance is below the threshold\n",
    "    df[\"close\"] = df[\"dist\"] < Thresh\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Find the start and end indices of streaks of True values in the 'close' column\n",
    "    df[\"block\"] = (df[\"close\"].shift(1) != df[\"close\"]).cumsum()\n",
    "    events = (\n",
    "        df[df[\"close\"]]\n",
    "        .groupby(\"block\")\n",
    "        .agg(start=(\"index\", \"min\"), end=(\"index\", \"max\"))\n",
    "    )\n",
    "\n",
    "    # Store the interaction events as separate DataFrames\n",
    "    interaction_events = [\n",
    "        df.loc[start:end]\n",
    "        for start, end in events[[\"start\", \"end\"]].itertuples(index=False)\n",
    "    ]\n",
    "\n",
    "    # remove events that are less than min_time frames long\n",
    "    interaction_events = [\n",
    "        event for event in interaction_events if len(event) >= min_time\n",
    "    ]\n",
    "\n",
    "    # event_times = [(df[\"time\"].min(), df[\"time\"].max()) for df in interaction_events]\n",
    "\n",
    "    return interaction_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "ballpath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/corridor3_tracked_ball.000_corridor3.analysis.h5\"\n",
    ")\n",
    "\n",
    "flypath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/tracked_fly.000_corridor3.analysis.h5\"\n",
    ")\n",
    "\n",
    "vidpath = Path(\n",
    "    \"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos/230721_Feedingstate_4_PM_Videos_Tracked/arena5/corridor3/corridor3.mp4\"\n",
    ")\n",
    "\n",
    "interaction_events = extract_interaction_events(ballpath, flypath)\n",
    "\n",
    "OutFolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Grids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clips generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def check_yball_variation(event_df, threshold=10):\n",
    "    yball_segment = event_df['yball_smooth']\n",
    "    variation = yball_segment.max() - yball_segment.min()\n",
    "    return variation > threshold\n",
    "\n",
    "clips = []\n",
    "# Assuming interaction_events is a list of dataframes\n",
    "for i, event_df in enumerate(interaction_events):\n",
    "    start_frame, end_frame = event_df['Frame'].min(), event_df['Frame'].max()\n",
    "    start_time, end_time = event_df['time'].min(), event_df['time'].max()  # Assuming 'time' is in seconds\n",
    "    start_time_str = str(timedelta(seconds=int(start_time)))\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(str(vidpath))\n",
    "\n",
    "    # Get the video's width, height, and frames per second (fps)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lower case\n",
    "    \n",
    "    clip_path = OutFolder.joinpath(f\"output_{i}.mp4\").as_posix()\n",
    "    \n",
    "    out = cv2.VideoWriter(clip_path, fourcc, fps, (height, width))  # Note that width and height are swapped\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    for _ in range(start_frame, end_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Rotate frame 90 degrees clockwise\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # Write some Text\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = f\"Event:{i+1} - start:{start_time_str}\"\n",
    "        font_scale = width / 150\n",
    "        thickness = int(4 * font_scale)\n",
    "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        \n",
    "        # Position the text at the top center of the frame\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "        text_y = 25\n",
    "        cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Check if yball value varies more than threshold\n",
    "        if check_yball_variation(event_df):  # You need to implement this function\n",
    "            # Add red dot to segment\n",
    "            dot = np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "            dot[:, :, 0] = 0\n",
    "            dot[:, :, 1] = 0\n",
    "            dot[:, :, 2] = 255\n",
    "            dot = cv2.resize(dot, (20, 20))\n",
    "            \n",
    "            # Position the dot right next to the text at the top of the frame\n",
    "            dot_x = text_x + text_size[0] + 10  # Position the dot right next to the text with a margin of 10\n",
    "            \n",
    "            # Adjusted position for dot_y to make it slightly higher\n",
    "            dot_y_adjustment_factor = 1.2  \n",
    "            dot_y = text_y - int(dot.shape[0] * dot_y_adjustment_factor) + text_size[1] // 2\n",
    "            \n",
    "            frame[dot_y:dot_y+dot.shape[0], dot_x:dot_x+dot.shape[1]] = dot\n",
    "\n",
    "        # Write the frame into the output file\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything when done\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    clips.append(clip_path)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating the clips into one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec and create a VideoWriter object for the final video\n",
    "out = cv2.VideoWriter(OutFolder.joinpath('final_output.mp4').as_posix(), fourcc, fps, (height, width)) # Note that width and height are swapped because the clips were rotated\n",
    "\n",
    "# Assuming 'clips' is a list of paths to the clip files\n",
    "for clip_path in clips:\n",
    "    cap = cv2.VideoCapture(clip_path)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Write the frame into the final output file\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Release the final output file when done\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutFolder.joinpath(\"output.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the folder containing all videos to be concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataFolder\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    DataPath = Path(\"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "# Linux Datapath\n",
    "if platform.system() == \"Linux\":\n",
    "    DataPath = Path(\"/mnt/labserver/DURRIEU_Matthias/Experimental_data/MultiMazeRecorder/Videos\")\n",
    "\n",
    "print(DataPath)\n",
    "# Make a list of the folders I want to use\n",
    "# For instance, I want to use the folders that have the \"FeedingState\" in the name\n",
    "\n",
    "Folders = []\n",
    "for folder in DataPath.iterdir():\n",
    "    minfolder = str(folder).lower()\n",
    "    #if \"tnt\" in minfolder and \"tracked\" in minfolder and \"pm\" in minfolder:\n",
    "    # Only use the folders that have 'feedingstate' and 'tracked' but not 'dark' in the name\n",
    "    if \"feedingstate\" in minfolder and \"tracked\" in minfolder :#and \"dark\" not in minfolder:\n",
    "        Folders.append(folder)\n",
    "\n",
    "Folders\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in Folders:\n",
    "    print(f\"Adding experiment {folder} to the dataset...\")\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "        \n",
    "        print (metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(ballpath, flypath, vidpath, OutFolder, vidname, threshold=10):\n",
    "    def check_yball_variation(event_df, threshold=10):\n",
    "        yball_segment = event_df['yball_smooth']\n",
    "        variation = yball_segment.max() - yball_segment.min()\n",
    "        return variation > threshold\n",
    "\n",
    "    interaction_events = extract_interaction_events(ballpath, flypath)\n",
    "    clips = []\n",
    "    for i, event_df in enumerate(interaction_events):\n",
    "        start_frame, end_frame = event_df['Frame'].min(), event_df['Frame'].max()\n",
    "        start_time, end_time = event_df['time'].min(), event_df['time'].max()  # Assuming 'time' is in seconds\n",
    "        start_time_str = str(timedelta(seconds=int(start_time)))\n",
    "        # Load the video\n",
    "        cap = cv2.VideoCapture(str(vidpath))\n",
    "\n",
    "        # Get the video's width, height, and frames per second (fps)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Define the codec and create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Be sure to use lower case\n",
    "        \n",
    "        clip_path = OutFolder.joinpath(f\"output_{i}.mp4\").as_posix()\n",
    "        \n",
    "        out = cv2.VideoWriter(clip_path, fourcc, fps, (height, width))  # Note that width and height are swapped\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        for _ in range(start_frame, end_frame):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Rotate frame 90 degrees clockwise\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "            # Write some Text\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text = f\"Event:{i+1} - start:{start_time_str}\"\n",
    "            font_scale = width / 150\n",
    "            thickness = int(4 * font_scale)\n",
    "            text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "            \n",
    "            # Position the text at the top center of the frame\n",
    "            text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "            text_y = 25\n",
    "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "            # Check if yball value varies more than threshold\n",
    "            if check_yball_variation(event_df):  # You need to implement this function\n",
    "                # Add red dot to segment\n",
    "                dot = np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "                dot[:, :, 0] = 0\n",
    "                dot[:, :, 1] = 0\n",
    "                dot[:, :, 2] = 255\n",
    "                dot = cv2.resize(dot, (20, 20))\n",
    "                \n",
    "                # Position the dot right next to the text at the top of the frame\n",
    "                dot_x = text_x + text_size[0] + 10  # Position the dot right next to the text with a margin of 10\n",
    "                \n",
    "                # Adjusted position for dot_y to make it slightly higher\n",
    "                dot_y_adjustment_factor = 1.2  \n",
    "                dot_y = text_y - int(dot.shape[0] * dot_y_adjustment_factor) + text_size[1] // 2\n",
    "                \n",
    "                frame[dot_y:dot_y+dot.shape[0], dot_x:dot_x+dot.shape[1]] = dot\n",
    "\n",
    "            # Write the frame into the output file\n",
    "            out.write(frame)\n",
    "\n",
    "        # Release everything when done\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        clips.append(clip_path)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Define the codec and create a VideoWriter object for the final video\n",
    "    out = cv2.VideoWriter(OutFolder.joinpath(f'{vidname}.mp4').as_posix(), fourcc, fps, (height, width)) # Note that width and height are swapped because the clips were rotated\n",
    "\n",
    "    # Assuming 'clips' is a list of paths to the clip files\n",
    "    for clip_path in clips:\n",
    "        cap = cv2.VideoCapture(clip_path)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Write the frame into the final output file\n",
    "            out.write(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    # Release the final output file when done\n",
    "    out.release()\n",
    "    \n",
    "    # Delete the clips\n",
    "    for clip_path in clips:\n",
    "        os.remove(clip_path)\n",
    "        \n",
    "    print(f\"Finished processing {vidname}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "process_videos(ballpath, flypath, vidpath, OutFolder, vidname = 'myvid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveFolder = Path(\"/mnt/labserver/DURRIEU_Matthias/Videos/TNT_BallPushing_Events\")\n",
    "\n",
    "for folder in Folders:\n",
    "    print(f\"Processing {folder}...\")\n",
    "    # Read the metadata.json file\n",
    "    with open(folder / \"Metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        variables = metadata[\"Variable\"]\n",
    "        metadata_dict = {}\n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {}\n",
    "            for arena in range(1, 10):\n",
    "                arena_key = f\"Arena{arena}\"\n",
    "                var_index = variables.index(var)\n",
    "                metadata_dict[var][arena_key] = metadata[arena_key][var_index]\n",
    "                \n",
    "        # In the metadata_dict, make all they Arena subkeys lower case\n",
    "        \n",
    "        for var in variables:\n",
    "            metadata_dict[var] = {k.lower(): v for k, v in metadata_dict[var].items()}\n",
    "        print (metadata_dict)\n",
    "    for file in folder.glob(\"**/*.mp4\"):\n",
    "        print(file.name)\n",
    "        # Get the arena and corridor numbers from the parent (corridor) and grandparent (arena) folder names\n",
    "        arena = file.parent.parent.name\n",
    "        #print(arena)\n",
    "        corridor = file.parent.name\n",
    "        \n",
    "        # Get the Genotype and Dates from the metadata, arena should have a upper case first letter\n",
    "        \n",
    "        Genotype = metadata_dict[\"Genotype\"][arena]\n",
    "        print(f\"Genotype: {Genotype} for arena {arena}\")\n",
    "        \n",
    "        Date = metadata_dict[\"Date\"][arena]\n",
    "        #print(f\"Date: {Date} for arena {arena}\")\n",
    "        \n",
    "        dir = file.parent\n",
    "        \n",
    "        # Define flypath as the *tracked_fly*.analysis.h5 file in the same folder as the video\n",
    "        flypath = list(dir.glob('*tracked_fly*.analysis.h5'))[0]\n",
    "        \n",
    "        #flypath = file.parent / f\"tracked_fly.000_{corridor}.analysis.h5\"\n",
    "        print(flypath.name)\n",
    "        # Define ballpath as the *tracked*.analysis.h5 file in the same folder as the video\n",
    "        ballpath = list(dir.glob('*tracked*.analysis.h5'))[0]\n",
    "        print(ballpath.name)\n",
    "        vidpath = file\n",
    "        \n",
    "        # Define the output folder as a directory in SaveFolder with same name as Genotype. If it doesn't exist, create it.\n",
    "        OutFolder = SaveFolder / Genotype\n",
    "        OutFolder.mkdir(exist_ok=True)\n",
    "        \n",
    "        vidname = f\"{Genotype}_{Date}_{arena}_{corridor}\"\n",
    "        \n",
    "        # Check if the video has already been processed\n",
    "        if not OutFolder.joinpath(f\"{vidname}.mp4\").exists():\n",
    "            print(f\"Processing {vidname}...\")\n",
    "            process_videos(ballpath, flypath, vidpath, OutFolder, vidname = vidname)\n",
    "            \n",
    "        else:\n",
    "            print(f\"{vidname} already exists! Skipping...\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict['Genotype'][\"Arena1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
